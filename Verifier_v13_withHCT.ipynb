{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d929d6ad-2d49-41af-bf6b-141d5ef593e0",
   "metadata": {},
   "source": [
    "## Main verifier code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08dbaf2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch device: cpu\n",
      "imgs_1 dir -> ../onera/OSCD/paris/imgs_1/\n",
      "imgs_2 dir -> ../onera/OSCD/paris/imgs_2/\n",
      "cm path    -> ../onera/OSCD/paris/cm/cm.png\n",
      "[shim] installed: safe affine bounds + RCD shim; recursion should be gone.\n",
      "affine_bounds_conv2d -> affine_bounds_conv2d_final\n",
      "affine_margin_bounds_conv2d -> affine_margin_bounds_conv2d_final\n",
      "[final-patch] oscd_paths + final Conv2d bound fns installed.\n",
      "[tail] α-CROWN margin override armed (uses taps when CROWN_TAIL is set).\n",
      "[CROWN-tail] drop-in installed. If CROWN_TAIL tap is set, tail will be used; else final-only fallback.\n",
      "affine_margin_bounds_conv2d      -> _affine_margin_bounds_conv2d_tailaware_VERBOSE\n",
      "affine_margin_bounds_conv2d_safe -> _affine_margin_bounds_conv2d_tailaware_VERBOSE\n",
      "[tail] fixed α-CROWN override installed.\n",
      "[gt] loader/sanitizer installed.\n"
     ]
    }
   ],
   "source": [
    "# === All imports and global toggles ===\n",
    "import os, sys, time, csv, itertools, math, traceback\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "DUMMY_VERIFIER = False   # <- set to False once you paste real bound-prop code below\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"PyTorch device:\", DEVICE)\n",
    "# ---- ONE-CELL HOTFIX: force legacy concat to build correct paths ----\n",
    "import os, traceback\n",
    "\n",
    "# trailing slash REQUIRED here (because call-sites do string concatenation)\n",
    "OSCD_PATH_TOP = \"../onera/OSCD/\"        \n",
    "\n",
    "# leading + trailing slash REQUIRED here (same reason)\n",
    "OSCD_PATH_BOTTOM1 = \"/imgs_1/\"\n",
    "OSCD_PATH_BOTTOM2 = \"/imgs_2/\"\n",
    "OSCD_PATH_CM      = \"/cm/cm.png\"\n",
    "\n",
    "def _dbg_show(city):\n",
    "    print(\"imgs_1 dir ->\", OSCD_PATH_TOP + city + OSCD_PATH_BOTTOM1)\n",
    "    print(\"imgs_2 dir ->\", OSCD_PATH_TOP + city + OSCD_PATH_BOTTOM2)\n",
    "    print(\"cm path    ->\", OSCD_PATH_TOP + city + OSCD_PATH_CM)\n",
    "\n",
    "# quick sanity for paris (change if you like)\n",
    "_dbg_show(\"paris\")\n",
    "\n",
    "# assert they exist so we fail fast if something is still off\n",
    "for p in [\n",
    "    OSCD_PATH_TOP + \"paris\" + OSCD_PATH_BOTTOM1,\n",
    "    OSCD_PATH_TOP + \"paris\" + OSCD_PATH_BOTTOM2,\n",
    "    OSCD_PATH_TOP + \"paris\" + OSCD_PATH_CM,\n",
    "]:\n",
    "    if not os.path.exists(p):\n",
    "        print(\"[fatal path check] missing:\", p)\n",
    "        raise FileNotFoundError(p)\n",
    "# === Data helpers ===\n",
    "def _load_gt_mask_from_disk(city):\n",
    "    _, _, cm = oscd_paths(city)\n",
    "    if not os.path.exists(cm):\n",
    "        raise FileNotFoundError(f\"GT mask path missing for {city}: {cm}\")\n",
    "    m = np.array(Image.open(cm))\n",
    "    return (m > 0).astype(np.bool_)\n",
    "\n",
    "def make_dummy_input(city, H=128, W=128, C=13):\n",
    "    # Simple pattern so logits aren't constant; not reading any disk.\n",
    "    x = torch.zeros((1, C, H, W), device=DEVICE)\n",
    "    x[..., H//4:3*H//4, W//4:3*W//4] = 1.0\n",
    "    return x\n",
    "\n",
    "# All imports and definitions\n",
    "import itertools\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.enums import Resampling\n",
    "import rasterio.warp\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.ndimage import label as ndlabel\n",
    "from skimage.measure import label as sklabel\n",
    "from PIL import Image\n",
    "import traceback   # <-- fixes: name 'traceback' is not defined\n",
    "\n",
    "from models import AttU_Net, EncDec_LiRPA, FALCONetMHA_LiRPA\n",
    "# Constants\n",
    "BANDS = [\n",
    "    \"B01\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\",\n",
    "    \"B08\", \"B09\", \"B10\", \"B11\", \"B12\", \"B8A\"\n",
    "]\n",
    "\n",
    "\n",
    "# --- One-time compatibility shim for OSCD path constants ---\n",
    "import os, traceback  # traceback for earlier errors\n",
    "\n",
    "# Base Monolithic verifier routines  (anon stable BN version)\n",
    "# ============================================================\n",
    "# -----------------------------\n",
    "# Zonotope: accept scalar or tensor epsilon (broadcast-safe)\n",
    "# -----------------------------\n",
    "class Zonotope:\n",
    "    def __init__(self, center: torch.Tensor, epsilon):\n",
    "        self.center = center.detach().clone()\n",
    "\n",
    "        if torch.is_tensor(epsilon):\n",
    "            eps = epsilon.to(dtype=center.dtype, device=center.device)\n",
    "        else:\n",
    "            eps = torch.tensor(float(epsilon), dtype=center.dtype, device=center.device)\n",
    "\n",
    "        # Make sure eps is broadcastable to center (N,C,H,W)\n",
    "        while eps.ndim < self.center.ndim:\n",
    "            eps = eps.view(*([1] * eps.ndim), 1)\n",
    "\n",
    "        self.epsilon = eps\n",
    "        self.lower = self.center - eps\n",
    "        self.upper = self.center + eps\n",
    "\n",
    "    def bound_box(self):\n",
    "        return self.lower, self.upper\n",
    "\n",
    "# -----------------------------\n",
    "# Utilities\n",
    "# -----------------------------\n",
    "def flatten_hw(x):\n",
    "    B, C, H, W = x.shape\n",
    "    return x.view(B, C, H * W), (B, C, H, W)\n",
    "\n",
    "def unflatten_hw(x, shape):\n",
    "    B, C, H, W = shape\n",
    "    return x.view(B, C, H, W)\n",
    "\n",
    "# -----------------------------\n",
    "# Safe BatchNorm2d interval (eval-mode running stats)\n",
    "# Handles sign of scale and prevents numeric blow-ups.\n",
    "# -----------------------------\n",
    "def interval_batchnorm(x_l, x_u, bn: nn.BatchNorm2d, max_scale=4.0, min_var=5e-2):\n",
    "    \"\"\"\n",
    "    Eval-mode BatchNorm2d bounds using running stats, with:\n",
    "      - variance floor (min_var) to avoid huge 1/sqrt(var)\n",
    "      - scale clamp (max_scale) to stop multiplicative explosions across many BNs\n",
    "    y = gamma * (x - mu) / sqrt(var + eps) + beta\n",
    "    \"\"\"\n",
    "    # (1,C,1,1) buffers\n",
    "    w  = bn.weight.view(1, -1, 1, 1)\n",
    "    b  = bn.bias.view(1, -1, 1, 1)\n",
    "    mu = bn.running_mean.view(1, -1, 1, 1)\n",
    "    var= bn.running_var.view(1, -1, 1, 1)\n",
    "\n",
    "    # guard tiny variance and clamp scale\n",
    "    inv_std = torch.rsqrt(torch.clamp(var + bn.eps, min=min_var))\n",
    "    s = torch.clamp(w * inv_std, min=-max_scale, max=max_scale)  # per-channel scale\n",
    "    t = b - s * mu                                               # per-channel bias\n",
    "\n",
    "    y_l = s * x_l + t\n",
    "    y_u = s * x_u + t\n",
    "    # handle negative scale by swapping\n",
    "    return torch.minimum(y_l, y_u), torch.maximum(y_l, y_u)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Interval forward for common modules (EncDec/FALCONet/AttUNet)\n",
    "# -----------------------------\n",
    "def _interval_conv2d(x_l, x_u, conv: nn.Conv2d):\n",
    "    W, b = conv.weight, conv.bias\n",
    "    mu = 0.5 * (x_u + x_l)\n",
    "    r  = 0.5 * (x_u - x_l)\n",
    "    mu = F.conv2d(mu, W, b, stride=conv.stride, padding=conv.padding,\n",
    "                  dilation=conv.dilation, groups=conv.groups)\n",
    "    r  = F.conv2d(r,  W.abs(), None, stride=conv.stride, padding=conv.padding,\n",
    "                  dilation=conv.dilation, groups=conv.groups)\n",
    "    return mu - r, mu + r\n",
    "\n",
    "def _interval_conv1d(x_l, x_u, conv: nn.Conv1d):\n",
    "    W, b = conv.weight, conv.bias\n",
    "    mu = 0.5 * (x_u + x_l)\n",
    "    r  = 0.5 * (x_u - x_l)\n",
    "\n",
    "    # Ensure (B, C_in, L)\n",
    "    if mu.dim() == 3 and mu.shape[1] != W.shape[1] * conv.groups:\n",
    "        mu = mu.transpose(1, 2)  # (B,L,C) -> (B,C,L)\n",
    "        r  = r.transpose(1, 2)\n",
    "\n",
    "    mu = F.conv1d(mu, W, b, stride=conv.stride, padding=conv.padding,\n",
    "                  dilation=conv.dilation, groups=conv.groups)\n",
    "    r  = F.conv1d(r,  W.abs(), None, stride=conv.stride, padding=conv.padding,\n",
    "                  dilation=conv.dilation, groups=conv.groups)\n",
    "    return mu - r, mu + r\n",
    "\n",
    "def _interval_linear(x_l, x_u, linear: nn.Linear):\n",
    "    W, b = linear.weight, linear.bias\n",
    "    mu = 0.5 * (x_u + x_l)\n",
    "    r  = 0.5 * (x_u - x_l)\n",
    "\n",
    "    orig = mu.shape\n",
    "    mu = mu.view(-1, mu.shape[-1])\n",
    "    r  = r.view(-1,  r.shape[-1])\n",
    "\n",
    "    mu = F.linear(mu, W, b)\n",
    "    r  = F.linear(r,  W.abs(), None)\n",
    "\n",
    "    y_l = (mu - r).view(*orig[:-1], -1)\n",
    "    y_u = (mu + r).view(*orig[:-1], -1)\n",
    "    return y_l, y_u\n",
    "\n",
    "def _resolve_final_1x1(model: nn.Module) -> nn.Conv2d:\n",
    "    # Common names first\n",
    "    for name in (\"final\", \"outc\", \"Conv_1x1\", \"conv_last\", \"classifier\", \"head\"):\n",
    "        if hasattr(model, name):\n",
    "            mod = getattr(model, name)\n",
    "            if isinstance(mod, nn.Conv2d):\n",
    "                return mod\n",
    "            # If it's a container, grab its last Conv2d\n",
    "            for m in reversed(list(mod.modules())):\n",
    "                if isinstance(m, nn.Conv2d):\n",
    "                    return m\n",
    "    # Fallback: last 1×1 Conv2d anywhere in the model\n",
    "    for m in reversed(list(model.modules())):\n",
    "        if isinstance(m, nn.Conv2d) and m.kernel_size == (1, 1):\n",
    "            return m\n",
    "    raise AttributeError(f\"Could not resolve final 1×1 head for {model.__class__.__name__}\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# FALCONet module-wise interval forward\n",
    "# -----------------------------\n",
    "def interval_forward_falconet(x_l, x_u, module):\n",
    "    if isinstance(module, nn.Conv2d):\n",
    "        return _interval_conv2d(x_l, x_u, module)\n",
    "\n",
    "    elif isinstance(module, nn.Conv1d):\n",
    "        return _interval_conv1d(x_l, x_u, module)\n",
    "\n",
    "    elif isinstance(module, nn.Sequential):\n",
    "        for sub in module:\n",
    "            x_l, x_u = interval_forward_falconet(x_l, x_u, sub)\n",
    "        return x_l, x_u\n",
    "\n",
    "    elif isinstance(module, nn.ReLU):\n",
    "        return F.relu(x_l), F.relu(x_u)\n",
    "\n",
    "    elif isinstance(module, nn.LeakyReLU):\n",
    "        # Monotone increasing → apply elementwise\n",
    "        return F.leaky_relu(x_l, negative_slope=module.negative_slope), \\\n",
    "               F.leaky_relu(x_u, negative_slope=module.negative_slope)\n",
    "\n",
    "    elif isinstance(module, nn.BatchNorm2d):\n",
    "        # ---- SAFE BN (eval-mode running stats) ----\n",
    "        w  = module.weight.view(1, -1, 1, 1)\n",
    "        b  = module.bias.view(1, -1, 1, 1)\n",
    "        mu = module.running_mean.view(1, -1, 1, 1)\n",
    "        var= module.running_var.view(1, -1, 1, 1)\n",
    "    \n",
    "        # guard tiny variance + clamp scale\n",
    "        inv_std = torch.rsqrt(torch.clamp(var + module.eps, min=1e-2))\n",
    "        s = torch.clamp(w * inv_std, min=-16.0, max=16.0)\n",
    "        t = b - s * mu\n",
    "    \n",
    "        y_l = s * x_l + t\n",
    "        y_u = s * x_u + t\n",
    "    \n",
    "        # # one-time debug to ensure THIS branch is actually hit\n",
    "        # if not hasattr(module, \"_bn_dbg_printed\"):\n",
    "        #     print(\"[bn] scale range:\", float(s.min()), float(s.max()))\n",
    "        #     module._bn_dbg_printed = True\n",
    "    \n",
    "        return torch.minimum(y_l, y_u), torch.maximum(y_l, y_u)\n",
    "\n",
    "    elif isinstance(module, nn.Upsample):\n",
    "        return (F.interpolate(x_l, scale_factor=module.scale_factor, mode=module.mode,\n",
    "                              align_corners=getattr(module, 'align_corners', None)),\n",
    "                F.interpolate(x_u, scale_factor=module.scale_factor, mode=module.mode,\n",
    "                              align_corners=getattr(module, 'align_corners', None)))\n",
    "\n",
    "    elif isinstance(module, nn.Identity):\n",
    "        return x_l, x_u\n",
    "\n",
    "    elif isinstance(module, nn.Linear):\n",
    "        return _interval_linear(x_l, x_u, module)\n",
    "\n",
    "    elif isinstance(module, nn.Module) and len(list(module.children())) > 0:\n",
    "        for sub in module.children():\n",
    "            x_l, x_u = interval_forward_falconet(x_l, x_u, sub)\n",
    "        return x_l, x_u\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(f\"[FALCONet] Unsupported module type: {type(module)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Specialized interval forward for MultiHeadConvAttention (safe fallback)\n",
    "# -----------------------------\n",
    "def interval_forward_tokenmixer(x_l, x_u, attn_module):\n",
    "    \"\"\"\n",
    "    Token mixer fallback: propagate through depthwise/projections headwise,\n",
    "    ignore attention weights (use V bounds). Shapes: (B,C,L) in/out.\n",
    "    \"\"\"\n",
    "    assert x_l.ndim == 3 and x_u.ndim == 3, f\"[token_mixer] Expected (B,C,L), got {x_l.shape}\"\n",
    "    B, C, L = x_l.shape\n",
    "    head_dim  = attn_module.head_dim\n",
    "    num_heads = attn_module.num_heads\n",
    "    assert C == head_dim * num_heads, f\"[token_mixer] C={C} != {head_dim}x{num_heads}\"\n",
    "\n",
    "    outs_l, outs_u = [], []\n",
    "    for i, head in enumerate(attn_module.heads):\n",
    "        s, e = i * head_dim, (i + 1) * head_dim\n",
    "        # (B, head_dim, L)\n",
    "        xl = x_l[:, s:e, :]\n",
    "        xu = x_u[:, s:e, :]\n",
    "\n",
    "        # Depthwise conv (1D)\n",
    "        xl, xu = interval_forward_falconet(xl, xu, head.depthwise_conv)\n",
    "\n",
    "        # Q,K,V projections\n",
    "        ql, qu = interval_forward_falconet(xl, xu, head.q_proj)\n",
    "        kl, ku = interval_forward_falconet(xl, xu, head.k_proj)\n",
    "        vl, vu = interval_forward_falconet(xl, xu, head.v_proj)\n",
    "\n",
    "        # Safe fallback: pass V only\n",
    "        outl, outu = vl, vu\n",
    "        outs_l.append(outl.transpose(1, 2))  # (B,L,head_dim)\n",
    "        outs_u.append(outu.transpose(1, 2))  # (B,L,head_dim)\n",
    "\n",
    "    # Concat heads on channel axis (B,L,C)\n",
    "    out_l = torch.cat(outs_l, dim=2)\n",
    "    out_u = torch.cat(outs_u, dim=2)\n",
    "\n",
    "    # Final linear projection (treat as Linear over last dim)\n",
    "    B, L, C = out_l.shape\n",
    "    out_l = out_l.reshape(B * L, C)\n",
    "    out_u = out_u.reshape(B * L, C)\n",
    "    out_l, out_u = interval_forward_falconet(out_l, out_u, attn_module.out_proj)\n",
    "    out_l = out_l.view(B, L, -1).transpose(1, 2)  # (B,C_out,L)\n",
    "    out_u = out_u.view(B, L, -1).transpose(1, 2)  # (B,C_out,L)\n",
    "    return out_l, out_u\n",
    "\n",
    "# -----------------------------\n",
    "# Top-level verifier for Simple Encoder-Decoder\n",
    "# -----------------------------\n",
    "def propagate_bounds_encdecnet(model, zonotope):\n",
    "    x_l, x_u = zonotope.lower, zonotope.upper\n",
    "\n",
    "    # Encoder\n",
    "    x1_l, x1_u = interval_forward_falconet(x_l, x_u, model.inc)\n",
    "    x2_l, x2_u = interval_forward_falconet(x1_l, x1_u, model.down1)\n",
    "    x3_l, x3_u = interval_forward_falconet(x2_l, x2_u, model.down2)\n",
    "    x4_l, x4_u = interval_forward_falconet(x3_l, x3_u, model.down3)\n",
    "    x5_l, x5_u = interval_forward_falconet(x4_l, x4_u, model.down4)\n",
    "\n",
    "    # Decoder\n",
    "    def up_step(up, xl, xu, sk_l, sk_u):\n",
    "        xl = up.up(xl); xu = up.up(xu)\n",
    "        xl = torch.cat([sk_l, xl], dim=1)\n",
    "        xu = torch.cat([sk_u, xu], dim=1)\n",
    "        return interval_forward_falconet(xl, xu, up.conv)\n",
    "\n",
    "    x_l, x_u = up_step(model.up1, x5_l, x5_u, x4_l, x4_u)\n",
    "    x_l, x_u = up_step(model.up2, x_l,  x_u,  x3_l, x3_u)\n",
    "    x_l, x_u = up_step(model.up3, x_l,  x_u,  x2_l, x2_u)\n",
    "    x_l, x_u = up_step(model.up4, x_l,  x_u,  x1_l, x1_u)\n",
    "    x_l, x_u = interval_forward_falconet(x_l, x_u, model.outc)\n",
    "    return x_l, x_u\n",
    "\n",
    "# -----------------------------\n",
    "# Top-level verifier for FALCONet + token mixers\n",
    "# -----------------------------\n",
    "def propagate_bounds_falconetmha_lirpa(model, zonotope):\n",
    "    x_l, x_u = zonotope.lower, zonotope.upper\n",
    "\n",
    "    # Encoder\n",
    "    x1_l, x1_u = interval_forward_falconet(x_l, x_u, model.inc)\n",
    "    x2_l, x2_u = interval_forward_falconet(x1_l, x1_u, model.down1)\n",
    "    x3_l, x3_u = interval_forward_falconet(x2_l, x2_u, model.down2)\n",
    "\n",
    "    x3_l, shape3 = flatten_hw(x3_l); x3_u, _ = flatten_hw(x3_u)\n",
    "    x3_l, x3_u   = interval_forward_tokenmixer(x3_l, x3_u, model.token_mixer_2)\n",
    "    x3_l, x3_u   = unflatten_hw(x3_l, shape3), unflatten_hw(x3_u, shape3)\n",
    "\n",
    "    x4_l, x4_u   = interval_forward_falconet(x3_l, x3_u, model.down3)\n",
    "    x4_l, shape4 = flatten_hw(x4_l); x4_u, _ = flatten_hw(x4_u)\n",
    "    x4_l, x4_u   = interval_forward_tokenmixer(x4_l, x4_u, model.token_mixer_3)\n",
    "    x4_l, x4_u   = unflatten_hw(x4_l, shape4), unflatten_hw(x4_u, shape4)\n",
    "\n",
    "    x5_l, x5_u   = interval_forward_falconet(x4_l, x4_u, model.down4)\n",
    "    x5_l, shape5 = flatten_hw(x5_l); x5_u, _ = flatten_hw(x5_u)\n",
    "    x5_l, x5_u   = interval_forward_tokenmixer(x5_l, x5_u, model.token_mixer_4)\n",
    "    x5_l, x5_u   = unflatten_hw(x5_l, shape5), unflatten_hw(x5_u, shape5)\n",
    "\n",
    "    # Decoder\n",
    "    def up_step(up, xl, xu, sk_l, sk_u):\n",
    "        xl = up.up(xl); xu = up.up(xu)\n",
    "        xl = torch.cat([sk_l, xl], dim=1)\n",
    "        xu = torch.cat([sk_u, xu], dim=1)\n",
    "        return interval_forward_falconet(xl, xu, up.conv)\n",
    "\n",
    "    x_l, x_u = up_step(model.up1, x5_l, x5_u, x4_l, x4_u)\n",
    "    x_l, x_u = up_step(model.up2, x_l,  x_u,  x3_l, x3_u)\n",
    "    x_l, x_u = up_step(model.up3, x_l,  x_u,  x2_l, x2_u)\n",
    "    x_l, x_u = up_step(model.up4, x_l,  x_u,  x1_l, x1_u)\n",
    "    x_l, x_u = interval_forward_falconet(x_l, x_u, model.outc)\n",
    "    return x_l, x_u\n",
    "\n",
    "# -----------------------------\n",
    "# Interval forward for Attention U-Net (modules)\n",
    "# -----------------------------\n",
    "def interval_forward_attunet(x_l, x_u, module):\n",
    "    if isinstance(module, nn.Conv2d):\n",
    "        return _interval_conv2d(x_l, x_u, module)\n",
    "\n",
    "    elif isinstance(module, nn.Sequential):\n",
    "        for sub in module:\n",
    "            x_l, x_u = interval_forward_attunet(x_l, x_u, sub)\n",
    "        return x_l, x_u\n",
    "\n",
    "    elif isinstance(module, nn.ReLU):\n",
    "        return F.relu(x_l), F.relu(x_u)\n",
    "\n",
    "    elif isinstance(module, nn.Sigmoid):\n",
    "        # Sigmoid is monotone; clamp inputs to avoid overflow\n",
    "        return torch.sigmoid(x_l.clamp(-10, 10)), torch.sigmoid(x_u.clamp(-10, 10))\n",
    "\n",
    "    elif isinstance(module, nn.LeakyReLU):\n",
    "        return F.leaky_relu(x_l, negative_slope=module.negative_slope), \\\n",
    "               F.leaky_relu(x_u, negative_slope=module.negative_slope)\n",
    "\n",
    "    elif isinstance(module, nn.BatchNorm2d):\n",
    "        # ---- SAFE BN (eval-mode running stats) ----\n",
    "        w  = module.weight.view(1, -1, 1, 1)\n",
    "        b  = module.bias.view(1, -1, 1, 1)\n",
    "        mu = module.running_mean.view(1, -1, 1, 1)\n",
    "        var= module.running_var.view(1, -1, 1, 1)\n",
    "    \n",
    "        # guard tiny variance + clamp scale\n",
    "        inv_std = torch.rsqrt(torch.clamp(var + module.eps, min=1e-2))\n",
    "        s = torch.clamp(w * inv_std, min=-16.0, max=16.0)\n",
    "        t = b - s * mu\n",
    "    \n",
    "        y_l = s * x_l + t\n",
    "        y_u = s * x_u + t\n",
    "    \n",
    "        # # one-time debug to ensure THIS branch is actually hit\n",
    "        # if not hasattr(module, \"_bn_dbg_printed\"):\n",
    "        #     print(\"[bn] scale range:\", float(s.min()), float(s.max()))\n",
    "        #     module._bn_dbg_printed = True\n",
    "    \n",
    "        return torch.minimum(y_l, y_u), torch.maximum(y_l, y_u)\n",
    "\n",
    "    elif isinstance(module, nn.Upsample):\n",
    "        return (F.interpolate(x_l, scale_factor=module.scale_factor, mode=module.mode,\n",
    "                              align_corners=getattr(module, 'align_corners', None)),\n",
    "                F.interpolate(x_u, scale_factor=module.scale_factor, mode=module.mode,\n",
    "                              align_corners=getattr(module, 'align_corners', None)))\n",
    "\n",
    "    elif isinstance(module, nn.Identity):\n",
    "        return x_l, x_u\n",
    "\n",
    "    elif isinstance(module, nn.Module) and len(list(module.children())) > 0:\n",
    "        for sub in module.children():\n",
    "            x_l, x_u = interval_forward_attunet(x_l, x_u, sub)\n",
    "        return x_l, x_u\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(f\"[AttU_Net] Unsupported module type: {type(module)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Attention gate (psi sigmoid handled safely)\n",
    "# -----------------------------\n",
    "def interval_mul_pos(x_l, x_u, p_l, p_u):\n",
    "    \"\"\"\n",
    "    Interval product when 0 <= p_l <= p_u <= 1 (sigmoid outputs).\n",
    "    Returns tight lower/upper by enumerating endpoints.\n",
    "    \"\"\"\n",
    "    c1 = x_l * p_l\n",
    "    c2 = x_l * p_u\n",
    "    c3 = x_u * p_l\n",
    "    c4 = x_u * p_u\n",
    "    lo = torch.minimum(torch.minimum(c1, c2), torch.minimum(c3, c4))\n",
    "    hi = torch.maximum(torch.maximum(c1, c2), torch.maximum(c3, c4))\n",
    "    return lo, hi\n",
    "    \n",
    "def interval_forward_attention_gate(attn_block, g_l, g_u, x_l, x_u):\n",
    "    g1_l, g1_u = interval_forward_attunet(g_l, g_u, attn_block.W_g)\n",
    "    x1_l, x1_u = interval_forward_attunet(x_l, x_u, attn_block.W_x)\n",
    "\n",
    "    psi_l = F.relu(g1_l + x1_l)\n",
    "    psi_u = F.relu(g1_u + x1_u)\n",
    "    psi_l, psi_u = interval_forward_attunet(psi_l, psi_u, attn_block.psi)\n",
    "\n",
    "    # Sigmoid is monotone; clamp inputs to avoid overflow\n",
    "    psi_l = torch.sigmoid(psi_l.clamp(-10, 10))\n",
    "    psi_u = torch.sigmoid(psi_u.clamp(-10, 10))\n",
    "\n",
    "    return interval_mul_pos(x_l, x_u, psi_l, psi_u)\n",
    "\n",
    "# -----------------------------\n",
    "# Top-level verifier for Attention U-Net\n",
    "# -----------------------------\n",
    "def propagate_bounds_attunet_lirpa(model, zonotope):\n",
    "    x_l, x_u = zonotope.lower, zonotope.upper\n",
    "\n",
    "    # Encoder\n",
    "    x1_l, x1_u = interval_forward_attunet(x_l, x_u, model.Conv1)\n",
    "    # print(\"[dbg] after Conv1:\", float(x1_l.min()), float(x1_l.max()), float(x1_u.min()), float(x1_u.max()))\n",
    "\n",
    "    x2_l = F.max_pool2d(x1_l, kernel_size=2, stride=2)\n",
    "    x2_u = F.max_pool2d(x1_u, kernel_size=2, stride=2)\n",
    "    x2_l, x2_u = interval_forward_attunet(x2_l, x2_u, model.Conv2)\n",
    "\n",
    "    x3_l = F.max_pool2d(x2_l, kernel_size=2, stride=2)\n",
    "    x3_u = F.max_pool2d(x2_u, kernel_size=2, stride=2)\n",
    "    x3_l, x3_u = interval_forward_attunet(x3_l, x3_u, model.Conv3)\n",
    "\n",
    "    x4_l = F.max_pool2d(x3_l, kernel_size=2, stride=2)\n",
    "    x4_u = F.max_pool2d(x3_u, kernel_size=2, stride=2)\n",
    "    x4_l, x4_u = interval_forward_attunet(x4_l, x4_u, model.Conv4)\n",
    "\n",
    "    x5_l = F.max_pool2d(x4_l, kernel_size=2, stride=2)\n",
    "    x5_u = F.max_pool2d(x4_u, kernel_size=2, stride=2)\n",
    "    x5_l, x5_u = interval_forward_attunet(x5_l, x5_u, model.Conv5)\n",
    "\n",
    "    # Decoder with attention\n",
    "    d5_l, d5_u = interval_forward_attunet(x5_l, x5_u, model.Up5)\n",
    "    x4_l_att, x4_u_att = interval_forward_attention_gate(model.Att5, d5_l, d5_u, x4_l, x4_u)\n",
    "    d5_l, d5_u = torch.cat((x4_l_att, d5_l), dim=1), torch.cat((x4_u_att, d5_u), dim=1)\n",
    "    d5_l, d5_u = interval_forward_attunet(d5_l, d5_u, model.Up_conv5)\n",
    "\n",
    "    d4_l, d4_u = interval_forward_attunet(d5_l, d5_u, model.Up4)\n",
    "    x3_l_att, x3_u_att = interval_forward_attention_gate(model.Att4, d4_l, d4_u, x3_l, x3_u)\n",
    "    d4_l, d4_u = torch.cat((x3_l_att, d4_l), dim=1), torch.cat((x3_u_att, d4_u), dim=1)\n",
    "    d4_l, d4_u = interval_forward_attunet(d4_l, d4_u, model.Up_conv4)\n",
    "\n",
    "    d3_l, d3_u = interval_forward_attunet(d4_l, d4_u, model.Up3)\n",
    "    x2_l_att, x2_u_att = interval_forward_attention_gate(model.Att3, d3_l, d3_u, x2_l, x2_u)\n",
    "    d3_l, d3_u = torch.cat((x2_l_att, d3_l), dim=1), torch.cat((x2_u_att, d3_u), dim=1)\n",
    "    d3_l, d3_u = interval_forward_attunet(d3_l, d3_u, model.Up_conv3)\n",
    "\n",
    "    d2_l, d2_u = interval_forward_attunet(d3_l, d3_u, model.Up2)\n",
    "    x1_l_att, x1_u_att = interval_forward_attention_gate(model.Att2, d2_l, d2_u, x1_l, x1_u)\n",
    "    d2_l, d2_u = torch.cat((x1_l_att, d2_l), dim=1), torch.cat((x1_u_att, d2_u), dim=1)\n",
    "    d2_l, d2_u = interval_forward_attunet(d2_l, d2_u, model.Up_conv2)\n",
    "\n",
    "    out_l, out_u = interval_forward_attunet(d2_l, d2_u, model.Conv_1x1)\n",
    "    return out_l, out_u\n",
    "\n",
    "# ---------- Exact affine bounds for final Conv2d / margin ----------\n",
    "\n",
    "@torch.no_grad()\n",
    "def affine_bounds_conv2d(l, u, conv: nn.Conv2d):\n",
    "    \"\"\"\n",
    "    Exact interval bounds for y = Conv2d(x; W,b) given l<=x<=u.\n",
    "    Works for any kernel/stride/padding/groups. Returns (y_lb, y_ub) in logit space.\n",
    "    \"\"\"\n",
    "    if not hasattr(affine_bounds_conv2d, \"_dbg_printed\"):\n",
    "        print(\"[path] using affine_bounds_conv2d for final logits\")\n",
    "        affine_bounds_conv2d._dbg_printed = True\n",
    "    assert isinstance(conv, nn.Conv2d)\n",
    "    W, b = conv.weight, conv.bias\n",
    "    Wpos = torch.clamp(W, min=0)\n",
    "    Wneg = torch.clamp(W, max=0)\n",
    "\n",
    "    y_lb = F.conv2d(l, Wpos, bias=None,\n",
    "                    stride=conv.stride, padding=conv.padding,\n",
    "                    dilation=conv.dilation, groups=conv.groups) \\\n",
    "         + F.conv2d(u, Wneg, bias=None,\n",
    "                    stride=conv.stride, padding=conv.padding,\n",
    "                    dilation=conv.dilation, groups=conv.groups)\n",
    "    if b is not None:\n",
    "        y_lb = y_lb + b.view(1, -1, 1, 1)\n",
    "\n",
    "    y_ub = F.conv2d(u, Wpos, bias=None,\n",
    "                    stride=conv.stride, padding=conv.padding,\n",
    "                    dilation=conv.dilation, groups=conv.groups) \\\n",
    "         + F.conv2d(l, Wneg, bias=None,\n",
    "                    stride=conv.stride, padding=conv.padding,\n",
    "                    dilation=conv.dilation, groups=conv.groups)\n",
    "    if b is not None:\n",
    "        y_ub = y_ub + b.view(1, -1, 1, 1)\n",
    "\n",
    "    return y_lb, y_ub\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def affine_margin_bounds_conv2d(l, u, conv: nn.Conv2d, chg_idx=1, nchg_idx=0):\n",
    "    \"\"\"\n",
    "    Tight lower/upper bounds for the logit margin m = z_chg - z_nchg\n",
    "    using a *single* affine bound:\n",
    "       Wm := W[chg] - W[nchg],  bm := b[chg] - b[nchg]\n",
    "       m_lb = conv2d(l, Wm_pos) + conv2d(u, Wm_neg) + bm\n",
    "       m_ub = conv2d(u, Wm_pos) + conv2d(l, Wm_neg) + bm\n",
    "    \"\"\"\n",
    "    W, b = conv.weight, conv.bias\n",
    "    Wm = (W[chg_idx:chg_idx+1] - W[nchg_idx:nchg_idx+1])  # (1, Cin, kH, kW)\n",
    "    bm = None if b is None else (b[chg_idx] - b[nchg_idx]).view(1)\n",
    "\n",
    "    Wm_pos = torch.clamp(Wm, min=0)\n",
    "    Wm_neg = torch.clamp(Wm, max=0)\n",
    "\n",
    "    m_lb = F.conv2d(l, Wm_pos, bias=None,\n",
    "                    stride=conv.stride, padding=conv.padding,\n",
    "                    dilation=conv.dilation, groups=conv.groups) \\\n",
    "         + F.conv2d(u, Wm_neg, bias=None,\n",
    "                    stride=conv.stride, padding=conv.padding,\n",
    "                    dilation=conv.dilation, groups=conv.groups)\n",
    "    m_ub = F.conv2d(u, Wm_pos, bias=None,\n",
    "                    stride=conv.stride, padding=conv.padding,\n",
    "                    dilation=conv.dilation, groups=conv.groups) \\\n",
    "         + F.conv2d(l, Wm_neg, bias=None,\n",
    "                    stride=conv.stride, padding=conv.padding,\n",
    "                    dilation=conv.dilation, groups=conv.groups)\n",
    "\n",
    "    if bm is not None:\n",
    "        bm = bm.view(1, 1, 1, 1)\n",
    "        m_lb = m_lb + bm\n",
    "        m_ub = m_ub + bm\n",
    "\n",
    "    # squeeze channel dim -> (N,H,W)\n",
    "    return m_lb.squeeze(1), m_ub.squeeze(1)\n",
    "\n",
    "def _span_mean_max(l, u):\n",
    "    w = (u - l).abs()\n",
    "    return float(w.mean()), float(w.max())\n",
    "\n",
    "# --- Encoder-Decoder (stop before model.outc) ---\n",
    "def propagate_prelogits_encdecnet(model, z):\n",
    "    x_l, x_u = z.lower, z.upper\n",
    "\n",
    "    # encoder\n",
    "    x1_l, x1_u = interval_forward_falconet(x_l,  x_u,  model.inc)\n",
    "    x2_l, x2_u = interval_forward_falconet(x1_l, x1_u, model.down1)\n",
    "    x3_l, x3_u = interval_forward_falconet(x2_l, x2_u, model.down2)\n",
    "    x4_l, x4_u = interval_forward_falconet(x3_l, x3_u, model.down3)\n",
    "    x5_l, x5_u = interval_forward_falconet(x4_l, x4_u, model.down4)\n",
    "\n",
    "    # helper for the first three up blocks\n",
    "    def up_step(up, xl, xu, sk_l, sk_u):\n",
    "        xl = up.up(xl); xu = up.up(xu)\n",
    "        xl = torch.cat([sk_l, xl], dim=1)\n",
    "        xu = torch.cat([sk_u, xu], dim=1)\n",
    "        return interval_forward_falconet(xl, xu, up.conv)\n",
    "\n",
    "    # decoder up1..up3 as before\n",
    "    x_l, x_u = up_step(model.up1, x5_l, x5_u, x4_l, x4_u)\n",
    "    x_l, x_u = up_step(model.up2, x_l,  x_u,  x3_l, x3_u)\n",
    "    x_l, x_u = up_step(model.up3, x_l,  x_u,  x2_l, x2_u)\n",
    "\n",
    "    # ---- up4 expanded so we can TAP right before its DoubleConv ----\n",
    "    xup_l = model.up4.up(x_l)\n",
    "    xup_u = model.up4.up(x_u)\n",
    "    inp_l = torch.cat([x1_l, xup_l], dim=1)   # <-- input to final DoubleConv\n",
    "    inp_u = torch.cat([x1_u, xup_u], dim=1)\n",
    "\n",
    "    # CROWN-tail tap: start at DoubleConv(input) and end at final 1×1 head\n",
    "    if 'CROWN_TAIL' in globals():\n",
    "        CROWN_TAIL['l0']    = inp_l.detach().clone()\n",
    "        CROWN_TAIL['u0']    = inp_u.detach().clone()\n",
    "        CROWN_TAIL['block'] = getattr(model.up4, 'conv')\n",
    "        CROWN_TAIL['final'] = getattr(model, 'outc', None) or getattr(model, 'final')\n",
    "        if not CROWN_TAIL.get('_encdec_tap_printed', False):\n",
    "            print(\"[tail] EncDec tap @ up4: DoubleConv + final head set.\")\n",
    "            CROWN_TAIL['_encdec_tap_printed'] = True\n",
    "\n",
    "    # run the last DoubleConv to produce pre-logits\n",
    "    x_l, x_u = interval_forward_falconet(inp_l, inp_u, model.up4.conv)\n",
    "    return x_l, x_u   # <--- pre-logits (input to model.outc / model.final)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # --- Encoder-Decoder (stop before model.outc) ---\n",
    "# def propagate_prelogits_encdecnet(model, z):\n",
    "#     x_l, x_u = z.lower, z.upper\n",
    "#     x1_l, x1_u = interval_forward_falconet(x_l, x_u, model.inc)\n",
    "#     x2_l, x2_u = interval_forward_falconet(x1_l, x1_u, model.down1)\n",
    "#     x3_l, x3_u = interval_forward_falconet(x2_l, x2_u, model.down2)\n",
    "#     x4_l, x4_u = interval_forward_falconet(x3_l, x3_u, model.down3)\n",
    "#     x5_l, x5_u = interval_forward_falconet(x4_l, x4_u, model.down4)\n",
    "#     def up_step(up, xl, xu, sk_l, sk_u):\n",
    "#         xl = up.up(xl); xu = up.up(xu)\n",
    "#         xl = torch.cat([sk_l, xl], dim=1)\n",
    "#         xu = torch.cat([sk_u, xu], dim=1)\n",
    "#         return interval_forward_falconet(xl, xu, up.conv)\n",
    "#     x_l, x_u = up_step(model.up1, x5_l, x5_u, x4_l, x4_u)\n",
    "#     x_l, x_u = up_step(model.up2, x_l,  x_u,  x3_l, x3_u)\n",
    "#     x_l, x_u = up_step(model.up3, x_l,  x_u,  x2_l, x2_u)\n",
    "#     x_l, x_u = up_step(model.up4, x_l,  x_u,  x1_l, x1_u)\n",
    "#     return x_l, x_u   # <--- pre-logits; apply model.outc via affine bounds\n",
    "\n",
    "\n",
    "# --- FALCONet + token mixer (stop before model.outc) ---\n",
    "def propagate_prelogits_falconetmha(model, z):\n",
    "    x_l, x_u = z.lower, z.upper\n",
    "\n",
    "    # encoder + mixers\n",
    "    x1_l, x1_u = interval_forward_falconet(x_l, x_u, model.inc)\n",
    "\n",
    "    x2_l, x2_u = interval_forward_falconet(x1_l, x1_u, model.down1)\n",
    "\n",
    "    x3_l, x3_u = interval_forward_falconet(x2_l, x2_u, model.down2)\n",
    "    x3_l, sh3  = flatten_hw(x3_l);  x3_u, _ = flatten_hw(x3_u)\n",
    "    x3_l, x3_u = interval_forward_tokenmixer(x3_l, x3_u, model.token_mixer_2)\n",
    "    x3_l, x3_u = unflatten_hw(x3_l, sh3), unflatten_hw(x3_u, sh3)\n",
    "\n",
    "    x4_l, x4_u = interval_forward_falconet(x3_l, x3_u, model.down3)\n",
    "    x4_l, sh4  = flatten_hw(x4_l);  x4_u, _ = flatten_hw(x4_u)\n",
    "    x4_l, x4_u = interval_forward_tokenmixer(x4_l, x4_u, model.token_mixer_3)\n",
    "    x4_l, x4_u = unflatten_hw(x4_l, sh4), unflatten_hw(x4_u, sh4)\n",
    "\n",
    "    x5_l, x5_u = interval_forward_falconet(x4_l, x4_u, model.down4)\n",
    "    x5_l, sh5  = flatten_hw(x5_l);  x5_u, _ = flatten_hw(x5_u)\n",
    "    x5_l, x5_u = interval_forward_tokenmixer(x5_l, x5_u, model.token_mixer_4)\n",
    "    x5_l, x5_u = unflatten_hw(x5_l, sh5), unflatten_hw(x5_u, sh5)\n",
    "\n",
    "    # decoder helper for first three up blocks (unchanged)\n",
    "    def up_step(up, xl, xu, sk_l, sk_u):\n",
    "        xl = up.up(xl); xu = up.up(xu)                # (uses whatever op up.up is)\n",
    "        xl = torch.cat([sk_l, xl], dim=1)\n",
    "        xu = torch.cat([sk_u, xu], dim=1)\n",
    "        return interval_forward_falconet(xl, xu, up.conv)\n",
    "\n",
    "    # up1..up3 as before\n",
    "    x_l, x_u = up_step(model.up1, x5_l, x5_u, x4_l, x4_u)\n",
    "    x_l, x_u = up_step(model.up2, x_l,  x_u,  x3_l, x3_u)\n",
    "    x_l, x_u = up_step(model.up3, x_l,  x_u,  x2_l, x2_u)\n",
    "\n",
    "    # ---- up4 expanded so we can TAP right before its DoubleConv ----\n",
    "    xup_l = model.up4.up(x_l)\n",
    "    xup_u = model.up4.up(x_u)\n",
    "    inp_l = torch.cat([x1_l, xup_l], dim=1)          # <-- input to last DoubleConv\n",
    "    inp_u = torch.cat([x1_u, xup_u], dim=1)\n",
    "\n",
    "    # CROWN-tail tap: start at DoubleConv(input) and end at the final 1×1 head\n",
    "    if 'CROWN_TAIL' in globals():\n",
    "        CROWN_TAIL['l0']    = inp_l.detach().clone()\n",
    "        CROWN_TAIL['u0']    = inp_u.detach().clone()\n",
    "        CROWN_TAIL['block'] = getattr(model.up4, 'conv')       # last DoubleConv module\n",
    "        CROWN_TAIL['final'] = getattr(model, 'outc', None) or getattr(model, 'final')\n",
    "        # (optional) print to confirm once\n",
    "        if not CROWN_TAIL.get('_falco_tap_printed', False):\n",
    "            print(\"[tail] FALCONet tap @ up4: DoubleConv + final head set.\")\n",
    "            CROWN_TAIL['_falco_tap_printed'] = True\n",
    "\n",
    "    # run the last DoubleConv to produce pre-logits\n",
    "    x_l, x_u = interval_forward_falconet(inp_l, inp_u, model.up4.conv)\n",
    "    return x_l, x_u   # pre-logits (input to model.outc)\n",
    "\n",
    "\n",
    "\n",
    "# # --- FALCONet + token mixer (stop before model.outc) ---\n",
    "# def propagate_prelogits_falconetmha(model, z):\n",
    "#     x_l, x_u = z.lower, z.upper\n",
    "#     x1_l, x1_u = interval_forward_falconet(x_l, x_u, model.inc)\n",
    "#     x2_l, x2_u = interval_forward_falconet(x1_l, x1_u, model.down1)\n",
    "#     x3_l, x3_u = interval_forward_falconet(x2_l, x2_u, model.down2)\n",
    "#     x3_l, sh3 = flatten_hw(x3_l); x3_u, _ = flatten_hw(x3_u)\n",
    "#     x3_l, x3_u = interval_forward_tokenmixer(x3_l, x3_u, model.token_mixer_2)\n",
    "#     x3_l, x3_u = unflatten_hw(x3_l, sh3), unflatten_hw(x3_u, sh3)\n",
    "#     x4_l, x4_u = interval_forward_falconet(x3_l, x3_u, model.down3)\n",
    "#     x4_l, sh4  = flatten_hw(x4_l); x4_u, _ = flatten_hw(x4_u)\n",
    "#     x4_l, x4_u = interval_forward_tokenmixer(x4_l, x4_u, model.token_mixer_3)\n",
    "#     x4_l, x4_u = unflatten_hw(x4_l, sh4), unflatten_hw(x4_u, sh4)\n",
    "#     x5_l, x5_u = interval_forward_falconet(x4_l, x4_u, model.down4)\n",
    "#     x5_l, sh5  = flatten_hw(x5_l); x5_u, _ = flatten_hw(x5_u)\n",
    "#     x5_l, x5_u = interval_forward_tokenmixer(x5_l, x5_u, model.token_mixer_4)\n",
    "#     x5_l, x5_u = unflatten_hw(x5_l, sh5), unflatten_hw(x5_u, sh5)\n",
    "#     # decoder\n",
    "#     def up_step(up, xl, xu, sk_l, sk_u):\n",
    "#         xl = up.up(xl); xu = up.up(xu)\n",
    "#         xl = torch.cat([sk_l, xl], dim=1)\n",
    "#         xu = torch.cat([sk_u, xu], dim=1)\n",
    "#         return interval_forward_falconet(xl, xu, up.conv)\n",
    "#     x_l, x_u = up_step(model.up1, x5_l, x5_u, x4_l, x4_u)\n",
    "#     x_l, x_u = up_step(model.up2, x_l,  x_u,  x3_l, x3_u)\n",
    "#     x_l, x_u = up_step(model.up3, x_l,  x_u,  x2_l, x2_u)\n",
    "#     x_l, x_u = up_step(model.up4, x_l,  x_u,  x1_l, x1_u)\n",
    "#     return x_l, x_u   # <--- pre-logits\n",
    "\n",
    "# --- Attention U-Net (stop before Conv_1x1) ---\n",
    "def propagate_prelogits_attunet(model, z):\n",
    "    x_l, x_u = z.lower, z.upper\n",
    "    x1_l, x1_u = interval_forward_attunet(x_l, x_u, model.Conv1)\n",
    "    print(\"[w] after Conv1 :\", _span_mean_max(x1_l, x1_u))\n",
    "    x2_l = F.max_pool2d(x1_l, 2, 2); x2_u = F.max_pool2d(x1_u, 2, 2)\n",
    "    x2_l, x2_u = interval_forward_attunet(x2_l, x2_u, model.Conv2)\n",
    "    x3_l = F.max_pool2d(x2_l, 2, 2); x3_u = F.max_pool2d(x2_u, 2, 2)\n",
    "    x3_l, x3_u = interval_forward_attunet(x3_l, x3_u, model.Conv3)\n",
    "    print(\"[w] after Conv3 :\", _span_mean_max(x3_l, x3_u))\n",
    "    x4_l = F.max_pool2d(x3_l, 2, 2); x4_u = F.max_pool2d(x3_u, 2, 2)\n",
    "    x4_l, x4_u = interval_forward_attunet(x4_l, x4_u, model.Conv4)\n",
    "    x5_l = F.max_pool2d(x4_l, 2, 2); x5_u = F.max_pool2d(x4_u, 2, 2)\n",
    "    x5_l, x5_u = interval_forward_attunet(x5_l, x5_u, model.Conv5)\n",
    "    print(\"[w] after Conv5 :\", _span_mean_max(x5_l, x5_u))\n",
    "    # decoder + attention\n",
    "    d5_l, d5_u = interval_forward_attunet(x5_l, x5_u, model.Up5)\n",
    "    x4_l_att, x4_u_att = interval_forward_attention_gate(model.Att5, d5_l, d5_u, x4_l, x4_u)\n",
    "    d5_l, d5_u = torch.cat((x4_l_att, d5_l), 1), torch.cat((x4_u_att, d5_u), 1)\n",
    "    d5_l, d5_u = interval_forward_attunet(d5_l, d5_u, model.Up_conv5)\n",
    "    d4_l, d4_u = interval_forward_attunet(d5_l, d5_u, model.Up4)\n",
    "    x3_l_att, x3_u_att = interval_forward_attention_gate(model.Att4, d4_l, d4_u, x3_l, x3_u)\n",
    "    d4_l, d4_u = torch.cat((x3_l_att, d4_l), 1), torch.cat((x3_u_att, d4_u), 1)\n",
    "    d4_l, d4_u = interval_forward_attunet(d4_l, d4_u, model.Up_conv4)\n",
    "    d3_l, d3_u = interval_forward_attunet(d4_l, d4_u, model.Up3)\n",
    "    x2_l_att, x2_u_att = interval_forward_attention_gate(model.Att3, d3_l, d3_u, x2_l, x2_u)\n",
    "    d3_l, d3_u = torch.cat((x2_l_att, d3_l), 1), torch.cat((x2_u_att, d3_u), 1)\n",
    "    d3_l, d3_u = interval_forward_attunet(d3_l, d3_u, model.Up_conv3)\n",
    "    print(\"[w] after Up_conv3:\", _span_mean_max(d3_l, d3_u))   \n",
    "    d2_l, d2_u = interval_forward_attunet(d3_l, d3_u, model.Up2)\n",
    "    x1_l_att, x1_u_att = interval_forward_attention_gate(model.Att2, d2_l, d2_u, x1_l, x1_u)\n",
    "    d2_l, d2_u = torch.cat((x1_l_att, d2_l), 1), torch.cat((x1_u_att, d2_u), 1)\n",
    "\n",
    "    # === tap tail input for CROWN (place this right after you have l,u at Up_conv3 output) ===\n",
    "    if 'CROWN_TAIL' in globals():\n",
    "        CROWN_TAIL['l0']    = d3_l.detach().clone()    # bounds BEFORE Up_conv2\n",
    "        CROWN_TAIL['u0']    = d3_u.detach().clone()\n",
    "        CROWN_TAIL['block'] = model.Up_conv2           # last DoubleConv block\n",
    "        CROWN_TAIL['final'] = _resolve_final_1x1(model)  # <-- FIXED\n",
    "        if not CROWN_TAIL.get('_att_printed', False):\n",
    "            print(\"[tail] AttU-Net tap @ Up_conv2 + final 1×1 set.\")\n",
    "            CROWN_TAIL['_att_printed'] = True\n",
    "    # === end tap ===\n",
    "    \n",
    "    d2_l, d2_u = interval_forward_attunet(d2_l, d2_u, model.Up_conv2)\n",
    "    print(\"[w] after Up_conv2:\", _span_mean_max(d2_l, d2_u))\n",
    "    return d2_l, d2_u  # <--- pre-logits (before model.Conv_1x1)\n",
    "\n",
    "\n",
    "# --- Drop-in patch for \"final logits layer\" so affine_bounds_conv2d accepts containers ---\n",
    "import torch.nn as nn\n",
    "\n",
    "def _unwrap_to_last_conv2d(mod):\n",
    "    # already a conv?\n",
    "    if isinstance(mod, nn.Conv2d):\n",
    "        return mod\n",
    "    # tuple of (W, b)?\n",
    "    if isinstance(mod, tuple) and len(mod) == 2:\n",
    "        W, b = mod\n",
    "        fake = nn.Conv2d(W.shape[1], W.shape[0], kernel_size=1, bias=b is not None)\n",
    "        with torch.no_grad():\n",
    "            fake.weight.copy_(W)\n",
    "            if b is not None:\n",
    "                fake.bias.copy_(b)\n",
    "        return fake\n",
    "    # otherwise: search deepest Conv2d leaf\n",
    "    last = None\n",
    "    # named_modules() includes the module itself; we want the deepest Conv2d\n",
    "    for name, m in mod.named_modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            last = m\n",
    "    assert last is not None, f\"No nn.Conv2d found inside {type(mod)}\"\n",
    "    return last\n",
    "\n",
    "# keep original around\n",
    "_affine_bounds_conv2d_orig = affine_bounds_conv2d\n",
    "\n",
    "def affine_bounds_conv2d(feat_l, feat_u, conv_like):\n",
    "    conv = _unwrap_to_last_conv2d(conv_like)\n",
    "\n",
    "    # sanity: we expect a 1x1, stride 1, no padding, groups=1 for the last affine layer\n",
    "    k = conv.kernel_size if isinstance(conv.kernel_size, tuple) else (conv.kernel_size, conv.kernel_size)\n",
    "    s = conv.stride if isinstance(conv.stride, tuple) else (conv.stride, conv.stride)\n",
    "    p = conv.padding if isinstance(conv.padding, tuple) else (conv.padding, conv.padding)\n",
    "    g = conv.groups\n",
    "    assert k == (1, 1) and s == (1, 1) and p == (0, 0) and g == 1, \\\n",
    "        f\"Expected final 1x1 conv; got k={k}, s={s}, p={p}, groups={g}\"\n",
    "\n",
    "    return _affine_bounds_conv2d_orig(feat_l, feat_u, conv)\n",
    "\n",
    "# --- Drop-in shim: make both affine_*bounds* funcs accept OutConv/Sequential/(W,b) ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def _unwrap_to_last_conv2d(mod):\n",
    "    # Already a Conv2d?\n",
    "    if isinstance(mod, nn.Conv2d):\n",
    "        return mod\n",
    "    # Common wrapper on UNet heads: .conv is the actual 1x1 conv\n",
    "    if hasattr(mod, \"conv\") and isinstance(mod.conv, nn.Conv2d):\n",
    "        return mod.conv\n",
    "    # Passed as raw (weight, bias) tuple?\n",
    "    if isinstance(mod, tuple) and len(mod) == 2 and torch.is_tensor(mod[0]):\n",
    "        W, b = mod\n",
    "        fake = nn.Conv2d(W.shape[1], W.shape[0], kernel_size=1, bias=b is not None)\n",
    "        with torch.no_grad():\n",
    "            fake.weight.copy_(W)\n",
    "            if b is not None:\n",
    "                fake.bias.copy_(b)\n",
    "        return fake\n",
    "    # Otherwise: search deepest Conv2d leaf\n",
    "    last = None\n",
    "    for _, m in mod.named_modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            last = m\n",
    "    assert last is not None, f\"No nn.Conv2d found inside {type(mod)}\"\n",
    "    return last\n",
    "\n",
    "# Keep originals\n",
    "try:\n",
    "    _affine_bounds_conv2d_orig = affine_bounds_conv2d\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    _affine_margin_bounds_conv2d_orig = affine_margin_bounds_conv2d\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "# Wrap: affine_bounds_conv2d\n",
    "def affine_bounds_conv2d(feat_l, feat_u, conv_like):\n",
    "    conv = _unwrap_to_last_conv2d(conv_like)\n",
    "    # sanity: final should be 1x1, stride 1, no padding, groups=1\n",
    "    k = conv.kernel_size if isinstance(conv.kernel_size, tuple) else (conv.kernel_size, conv.kernel_size)\n",
    "    s = conv.stride if isinstance(conv.stride, tuple) else (conv.stride, conv.stride)\n",
    "    p = conv.padding if isinstance(conv.padding, tuple) else (conv.padding, conv.padding)\n",
    "    g = conv.groups\n",
    "    assert k == (1, 1) and s == (1, 1) and p == (0, 0) and g == 1, \\\n",
    "        f\"Expected final 1x1 conv; got k={k}, s={s}, p={p}, groups={g}\"\n",
    "    return _affine_bounds_conv2d_orig(feat_l, feat_u, conv)\n",
    "\n",
    "# Wrap: affine_margin_bounds_conv2d\n",
    "def affine_margin_bounds_conv2d(feat_l, feat_u, conv_like, chg_idx, nchg_idx):\n",
    "    conv = _unwrap_to_last_conv2d(conv_like)\n",
    "    k = conv.kernel_size if isinstance(conv.kernel_size, tuple) else (conv.kernel_size, conv.kernel_size)\n",
    "    s = conv.stride if isinstance(conv.stride, tuple) else (conv.stride, conv.stride)\n",
    "    p = conv.padding if isinstance(conv.padding, tuple) else (conv.padding, conv.padding)\n",
    "    g = conv.groups\n",
    "    assert k == (1, 1) and s == (1, 1) and p == (0, 0) and g == 1, \\\n",
    "        f\"Expected final 1x1 conv; got k={k}, s={s}, p={p}, groups={g}\"\n",
    "    return _affine_margin_bounds_conv2d_orig(feat_l, feat_u, conv, chg_idx, nchg_idx)\n",
    "\n",
    "\n",
    "# CERTIFICATION - structural predicates & plots \n",
    "# ==================================================\n",
    "# 1. CERTIFICATION DIAGNOSTICS FUNCTION\n",
    "# ==================================================\n",
    "def save_maps(lower, upper, model_logits, out_prefix=\"diagnostic\"):\n",
    "    # lower, upper: tensors (1,C,H,W) or (1,H,W) after squeeze/calling .detach().cpu().numpy()\n",
    "    l = lower.squeeze().detach().cpu().numpy()\n",
    "    u = upper.squeeze().detach().cpu().numpy()\n",
    "    m = (l + u) / 2\n",
    "    pred = model_logits.squeeze().detach().cpu().numpy()\n",
    "\n",
    "    # If multi-channel (C>1) pick change channel (e.g., channel 1)\n",
    "    if l.ndim == 3:\n",
    "        l = l[0]\n",
    "        u = u[0]\n",
    "        m = m[0]\n",
    "        pred = pred[0]\n",
    "\n",
    "    np.save(f\"{out_prefix}_lower.npy\", l)\n",
    "    np.save(f\"{out_prefix}_upper.npy\", u)\n",
    "    np.save(f\"{out_prefix}_mid.npy\", m)\n",
    "    np.save(f\"{out_prefix}_pred.npy\", pred)\n",
    "\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,3,1); plt.title(\"lower\"); plt.imshow(l, cmap='viridis'); plt.colorbar()\n",
    "    plt.subplot(1,3,2); plt.title(\"mid\");   plt.imshow(m, cmap='viridis'); plt.colorbar()\n",
    "    plt.subplot(1,3,3); plt.title(\"pred\");  plt.imshow(pred, cmap='viridis'); plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{out_prefix}_maps.png\")\n",
    "    print(\"Saved maps to\", f\"{out_prefix}_maps.png\")\n",
    "\n",
    "def margins_and_hist(lower, tau=0.9, out_prefix=\"margin\"):\n",
    "    l = lower.squeeze().detach().cpu().numpy()\n",
    "    if l.ndim == 3: l = l[0]\n",
    "    margin = l - tau\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.subplot(1,2,1); plt.imshow(margin, cmap='coolwarm', vmin=-0.2, vmax=0.2); plt.colorbar(); plt.title('lower - tau')\n",
    "    plt.subplot(1,2,2); plt.hist(margin.ravel(), bins=100); plt.title('margin histogram')\n",
    "    plt.savefig(out_prefix + \".png\")\n",
    "\n",
    "def run_certification_diagnostics(city, model, mapsave=False, model_type=0, eps=8/255., tau=0.9, k=30, s_min=20, out_prefix=\"diag\", gt_mask=None):\n",
    "    def resample_band_to_shape(band, src_transform, src_crs, target_shape, target_transform, target_crs):\n",
    "        dst = np.zeros(target_shape, dtype=np.float32)\n",
    "        rasterio.warp.reproject(\n",
    "            source=band,\n",
    "            destination=dst,\n",
    "            src_transform=src_transform,\n",
    "            src_crs=src_crs,\n",
    "            dst_transform=target_transform,\n",
    "            dst_crs=target_crs,\n",
    "            resampling=Resampling.bilinear\n",
    "        )\n",
    "        return dst\n",
    "\n",
    "    def load_oscd_patch(imgs_dir):\n",
    "        bands = []\n",
    "        reference_path = [f for f in os.listdir(imgs_dir) if \"B02\" in f][0]\n",
    "        reference_path = os.path.join(imgs_dir, reference_path)\n",
    "\n",
    "        with rasterio.open(reference_path) as ref:\n",
    "            target_shape = (256,256)\n",
    "            target_transform = ref.transform\n",
    "            target_crs = ref.crs\n",
    "\n",
    "        for band_name in BANDS:\n",
    "            candidates = [f for f in os.listdir(imgs_dir) if f.endswith(f\"{band_name}.tif\")]\n",
    "            band_path = os.path.join(imgs_dir, candidates[0])\n",
    "            with rasterio.open(band_path) as src:\n",
    "                band = src.read(1).astype(np.float32) / 10000.0\n",
    "                if src.shape != target_shape:\n",
    "                    band = resample_band_to_shape(band, src.transform, src.crs,\n",
    "                                                  target_shape, target_transform, target_crs)\n",
    "                bands.append(band)\n",
    "        return np.stack(bands, axis=-1)\n",
    "\n",
    "    def pad_to_multiple(x, multiple=16):\n",
    "        _, _, h, w = x.shape\n",
    "        pad_h = (multiple - h % multiple) % multiple\n",
    "        pad_w = (multiple - w % multiple) % multiple\n",
    "        return torch.nn.functional.pad(x, (0, pad_w, 0, pad_h)), (0, pad_w, 0, pad_h)\n",
    "    \n",
    "    # --- RAW tensors (no normalization here) ---\n",
    "    img1 = load_oscd_patch(OSCD_PATH_TOP + city + OSCD_PATH_BOTTOM1)  # H,W,13  RAW\n",
    "    img2 = load_oscd_patch(OSCD_PATH_TOP + city + OSCD_PATH_BOTTOM2)  # H,W,13  RAW\n",
    "    x_np = np.concatenate([img1, img2], axis=-1)                         # H,W,26  RAW\n",
    "    # --- per-image scalar z-score, then concat (matches OSCD inference) ---\n",
    "    C1 = img1.shape[2]  # 13 bands per timestamp\n",
    "\n",
    "    # --- ADD THESE TWO LINES: define x_raw and pad ---\n",
    "    x_raw = torch.tensor(x_np.transpose(2, 0, 1)).unsqueeze(0).float()   # (1,26,H,W) RAW\n",
    "    x_raw, pad = pad_to_multiple(x_raw, multiple=16)\n",
    "    # NEW: per-timestamp scalar stats (match OSCD inference)\n",
    "    mu1  = float(img1.mean());  sig1 = float(img1.std() + 1e-6)\n",
    "    mu2  = float(img2.mean());  sig2 = float(img2.std() + 1e-6)\n",
    "    \n",
    "\n",
    "    \n",
    "    x1 = (x_raw[:, :C1] - mu1) / sig1    # (1, 13, H, W)\n",
    "    x2 = (x_raw[:, C1:] - mu2) / sig2    # (1, 13, H, W)\n",
    "    x  = torch.cat([x1, x2], dim=1)      # (1, 26, H, W)  <-- this is what the model sees\n",
    "    \n",
    "    # per-half epsilon scaling (raw eps divided by each timestamp’s std)\n",
    "    eps1 = float(eps / sig1)\n",
    "    eps2 = float(eps / sig2)\n",
    "    eps_vec = torch.tensor([eps1]*C1 + [eps2]*C1, dtype=x.dtype, device=x.device).view(1, 2*C1, 1, 1)\n",
    "    \n",
    "    # # Zonotope centered at the normalized x\n",
    "    # #zonotope = Zonotope(center=x, epsilon=eps_vec)\n",
    "    # zonotope = Zonotope(center=x, epsilon=float(max(eps1, eps2)))  # scalar ε\n",
    "\n",
    "    # zl, zu = zonotope.lower, zonotope.upper\n",
    "    # print(\"zono lower/upper:\", float(zl.min()), float(zl.max()),\n",
    "    #       float(zu.min()), float(zu.max()))\n",
    "\n",
    "    # Replace Zonotope(...) with a dead-simple interval container\n",
    "    #K = 8.0  # safe z-score clamp (tweakable: 6.0–8.0 are typical)\n",
    "    K = 4.0   # → tighten\n",
    "    x = x.clamp(-K, K)\n",
    "    \n",
    "    eps_scalar = float(max(eps1, eps2))\n",
    "    zl = (x - eps_scalar).clamp(-K, K)\n",
    "    zu = (x + eps_scalar).clamp(-K, K)\n",
    "    \n",
    "    class _SimpleZ:\n",
    "        def __init__(self, l, u):\n",
    "            self.lower = l; self.upper = u; self.center = 0.5*(l+u)\n",
    "    \n",
    "    zonotope = _SimpleZ(zl, zu)\n",
    "\n",
    "    print(\"zono lower/upper:\", \n",
    "          float(zl.min()), float(zl.max()),\n",
    "          float(zu.min()), float(zu.max()))\n",
    "    \n",
    "    # # Bound propagation WITH THE ORIGINAL MODEL (not a wrapper)\n",
    "    # if model_type == 0:\n",
    "    #     lower, upper = propagate_bounds_encdecnet(model, zonotope)\n",
    "    # elif model_type == 1:\n",
    "    #     lower, upper = propagate_bounds_falconetmha_lirpa(model, zonotope)\n",
    "    # else:\n",
    "    #     lower, upper = propagate_bounds_attunet_lirpa(model, zonotope)\n",
    "    # pre-logits\n",
    "    USE_AFFINE_LAST_LAYER = True  # <-- flip this flag on\n",
    "\n",
    "    # --- choose propagation path ---\n",
    "    if USE_AFFINE_LAST_LAYER:\n",
    "        if model_type == 0:\n",
    "            feat_l, feat_u = propagate_prelogits_encdecnet(model, zonotope)\n",
    "            final = model.outc\n",
    "        elif model_type == 1:\n",
    "            feat_l, feat_u = propagate_prelogits_falconetmha(model, zonotope)\n",
    "            final = model.outc\n",
    "        else:\n",
    "            feat_l, feat_u = propagate_prelogits_attunet(model, zonotope)\n",
    "            final = model.Conv_1x1\n",
    "    \n",
    "        # optional: check pre-logit width to confirm we're here\n",
    "        pre_w_mean = (feat_u - feat_l).abs().mean().item()\n",
    "        print(\"[path] affine-last-layer ON  | prelogit width mean:\", f\"{pre_w_mean:.4f}\")\n",
    "    \n",
    "        # exact affine bounds for logits + tight margin\n",
    "        lower, upper = affine_bounds_conv2d(feat_l, feat_u, final)\n",
    "        chg_idx, nchg_idx = 1, 0\n",
    "        margin_lb, margin_ub = affine_margin_bounds_conv2d(feat_l, feat_u, final, chg_idx, nchg_idx)\n",
    "    \n",
    "    else:\n",
    "        # (legacy full IBP path — will blow up at eps>0)\n",
    "        if model_type == 0:\n",
    "            lower, upper = propagate_bounds_encdecnet(model, zonotope)\n",
    "            final = model.outc\n",
    "        elif model_type == 1:\n",
    "            lower, upper = propagate_bounds_falconetmha_lirpa(model, zonotope)\n",
    "            final = model.outc\n",
    "        else:\n",
    "            lower, upper = propagate_bounds_attunet_lirpa(model, zonotope)\n",
    "            final = model.Conv_1x1\n",
    "        # very loose margin from loose logits:\n",
    "        chg_idx, nchg_idx = 1, 0\n",
    "        margin_lb = lower[:, chg_idx] - upper[:, nchg_idx]\n",
    "        margin_ub = upper[:, chg_idx] - lower[:, nchg_idx]\n",
    "    \n",
    "    # --- certified set from tight margin bound ---\n",
    "    mask_cert = (margin_lb > 0)\n",
    "    \n",
    "    # Clean logits through the same normalized x\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "\n",
    "    if mapsave:\n",
    "        save_maps(lower, upper, logits, out_prefix)\n",
    "        margins_and_hist(lower, tau, out_prefix + \"_margin\")\n",
    "\n",
    "        if gt_mask is not None:\n",
    "            plt.figure(figsize=(4,4))\n",
    "            plt.imshow(gt_mask.astype(np.float32), cmap=\"gray\")\n",
    "            plt.title(\"GT Change Mask\")\n",
    "            plt.savefig(out_prefix + \"_gtmask.png\")\n",
    "\n",
    "    # If eps == 0, force exactness (sanity harness & plots stay meaningful)\n",
    "    if float(eps) == 0.0:\n",
    "        lower = logits.clone()\n",
    "        upper = logits.clone()\n",
    "\n",
    "    # scale & range sanity\n",
    "    print(\"σ1, σ2, eps1, eps2:\", sig1, sig2, float(eps/sig1), float(eps/sig2))\n",
    "    print(\"ranges:\",\n",
    "          \"lower\", float(lower.min()), float(lower.max()),\n",
    "          \"upper\", float(upper.min()), float(upper.max()),\n",
    "          \"logits\", float(logits.min()), float(logits.max()))\n",
    "\n",
    "    # for check only\n",
    "    logits_prob = torch.softmax(logits, dim=1)  # or sigmoid if that's your head\n",
    "    print(\"tightness (prob space):\",\n",
    "          torch.abs(lower - logits_prob).mean().item(),\n",
    "          torch.abs(upper - logits_prob).mean().item())\n",
    "\n",
    "    return lower, upper, logits\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# 2. PREDICATE VERIFICATION (CURRENT OR UPDATED VERSION)\n",
    "# ==================================================\n",
    "#Verificaion predicates - non-semantic\n",
    "def predicate_count_based(pred_map, tau=0.5, k=20):\n",
    "    binary = pred_map >= tau\n",
    "    return binary.sum() >= k\n",
    "\n",
    "def predicate_connected_components(pred_map, tau=0.5, min_area=20):\n",
    "    binary = (pred_map >= tau).astype(np.uint8)\n",
    "    labeled, num = ndlabel(binary)\n",
    "    for i in range(1, num + 1):\n",
    "        area = (labeled == i).sum()\n",
    "        if area >= min_area:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def predicate_hybrid(pred_map, tau=0.5, k=20, min_area=10):\n",
    "    binary = (pred_map >= tau).astype(np.uint8)\n",
    "    if binary.sum() < k:\n",
    "        return False\n",
    "    labeled, num = ndlabel(binary)\n",
    "    for i in range(1, num + 1):\n",
    "        area = (labeled == i).sum()\n",
    "        if area >= min_area:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def verify_predicates_diagnostic(lower, upper, tau, k, s_min):\n",
    "    pred_map = lower.squeeze().detach().cpu().numpy()\n",
    "    global_ok = predicate_count_based(pred_map, tau, k)\n",
    "    island_ok = predicate_connected_components(pred_map, tau, s_min)\n",
    "    hybrid_ok = predicate_hybrid(pred_map, tau, k, s_min)\n",
    "    return global_ok, island_ok, hybrid_ok\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# 3. AGGREGATION UTILITY\n",
    "# ==================================================\n",
    "def aggregate_predicate_results(all_results, csv_path=\"predicate_summary.csv\"):\n",
    "    fieldnames = [\"Model\", \"City\", \"Eps\", \"Tau\", \"K\", \"S_min\",\n",
    "                  \"Global_OK\", \"Island_OK\", \"Hybrid_OK\", \"Hybrid_Midpoint_OK\"]\n",
    "    with open(csv_path, \"w\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for row in all_results:\n",
    "            writer.writerow(row)\n",
    "    print(f\"Saved CSV results to {csv_path}\")\n",
    "\n",
    "# === anon v3 utils (non-destructive; unique names) ===\n",
    "import numpy as _np\n",
    "try:\n",
    "    from skimage.measure import label as _sklabel\n",
    "except Exception:\n",
    "    _sklabel = None\n",
    "try:\n",
    "    from scipy.ndimage import label as _ndlabel\n",
    "except Exception:\n",
    "    _ndlabel = None\n",
    "\n",
    "def _to_numpy(x):\n",
    "    try:\n",
    "        import torch\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            return x.detach().cpu().numpy()\n",
    "    except Exception:\n",
    "        pass\n",
    "    return _np.asarray(x)\n",
    "\n",
    "# === anon v3: margin-based certification for change detection ===\n",
    "def anon_choose_change_channel(clean_logits, gt_mask):\n",
    "    z = _to_numpy(clean_logits)\n",
    "    if z.ndim == 2:\n",
    "        raise ValueError(\"Single-channel head detected. Prefer two-logit head for sound margins.\")\n",
    "    C,H,W = z.shape\n",
    "    exps = _np.exp(z - z.max(axis=0, keepdims=True))\n",
    "    probs = exps / exps.sum(axis=0, keepdims=True)\n",
    "    gt = (_to_numpy(gt_mask) > 0).astype('uint8')\n",
    "    def iou(mask):\n",
    "        inter = int((mask & gt).sum()); union = int((mask | gt).sum())\n",
    "        return inter / max(union, 1)\n",
    "    if C == 2:\n",
    "        cands = [(0,1), (1,0)]\n",
    "    else:\n",
    "        top = int(_np.argmax(probs.mean((1,2))))\n",
    "        cands = [(top, i) for i in range(C) if i != top]\n",
    "    best = max(cands, key=lambda ab: iou((probs[ab[0]]>0.5).astype('uint8')))\n",
    "    return best\n",
    "\n",
    "def anon_certified_change_mask(lower, upper, chg_idx=0, nchg_idx=1):\n",
    "    l = _to_numpy(lower); u = _to_numpy(upper)\n",
    "    if l.ndim != 3 or u.ndim != 3:\n",
    "        raise ValueError(f\"expected 3D bounds (C,H,W), got {l.shape} and {u.shape}\")\n",
    "    lchg = l[chg_idx]; unchg = u[nchg_idx]\n",
    "    margin_lb = lchg - unchg\n",
    "    mask = (margin_lb > 0).astype('uint8')\n",
    "    return mask, margin_lb\n",
    "\n",
    "# === anon v3: predicates (keys match your summary schema) ===\n",
    "import json as _json\n",
    "\n",
    "def anon_predicate_overlap(mask_cert, clean_pred, rho=0.3):\n",
    "    clean = (_to_numpy(clean_pred)>0).astype('uint8')\n",
    "    denom = max(int(clean.sum()), 1)\n",
    "    overlap = int((mask_cert & clean).sum()) / denom\n",
    "    return (overlap >= rho), float(overlap)\n",
    "\n",
    "def anon_predicate_fp(mask_cert, gt_mask, gamma=0.3):\n",
    "    gt = (_to_numpy(gt_mask)>0).astype('uint8')\n",
    "    size = int(mask_cert.sum())\n",
    "    if size == 0:\n",
    "        return True, 0.0\n",
    "    fp = int(((mask_cert==1) & (gt==0)).sum()) / float(size)\n",
    "    return (fp <= gamma), float(fp)\n",
    "\n",
    "def anon_predicate_pattern(mask_cert, s_min=16, connectivity=1):\n",
    "    if int(mask_cert.sum()) == 0:\n",
    "        return True, {\"num\": 0, \"sizes\": []}\n",
    "    if _sklabel is not None:\n",
    "        lbl, num = _sklabel(mask_cert, connectivity=connectivity, return_num=True)\n",
    "    elif _ndlabel is not None:\n",
    "        lbl, num = _ndlabel(mask_cert, structure=None)\n",
    "    else:\n",
    "        raise RuntimeError(\"No connected-components function available (skimage/scipy missing)\")\n",
    "    sizes = [int((lbl==i).sum()) for i in range(1, num+1)]\n",
    "    ok = all(sz >= s_min for sz in sizes)\n",
    "    return ok, {\"num\": int(num), \"sizes\": sizes}\n",
    "\n",
    "def anon_verify_predicates_semantic(lower, upper, clean_logits, clean_pred, gt_mask,\n",
    "                                    rho=0.3, gamma=0.3, s_min=16,\n",
    "                                    chg_idx=None, nchg_idx=None):\n",
    "    if chg_idx is None or nchg_idx is None:\n",
    "        chg_idx, nchg_idx = anon_choose_change_channel(clean_logits, gt_mask)\n",
    "    mask_cert, margin_lb = anon_certified_change_mask(lower, upper, chg_idx, nchg_idx)\n",
    "    ol_ok, ol_val = anon_predicate_overlap(mask_cert, clean_pred, rho=rho)\n",
    "    fp_ok, fp_val = anon_predicate_fp(mask_cert, gt_mask, gamma=gamma)\n",
    "    patt_ok, patt_stats = anon_predicate_pattern(mask_cert, s_min=s_min, connectivity=1)\n",
    "    strict = bool(ol_ok and fp_ok and patt_ok)\n",
    "    patt_json = _json.dumps(patt_stats, separators=(',',':'))\n",
    "    res = {\n",
    "        \"Certified_strict\": int(strict),\n",
    "        \"overlap_ok\": int(ol_ok), \"overlap_ratio\": float(ol_val),\n",
    "        \"fp_ok\": int(fp_ok), \"fp_ratio\": float(fp_val),\n",
    "        \"min_margin\": float(margin_lb.min()) if margin_lb.size>0 else 0.0,\n",
    "        \"pattern_ok\": int(patt_ok), \"pattern_stats\": patt_json,\n",
    "        \"certified_strict\": int(strict),\n",
    "        \"Overlap_ok\": int(ol_ok), \"Overlap_ratio\": float(ol_val),\n",
    "        \"Fp_ok\": int(fp_ok), \"Fp_ratio\": float(fp_val),\n",
    "        \"Min_margin\": float(margin_lb.min()) if margin_lb.size>0 else 0.0,\n",
    "        \"Pattern_ok\": int(patt_ok), \"Pattern_stats\": patt_json,\n",
    "        \"chg_idx\": int(chg_idx), \"nchg_idx\": int(nchg_idx),\n",
    "    }\n",
    "    return res, mask_cert, margin_lb\n",
    "\n",
    "# === anon v3: CSV writer aligned to your schema ===\n",
    "import csv, os\n",
    "\n",
    "def anon_write_row(csv_path, row, header=None):\n",
    "    default_header = [\n",
    "        \"Model\",\"City\",\"Eps\",\"Tau\",\"K\",\"S_min\",\n",
    "        \"Certified_strict\",\n",
    "        \"Overlap_ok\",\"Overlap_ratio\",\n",
    "        \"Fp_ok\",\"Fp_ratio\",\n",
    "        \"Min_margin\",\n",
    "        \"Pattern_ok\",\"Pattern_stats\",\n",
    "        \"chg_idx\",\"nchg_idx\"\n",
    "    ]\n",
    "    header = header or default_header\n",
    "    exists = os.path.exists(csv_path)\n",
    "    with open(csv_path, \"a\", newline=\"\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=header)\n",
    "        if not exists:\n",
    "            w.writeheader()\n",
    "        w.writerow(row)\n",
    "\n",
    "# channel choice \n",
    "# 1) helper: to numpy\n",
    "def _to_numpy(x):\n",
    "    try:\n",
    "        import torch\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            return x.detach().cpu().numpy()\n",
    "    except Exception:\n",
    "        pass\n",
    "    return _np.asarray(x)\n",
    " \n",
    "def anon_choose_change_channel(clean_logits, gt_mask):\n",
    "    z = _to_numpy(clean_logits)\n",
    "    if z.ndim == 2:\n",
    "        raise ValueError(\"Single-channel head; two-logit head recommended.\")\n",
    "    C, H, W = z.shape\n",
    "    exps = _np.exp(z - z.max(axis=0, keepdims=True))\n",
    "    probs = exps / exps.sum(axis=0, keepdims=True)\n",
    "    gt = (_to_numpy(gt_mask) > 0).astype('uint8')\n",
    "    def iou(mask):\n",
    "        inter = int((mask & gt).sum()); union = int((mask | gt).sum())\n",
    "        return inter / max(union, 1)\n",
    "    if C == 2:\n",
    "        cands = [(0,1), (1,0)]\n",
    "    else:\n",
    "        top = int(_np.argmax(probs.mean((1,2))))\n",
    "        cands = [(top, i) for i in range(C) if i != top]\n",
    "    best = max(cands, key=lambda ab: iou((probs[ab[0]] > 0.5).astype('uint8')))\n",
    "    return best\n",
    " \n",
    "# 3) helper: logits -> clean_pred for the chosen change channel\n",
    "def logits_to_clean_pred(clean_logits, chg_idx, thresh=0.5):\n",
    "    z = _to_numpy(clean_logits)\n",
    "    exps = _np.exp(z - z.max(axis=0, keepdims=True))\n",
    "    probs = exps / exps.sum(axis=0, keepdims=True)\n",
    "    return (probs[chg_idx] > thresh).astype('uint8')\n",
    " \n",
    "\n",
    " \n",
    "# 5) NEW wrapper with the SAME name: now returns (lower, upper, clean_logits, clean_pred, gt_mask)\n",
    "def rcd(model, model_type, city, eps):\n",
    "    # call your original\n",
    "    lower, upper, clean_logits = run_certification_diagnostics(model=model, model_type=model_type, city=city, eps=eps)\n",
    "    lower, upper, clean_logits = lower.squeeze(0), upper.squeeze(0), clean_logits.squeeze(0)\n",
    "\n",
    "    H, W = clean_logits.shape[-2], clean_logits.shape[-1]\n",
    " \n",
    "    # fetch GT mask from your dict (raise clearly if missing)\n",
    "    if city not in GT_MASKS:\n",
    "        raise KeyError(f\"GT_MASKS['{city}'] not set. Please do: GT_MASKS['{city}']=<HxW binary array>\")\n",
    " \n",
    "    gt_mask = GT_MASKS[city]\n",
    "\n",
    "    gt_mask = np.asarray(gt_mask)\n",
    "    if gt_mask.ndim == 3:\n",
    "        gt_mask = gt_mask.squeeze()\n",
    "\n",
    "    if gt_mask.shape != (H,W):\n",
    "        gt_mask = (np.array(Image.fromarray((gt_mask > 0).astype('uint8') * 255).resize((W,H), resample=Image.NEAREST)) > 0).astype('uint8')\n",
    "    else:\n",
    "        gt_mask = (gt_mask > 0).astype('uint8')\n",
    "        \n",
    " \n",
    "    # select channels consistently and build clean_pred\n",
    "    chg_idx, nchg_idx = anon_choose_change_channel(clean_logits, gt_mask)\n",
    "    clean_pred = logits_to_clean_pred(clean_logits, chg_idx, thresh=0.5)\n",
    " \n",
    "    return lower, upper, clean_logits, clean_pred, gt_mask\n",
    "\n",
    "# === anon v3: Sanity suite (eps=0 and 2/255) ===\n",
    "def sanity_suite_one_tile(model, model_type, city, eps_list=(0.0, 2/255), rho=0.2, gamma=0.3, s_min=16,\n",
    "                          csv_path=\"predicate_summary_semantic_v3.csv\"):\n",
    "    print(f\"[sanity] model={model_type} city={city} eps={eps_list} rho={rho} gamma={gamma} s_min={s_min}\")\n",
    "    for eps in eps_list:\n",
    "        out = rcd(model=model, city=city, model_type=model_type , eps=eps)\n",
    "        if not (isinstance(out, (list, tuple)) and len(out) == 5):\n",
    "            raise ValueError(\"run_certification_diagnostics must return (lower, upper, clean_logits, clean_pred, gt_mask)\")\n",
    "        lower, upper, clean_logits, clean_pred, gt_mask = out\n",
    "        results, mask_cert, margin_lb = anon_verify_predicates_semantic(\n",
    "            lower, upper, clean_logits, clean_pred, gt_mask,\n",
    "            rho=rho, gamma=gamma, s_min=s_min\n",
    "        )\n",
    "        print(f\"  eps={eps:.5f} -> overlap={results['Overlap_ratio']:.3f}, fp={results['Fp_ratio']:.3f}, \"\n",
    "              f\"pattern_ok={results['Pattern_ok']}, strict={results['Certified_strict']}, \"\n",
    "              f\"min_margin={results['Min_margin']:.4f} (chg,nchg)=({results['chg_idx']},{results['nchg_idx']})\")\n",
    "        row = {\n",
    "            \"Model\": str(model), \"City\": str(city), \"Eps\": eps,\n",
    "            \"Tau\": \"-\", \"K\": \"-\", \"S_min\": s_min,\n",
    "            \"Certified_strict\": results[\"Certified_strict\"],\n",
    "            \"Overlap_ok\": results[\"Overlap_ok\"], \"Overlap_ratio\": results[\"Overlap_ratio\"],\n",
    "            \"Fp_ok\": results[\"Fp_ok\"], \"Fp_ratio\": results[\"Fp_ratio\"],\n",
    "            \"Min_margin\": results[\"Min_margin\"],\n",
    "            \"Pattern_ok\": results[\"Pattern_ok\"], \"Pattern_stats\": results[\"Pattern_stats\"],\n",
    "            \"chg_idx\": results[\"chg_idx\"], \"nchg_idx\": results[\"nchg_idx\"],\n",
    "        }\n",
    "        anon_write_row(csv_path, row)\n",
    "    print(f\"[sanity] wrote -> {csv_path}\")\n",
    "\n",
    "# === anon v3: Normalization check ===\n",
    "def anon_debug_normalization(lower, upper, clean_logits, eps):\n",
    "    l = _to_numpy(lower); u = _to_numpy(upper); z = _to_numpy(clean_logits)\n",
    "    print(f\"[norm] eps={eps} -> lower/upper shapes={l.shape}/{u.shape}, clean_logits={z.shape}\")\n",
    "    if eps == 0.0:\n",
    "        import numpy as _np\n",
    "        diff_l = _np.abs(l - z).mean()\n",
    "        diff_u = _np.abs(u - z).mean()\n",
    "        print(f\"[norm] eps=0 diffs -> mean|lower-clean|={diff_l:.4g}, mean|upper-clean|={diff_u:.4g}\")\n",
    "        if diff_l > 1e-3 or diff_u > 1e-3:\n",
    "            print(\"[norm][WARN] bounds not tight at eps=0; check normalization and verification graph.\")\n",
    "\n",
    "\n",
    "# channel choice \n",
    "# 1) helper: to numpy\n",
    "def _to_numpy(x):\n",
    "    try:\n",
    "        import torch\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            return x.detach().cpu().numpy()\n",
    "    except Exception:\n",
    "        pass\n",
    "    return _np.asarray(x)\n",
    " \n",
    "def anon_choose_change_channel(clean_logits, gt_mask):\n",
    "    z = _to_numpy(clean_logits)\n",
    "    if z.ndim == 2:\n",
    "        raise ValueError(\"Single-channel head; two-logit head recommended.\")\n",
    "    C, H, W = z.shape\n",
    "    exps = _np.exp(z - z.max(axis=0, keepdims=True))\n",
    "    probs = exps / exps.sum(axis=0, keepdims=True)\n",
    "    gt = (_to_numpy(gt_mask) > 0).astype('uint8')\n",
    "    def iou(mask):\n",
    "        inter = int((mask & gt).sum()); union = int((mask | gt).sum())\n",
    "        return inter / max(union, 1)\n",
    "    if C == 2:\n",
    "        cands = [(0,1), (1,0)]\n",
    "    else:\n",
    "        top = int(_np.argmax(probs.mean((1,2))))\n",
    "        cands = [(top, i) for i in range(C) if i != top]\n",
    "    best = max(cands, key=lambda ab: iou((probs[ab[0]] > 0.5).astype('uint8')))\n",
    "    return best\n",
    " \n",
    "# 3) helper: logits -> clean_pred for the chosen change channel\n",
    "def logits_to_clean_pred(clean_logits, chg_idx, thresh=0.5):\n",
    "    z = _to_numpy(clean_logits)\n",
    "    exps = _np.exp(z - z.max(axis=0, keepdims=True))\n",
    "    probs = exps / exps.sum(axis=0, keepdims=True)\n",
    "    return (probs[chg_idx] > thresh).astype('uint8')\n",
    " \n",
    "\n",
    " \n",
    "# 5) NEW wrapper with the SAME name: now returns (lower, upper, clean_logits, clean_pred, gt_mask)\n",
    "def rcd(model, model_type, city, eps):\n",
    "    # call your original\n",
    "    lower, upper, clean_logits = run_certification_diagnostics(model=model, model_type=model_type, city=city, eps=eps)\n",
    "    lower, upper, clean_logits = lower.squeeze(0), upper.squeeze(0), clean_logits.squeeze(0)\n",
    "\n",
    "    H, W = clean_logits.shape[-2], clean_logits.shape[-1]\n",
    " \n",
    "    # fetch GT mask from your dict (raise clearly if missing)\n",
    "    if city not in GT_MASKS:\n",
    "        raise KeyError(f\"GT_MASKS['{city}'] not set. Please do: GT_MASKS['{city}']=<HxW binary array>\")\n",
    " \n",
    "    gt_mask = GT_MASKS[city]\n",
    "\n",
    "    gt_mask = np.asarray(gt_mask)\n",
    "    if gt_mask.ndim == 3:\n",
    "        gt_mask = gt_mask.squeeze()\n",
    "\n",
    "    if gt_mask.shape != (H,W):\n",
    "        gt_mask = (np.array(Image.fromarray((gt_mask > 0).astype('uint8') * 255).resize((W,H), resample=Image.NEAREST)) > 0).astype('uint8')\n",
    "    else:\n",
    "        gt_mask = (gt_mask > 0).astype('uint8')\n",
    "        \n",
    " \n",
    "    # select channels consistently and build clean_pred\n",
    "    chg_idx, nchg_idx = anon_choose_change_channel(clean_logits, gt_mask)\n",
    "    clean_pred = logits_to_clean_pred(clean_logits, chg_idx, thresh=0.5)\n",
    " \n",
    "    return lower, upper, clean_logits, clean_pred, gt_mask\n",
    "\n",
    "# === SHIM: stop recursion in affine_bounds_conv2d & friends, no edits elsewhere ===\n",
    "import torch.nn as nn\n",
    "import types\n",
    "\n",
    "# ---- 1) Locate the \"true originals\" from whatever state the notebook is in ----\n",
    "AB_ORIG = None\n",
    "MB_ORIG = None\n",
    "\n",
    "# Common places we've seen the originals stashed by earlier patches:\n",
    "if 'AFFINE_BOUNDS_CONV2D_ORIG' in globals() and callable(globals()['AFFINE_BOUNDS_CONV2D_ORIG']):\n",
    "    AB_ORIG = globals()['AFFINE_BOUNDS_CONV2D_ORIG']\n",
    "elif '_affine_bounds_conv2d_orig' in globals() and callable(globals()['_affine_bounds_conv2d_orig']):\n",
    "    AB_ORIG = globals()['_affine_bounds_conv2d_orig']\n",
    "elif 'affine_bounds_conv2d' in globals() and callable(globals()['affine_bounds_conv2d']):\n",
    "    # Best effort: assume current is original (ok if you haven't patched before).\n",
    "    AB_ORIG = globals()['affine_bounds_conv2d']\n",
    "\n",
    "if 'AFFINE_MARGIN_CONV2D_ORIG' in globals() and callable(globals()['AFFINE_MARGIN_CONV2D_ORIG']):\n",
    "    MB_ORIG = globals()['AFFINE_MARGIN_CONV2D_ORIG']\n",
    "elif '_affine_margin_bounds_conv2d_orig' in globals() and callable(globals()['_affine_margin_bounds_conv2d_orig']):\n",
    "    MB_ORIG = globals()['_affine_margin_bounds_conv2d_orig']\n",
    "elif 'affine_margin_bounds_conv2d' in globals() and callable(globals()['affine_margin_bounds_conv2d']):\n",
    "    MB_ORIG = globals()['affine_margin_bounds_conv2d']  # ok if you don't use margin\n",
    "\n",
    "if AB_ORIG is None:\n",
    "    raise RuntimeError(\"Could not locate the original affine_bounds_conv2d in this notebook state.\")\n",
    "\n",
    "# ---- 2) Robust unwrapping: get the actual Conv2d even if wrapped (OutConv, Sequential, etc.) ----\n",
    "def _unwrap_last_conv2d(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        return m\n",
    "    # Try common single-attr wrappers (e.g., U-Net heads)\n",
    "    for attr in ('conv', 'final', 'out_conv', 'out', 'project', 'proj'):\n",
    "        if hasattr(m, attr):\n",
    "            sub = getattr(m, attr)\n",
    "            c = _unwrap_last_conv2d(sub)\n",
    "            if c is not None:\n",
    "                return c\n",
    "    # Walk children from the end for Sequential / nested modules\n",
    "    if hasattr(m, 'children'):\n",
    "        for child in reversed(list(m.children())):\n",
    "            c = _unwrap_last_conv2d(child)\n",
    "            if c is not None:\n",
    "                return c\n",
    "    return None\n",
    "\n",
    "# ---- 3) Safe versions that delegate to the originals on a real Conv2d ----\n",
    "def affine_bounds_conv2d_safe(feat_l, feat_u, conv_like):\n",
    "    conv = _unwrap_last_conv2d(conv_like)\n",
    "    if conv is None:\n",
    "        raise TypeError(f\"Expected Conv2d or wrapper; got {type(conv_like).__name__}\")\n",
    "    return AB_ORIG(feat_l, feat_u, conv)\n",
    "\n",
    "def affine_margin_bounds_conv2d_safe(feat_l, feat_u, conv_like, pos_idx, neg_idx):\n",
    "    if MB_ORIG is None:\n",
    "        raise RuntimeError(\"Margin bounds function not available in this notebook.\")\n",
    "    conv = _unwrap_last_conv2d(conv_like)\n",
    "    if conv is None:\n",
    "        raise TypeError(f\"Expected Conv2d or wrapper; got {type(conv_like).__name__}\")\n",
    "    return MB_ORIG(feat_l, feat_u, conv, pos_idx, neg_idx)\n",
    "\n",
    "# ---- 4) Wrap run_certification_diagnostics so it uses the *safe* functions only during its run ----\n",
    "if 'run_certification_diagnostics' not in globals() or not callable(run_certification_diagnostics):\n",
    "    raise RuntimeError(\"run_certification_diagnostics not found; run the cell that defines it first.\")\n",
    "\n",
    "_RCD_ORIG = run_certification_diagnostics  # capture the real one\n",
    "\n",
    "def run_certification_diagnostics(*args, **kwargs):\n",
    "    # Temporarily rebind the global names so any internal calls use the safe versions\n",
    "    g = globals()\n",
    "    saved_ab = g.get('affine_bounds_conv2d', None)\n",
    "    saved_mb = g.get('affine_margin_bounds_conv2d', None)\n",
    "    g['affine_bounds_conv2d'] = affine_bounds_conv2d_safe\n",
    "    if MB_ORIG is not None:\n",
    "        g['affine_margin_bounds_conv2d'] = affine_margin_bounds_conv2d_safe\n",
    "    try:\n",
    "        return _RCD_ORIG(*args, **kwargs)\n",
    "    finally:\n",
    "        # restore previous bindings\n",
    "        if saved_ab is not None:\n",
    "            g['affine_bounds_conv2d'] = saved_ab\n",
    "        if saved_mb is not None and MB_ORIG is not None:\n",
    "            g['affine_margin_bounds_conv2d'] = saved_mb\n",
    "\n",
    "print(\"[shim] installed: safe affine bounds + RCD shim; recursion should be gone.\")\n",
    "# === FINAL BINDINGS PATCH (v9) ===\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "# --- 1) Provide oscd_paths() so GT loader works even if older cells expect it ---\n",
    "def oscd_paths(city: str):\n",
    "    # Use the legacy global path constants already in your notebook\n",
    "    # (If they aren't defined for some reason, set them before calling run_sweep)\n",
    "    top = OSCD_PATH_TOP\n",
    "    imgs1 = top + city + OSCD_PATH_BOTTOM1\n",
    "    imgs2 = top + city + OSCD_PATH_BOTTOM2\n",
    "    cm    = top + city + OSCD_PATH_CM\n",
    "    return imgs1, imgs2, cm\n",
    "\n",
    "# --- 2) Helper to unwrap to the last real Conv2d (handles OutConv/Sequential/etc.) ---\n",
    "def _last_conv2d(module: nn.Module):\n",
    "    last = None\n",
    "    for m in module.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            last = m\n",
    "    if last is None:\n",
    "        raise RuntimeError(\"Could not find a Conv2d inside final module.\")\n",
    "    return last\n",
    "\n",
    "# --- 3) General (any k/s/p/dilation/groups) exact interval bounds for the FINAL Conv2d ---\n",
    "def _conv2d_interval_bounds(xL, xU, W, b, stride, padding, dilation, groups):\n",
    "    # Standard interval arithmetic: split weight into positive/negative parts\n",
    "    device = xL.device\n",
    "    Wpos = torch.clamp(W, min=0).to(device=device)\n",
    "    Wneg = torch.clamp(W, max=0).to(device=device)\n",
    "    yL = F.conv2d(xL, Wpos, None, stride, padding, dilation, groups) + \\\n",
    "         F.conv2d(xU, Wneg, None, stride, padding, dilation, groups)\n",
    "    yU = F.conv2d(xU, Wpos, None, stride, padding, dilation, groups) + \\\n",
    "         F.conv2d(xL, Wneg, None, stride, padding, dilation, groups)\n",
    "    if b is not None:\n",
    "        b = b.to(device=device).view(1, -1, 1, 1)\n",
    "        yL = yL + b\n",
    "        yU = yU + b\n",
    "    return yL, yU\n",
    "\n",
    "def affine_bounds_conv2d_final(feat_l, feat_u, final_module):\n",
    "    conv = _last_conv2d(final_module)\n",
    "    yL, yU = _conv2d_interval_bounds(\n",
    "        feat_l, feat_u, conv.weight, conv.bias,\n",
    "        conv.stride, conv.padding, conv.dilation, conv.groups\n",
    "    )\n",
    "    print(\"[bind] using non-recursive final Conv2d bounds\")\n",
    "    return yL, yU\n",
    "\n",
    "# --- 4) Margin bounds for (logit[c] - logit[nc]) at the FINAL Conv2d ---\n",
    "def affine_margin_bounds_conv2d_final(feat_l, feat_u, final_module, chg_idx, nchg_idx):\n",
    "    conv = _last_conv2d(final_module)\n",
    "    device = feat_l.device\n",
    "    # Build the single-channel difference kernel: Wd = W[c] - W[nc]\n",
    "    Wc  = conv.weight[int(chg_idx)].unsqueeze(0)\n",
    "    Wnc = conv.weight[int(nchg_idx)].unsqueeze(0)\n",
    "    Wd = (Wc - Wnc).to(device=device)\n",
    "    bd = None\n",
    "    if conv.bias is not None:\n",
    "        bd = (conv.bias[int(chg_idx)] - conv.bias[int(nchg_idx)]).to(device=device)\n",
    "    yL, yU = _conv2d_interval_bounds(\n",
    "        feat_l, feat_u, Wd, bd,\n",
    "        conv.stride, conv.padding, conv.dilation, conv.groups\n",
    "    )\n",
    "    print(\"[bind] using non-recursive final Conv2d margin bounds\")\n",
    "    return yL, yU\n",
    "\n",
    "# --- 5) HARD REBIND: point *all* names the verifier might call to these safe versions ---\n",
    "globals()['affine_bounds_conv2d'] = affine_bounds_conv2d_final\n",
    "globals()['affine_margin_bounds_conv2d'] = affine_margin_bounds_conv2d_final\n",
    "\n",
    "# Some notebooks wrap & re-alias via \"*_safe\" names — clobber them, too:\n",
    "globals()['affine_bounds_conv2d_safe'] = affine_bounds_conv2d_final\n",
    "globals()['affine_margin_bounds_conv2d_safe'] = affine_margin_bounds_conv2d_final\n",
    "\n",
    "# Optional: tiny sanity to show we really overrode them\n",
    "print(\"affine_bounds_conv2d ->\", affine_bounds_conv2d.__name__)\n",
    "print(\"affine_margin_bounds_conv2d ->\", affine_margin_bounds_conv2d.__name__)\n",
    "print(\"[final-patch] oscd_paths + final Conv2d bound fns installed.\")\n",
    "# === CROWN-TAIL (margin) override — drop-in, no extra deps ===\n",
    "# Put this cell right after your \"final-conv patch\" cell.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- keep a handle to whatever margin-bounds function you have now (for fallback) ---\n",
    "_AFFINE_MARGIN_ORIG = globals().get('affine_margin_bounds_conv2d', None)\n",
    "\n",
    "_EPS = 1e-12\n",
    "\n",
    "# ---- helpers: flatten the last block into a simple forward-ordered layer list ----\n",
    "def _flatten_layers(mod: nn.Module):\n",
    "    out = []\n",
    "    def walk(m):\n",
    "        # atomic ops we support\n",
    "        if isinstance(m, (nn.Conv2d, nn.BatchNorm2d, nn.ReLU)):\n",
    "            out.append(m)\n",
    "        else:\n",
    "            kids = list(m.children())\n",
    "            if kids:\n",
    "                for k in kids:\n",
    "                    walk(k)\n",
    "            else:\n",
    "                # passthrough for unknown leafs (e.g., Dropout, Identity)\n",
    "                out.append(m)\n",
    "    walk(mod)\n",
    "    return out\n",
    "\n",
    "# ---- interval forward (IBP) through the block, record pre-activation (l,u) at each ReLU ----\n",
    "def _ibp_collect_relu_bounds(l, u, layers):\n",
    "    relu_lu = []  # in forward order; each item is (l_pre, u_pre) for that ReLU\n",
    "    for m in layers:\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            W = m.weight\n",
    "            b = m.bias\n",
    "            Wpos = torch.clamp(W, min=0)\n",
    "            Wneg = torch.clamp(W, max=0)\n",
    "            l = F.conv2d(l, Wpos, None, m.stride, m.padding, m.dilation, m.groups) + \\\n",
    "                F.conv2d(u, Wneg, None, m.stride, m.padding, m.dilation, m.groups)\n",
    "            u = F.conv2d(u, Wpos, None, m.stride, m.padding, m.dilation, m.groups) + \\\n",
    "                F.conv2d(l, Wneg, None, m.stride, m.padding, m.dilation, m.groups)\n",
    "            if b is not None:\n",
    "                b = b.view(1, -1, 1, 1)\n",
    "                l = l + b\n",
    "                u = u + b\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            # eval BN: y = s * x + q\n",
    "            assert not m.training, \"Expected BatchNorm in eval() for verification\"\n",
    "            s = (m.weight / torch.sqrt(m.running_var + m.eps)).view(1, -1, 1, 1)\n",
    "            q = (m.bias - m.running_mean * (m.weight / torch.sqrt(m.running_var + m.eps))).view(1, -1, 1, 1)\n",
    "            spos = torch.clamp(s, min=0)\n",
    "            sneg = torch.clamp(s, max=0)\n",
    "            l = spos * l + sneg * u + q\n",
    "            u = spos * u + sneg * l + q\n",
    "        elif isinstance(m, nn.ReLU):\n",
    "            # record pre-activation bounds for this ReLU, then push IBP through it\n",
    "            relu_lu.append((l.clone(), u.clone()))\n",
    "            l = torch.clamp(l, min=0)\n",
    "            u = torch.clamp(u, min=0)\n",
    "        else:\n",
    "            # unknown op: treat as identity for IBP (conservative)\n",
    "            l = l\n",
    "            u = u\n",
    "    return relu_lu\n",
    "\n",
    "# ---- backprop the linear form through the block with α-CROWN relaxations on ReLUs ----\n",
    "def _backprop_linear_form(C, t, layers, relu_lu, mode: str):\n",
    "    \"\"\"\n",
    "    C:  (1, C_out, H, W) coefficient map on current tensor\n",
    "    t:  (1, 1, H, W)     accumulated constant map\n",
    "    mode: 'upper' or 'lower'\n",
    "    \"\"\"\n",
    "    # traverse in reverse; consume ReLU bounds from the end\n",
    "    relu_idx = len(relu_lu) - 1\n",
    "    for m in reversed(layers):\n",
    "        if isinstance(m, nn.ReLU):\n",
    "            L, U = relu_lu[relu_idx]\n",
    "            relu_idx -= 1\n",
    "            # masks\n",
    "            cross = (L < 0) & (U > 0)\n",
    "            pos    = (C >= 0)\n",
    "            # α for crossing (safe if divide-by-zero → 1)\n",
    "            alpha = torch.where(cross, U / (U - L + _EPS), torch.ones_like(U))\n",
    "            # force α=0 when U<=0; α=1 when L>=0\n",
    "            alpha = torch.where(U <= 0, torch.zeros_like(alpha), torch.where(L >= 0, torch.ones_like(alpha), alpha))\n",
    "\n",
    "            if mode == 'upper':\n",
    "                # C>=0 → use upper line; C<0 → y minimal (=0)\n",
    "                C_use  = pos * C\n",
    "                t = t + (C_use * (-alpha * L)).sum(dim=1, keepdim=True)\n",
    "                C = C_use * alpha\n",
    "                # entries with U<=0 wipe out C; with L>=0 alpha==1 handled above\n",
    "                C = torch.where((U <= 0), torch.zeros_like(C), C)\n",
    "            else:  # 'lower'\n",
    "                # C>=0 → y minimal (=0); C<0 → use upper line (max y)\n",
    "                C_use  = (~pos) * C  # negative entries only\n",
    "                t = t + (C_use * (-alpha * L)).sum(dim=1, keepdim=True)\n",
    "                C = C_use * alpha\n",
    "                C = torch.where((U <= 0), torch.zeros_like(C), C)\n",
    "                # L>=0 case acts as identity; already covered since alpha=1 there and pos/neg selection above\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            # y = s*x + q\n",
    "            s = (m.weight / torch.sqrt(m.running_var + m.eps)).view(1, -1, 1, 1)\n",
    "            q = (m.bias - m.running_mean * (m.weight / torch.sqrt(m.running_var + m.eps))).view(1, -1, 1, 1)\n",
    "            # C·(s x + q) = (C*s)·x + C·q\n",
    "            t = t + (C * q).sum(dim=1, keepdim=True)\n",
    "            C = C * s\n",
    "        elif isinstance(m, nn.Conv2d):\n",
    "            # C·(conv(x)+b) = (conv_transpose(C, W))·x + (C·b)\n",
    "            if m.bias is not None:\n",
    "                t = t + (C * m.bias.view(1, -1, 1, 1)).sum(dim=1, keepdim=True)\n",
    "            C = F.conv_transpose2d(C, m.weight, bias=None,\n",
    "                                   stride=m.stride, padding=m.padding,\n",
    "                                   dilation=m.dilation, groups=m.groups)\n",
    "        else:\n",
    "            # unknown op → assume identity (conservative)\n",
    "            C = C\n",
    "            t = t\n",
    "    return C, t\n",
    "\n",
    "def _affine_margin_bounds_conv2d_crown_tail(feat_l, feat_u, final_module, chg_idx, nchg_idx):\n",
    "    \"\"\"\n",
    "    CROWN tail for the margin: backprop v = W[c]-W[nc] through last DoubleConv block\n",
    "    and bound v^T h + (b_c - b_nc) over h ∈ post-DoubleConv(z), z∈[l0,u0].\n",
    "    \"\"\"\n",
    "    # Activate only if taps are present and final matches the tapped head\n",
    "    if 'CROWN_TAIL' not in globals():\n",
    "        raise RuntimeError(\"CROWN_TAIL not set\")\n",
    "    taps = CROWN_TAIL\n",
    "    l0 = taps['l0']; u0 = taps['u0']\n",
    "    block = taps['block']\n",
    "    final = taps['final']\n",
    "    if final is not final_module:\n",
    "        # different head (unlikely), refuse to proceed\n",
    "        raise RuntimeError(\"CROWN_TAIL['final'] != final_module\")\n",
    "\n",
    "    device = l0.device\n",
    "    # 1) Prepare layers & ReLU (pre-activation) bounds inside the block\n",
    "    layers = _flatten_layers(block)\n",
    "    relu_lu = _ibp_collect_relu_bounds(l0, u0, layers)\n",
    "\n",
    "    # 2) Initialize the linear form with the 1×1 \"margin head\": v = W[c]-W[nc]\n",
    "    head = final\n",
    "    Wc  = head.weight[int(chg_idx)].unsqueeze(0)   # (1, C_in, 1,1)\n",
    "    Wnc = head.weight[int(nchg_idx)].unsqueeze(0)\n",
    "    v = (Wc - Wnc)                                 # (1, C_in, 1,1)\n",
    "    b_margin = None\n",
    "    if head.bias is not None:\n",
    "        b_margin = (head.bias[int(chg_idx)] - head.bias[int(nchg_idx)]).to(device=device)\n",
    "\n",
    "    # Coefficient map C starts as v broadcast to spatial size of block output\n",
    "    H, W = feat_l.shape[-2:]\n",
    "    C0 = v.expand(-1, -1, H, W).contiguous()       # (1, C_in, H, W)\n",
    "    t0 = torch.zeros((1,1,H,W), device=device)     # constant map accumulator\n",
    "\n",
    "    # 3) Backprop the **upper** linear bound through the block\n",
    "    C_u, t_u = _backprop_linear_form(C0.clone(), t0.clone(), layers, relu_lu, mode='upper')\n",
    "    # 4) Backprop the **lower** linear bound through the block\n",
    "    C_l, t_l = _backprop_linear_form(C0.clone(), t0.clone(), layers, relu_lu, mode='lower')\n",
    "\n",
    "    # 5) Max/min over z ∈ [l0,u0] for the linear forms C·z + t\n",
    "    # upper: C_pos*u0 + C_neg*l0 + t\n",
    "    Cu_pos = torch.clamp(C_u, min=0); Cu_neg = torch.clamp(C_u, max=0)\n",
    "    Lu = (Cu_pos * u0 + Cu_neg * l0).sum(dim=1, keepdim=True) + t_u\n",
    "    # lower: C_pos*l0 + C_neg*u0 + t\n",
    "    Cl_pos = torch.clamp(C_l, min=0); Cl_neg = torch.clamp(C_l, max=0)\n",
    "    Ll = (Cl_pos * l0 + Cl_neg * u0).sum(dim=1, keepdim=True) + t_l\n",
    "\n",
    "    # 6) Add the margin bias (passes straight through)\n",
    "    if b_margin is not None:\n",
    "        Ll = Ll + b_margin.view(1,1,1,1)\n",
    "        Lu = Lu + b_margin.view(1,1,1,1)\n",
    "\n",
    "    # Shapes match your existing margin-bound expectations: (1,1,H,W)\n",
    "    return Ll, Lu\n",
    "\n",
    "# --- soft wrapper that uses CROWN tail when taps are available; else fallback ---\n",
    "def affine_margin_bounds_conv2d_tailaware(feat_l, feat_u, final_module, chg_idx, nchg_idx):\n",
    "    try:\n",
    "        if 'CROWN_TAIL' in globals():\n",
    "            return _affine_margin_bounds_conv2d_crown_tail(feat_l, feat_u, final_module, chg_idx, nchg_idx)\n",
    "    except Exception as e:\n",
    "        print(f\"[tail] CROWN-tail unavailable ({e}); falling back to original margin bounds.\")\n",
    "    # fallback to whatever was installed before\n",
    "    if _AFFINE_MARGIN_ORIG is not None:\n",
    "        return _AFFINE_MARGIN_ORIG(feat_l, feat_u, final_module, chg_idx, nchg_idx)\n",
    "    else:\n",
    "        # extremely unlikely: no original available\n",
    "        raise RuntimeError(\"No original affine_margin_bounds_conv2d found for fallback.\")\n",
    "\n",
    "# ---- hard rebind the name your verifier uses for margin bounds ----\n",
    "globals()['affine_margin_bounds_conv2d'] = affine_margin_bounds_conv2d_tailaware\n",
    "\n",
    "print(\"[tail] α-CROWN margin override armed (uses taps when CROWN_TAIL is set).\")\n",
    "# === CROWN tail (one DoubleConv + final 1x1) — drop-in override ===\n",
    "# Put this cell AFTER your \"final-conv bound patch\" cell in v9.\n",
    "\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "\n",
    "# Global “tap” the rcd() can populate with the tail input bounds and modules.\n",
    "# If this is not set, we fall back to the already-installed final-conv-only path.\n",
    "CROWN_TAIL = {\n",
    "    # 'l0': <Tensor [1,C,H,W]>, 'u0': <Tensor [1,C,H,W]>,\n",
    "    # 'block': <DoubleConv module>, 'final': <final 1x1 module>,\n",
    "}\n",
    "\n",
    "def _bn_affine_params(bn: nn.BatchNorm2d):\n",
    "    assert isinstance(bn, nn.BatchNorm2d)\n",
    "    # y = a * x + b  (eval mode only)\n",
    "    eps = bn.eps\n",
    "    w   = bn.weight.reshape(1,-1,1,1)\n",
    "    b   = bn.bias.reshape(1,-1,1,1)\n",
    "    mu  = bn.running_mean.reshape(1,-1,1,1)\n",
    "    var = bn.running_var.reshape(1,-1,1,1)\n",
    "    a = w / torch.sqrt(var + eps)\n",
    "    c = b - a * mu\n",
    "    return a, c\n",
    "\n",
    "def _interval_affine(l, u, a, b):\n",
    "    # y = a*x + b elementwise; a can be negative\n",
    "    y1 = a*l; y2 = a*u\n",
    "    L  = torch.minimum(y1, y2) + b\n",
    "    U  = torch.maximum(y1, y2) + b\n",
    "    return L, U\n",
    "\n",
    "def _relu_lin(l, u, mode: str):\n",
    "    # return (alpha, beta) for y <=/>= alpha*x + beta\n",
    "    # Upper:\n",
    "    #   u<=0 -> a=0,b=0 ; l>=0 -> a=1,b=0 ; else a=u/(u-l), b=-l*u/(u-l)\n",
    "    # Lower (simple): \n",
    "    #   u<=0 -> a=0,b=0 ; l>=0 -> a=1,b=0 ; else a=0,b=0\n",
    "    assert mode in (\"upper\",\"lower\")\n",
    "    a = torch.zeros_like(l)\n",
    "    b = torch.zeros_like(l)\n",
    "    pos   = (l >= 0)\n",
    "    neg   = (u <= 0)\n",
    "    unstab= (~pos & ~neg)\n",
    "    if mode == \"upper\":\n",
    "        a[pos] = 1.0\n",
    "        a[neg] = 0.0\n",
    "        # safe: avoid divide-by-zero when u≈l\n",
    "        denom = (u - l).clamp_min(1e-12)\n",
    "        a[unstab] = (u[unstab] / denom[unstab])\n",
    "        b[unstab] = (-l[unstab] * u[unstab] / denom[unstab])\n",
    "    else:\n",
    "        a[pos] = 1.0\n",
    "        a[neg] = 0.0\n",
    "        # on unstable we keep a=0,b=0 (simple lower bound)\n",
    "    return a, b\n",
    "\n",
    "def _conv_weight_flat(conv: nn.Conv2d):\n",
    "    W = conv.weight   # [Cout, Cin, kh, kw]\n",
    "    return W.view(W.shape[0], -1).contiguous()\n",
    "\n",
    "def _dual_back_through_conv(C_map, conv: nn.Conv2d):\n",
    "    \"\"\"Back-sub dual coeffs through Conv: \n",
    "       input:  C_map [1,Cout,Hout,Wout]\n",
    "       output: C_map_prev [1,Cin,Hin,Win], plus keep COL form for the *next* conv.\n",
    "    \"\"\"\n",
    "    assert isinstance(conv, nn.Conv2d)\n",
    "    N, Cout, Hout, Wout = C_map.shape\n",
    "    assert N == 1\n",
    "    # Bias contribution lives at the output domain; caller handles (C_map * b).sum over channels.\n",
    "    # Convert to COL at output domain\n",
    "    L = Hout * Wout\n",
    "    C_out_col = C_map.view(1, Cout, L)  # [1, Cout, L]\n",
    "    W_flat = _conv_weight_flat(conv)    # [Cout, Cin*kh*kw]\n",
    "    # Cin*kh*kw x L\n",
    "    C_in_col = torch.matmul(W_flat.t(), C_out_col)   # [1, Cin*kh*kw, L]\n",
    "    # Fold back to MAP at input domain for pointwise ops / next layers\n",
    "    Hin = (Hout - 1) * conv.stride[0] - 2*conv.padding[0] + conv.dilation[0]*(conv.kernel_size[0]-1) + 1\n",
    "    Win = (Wout - 1) * conv.stride[1] - 2*conv.padding[1] + conv.dilation[1]*(conv.kernel_size[1]-1) + 1\n",
    "    C_in_map = F.fold(\n",
    "        C_in_col,\n",
    "        output_size=(Hin, Win),\n",
    "        kernel_size=conv.kernel_size,\n",
    "        dilation=conv.dilation,\n",
    "        padding=conv.padding,\n",
    "        stride=conv.stride,\n",
    "    )\n",
    "    return C_in_map, C_in_col, (Hin,Win), C_out_col\n",
    "\n",
    "def _unfold_like_conv(x, conv: nn.Conv2d):\n",
    "    return F.unfold(\n",
    "        x, kernel_size=conv.kernel_size,\n",
    "        dilation=conv.dilation, padding=conv.padding, stride=conv.stride\n",
    "    )  # [N, Cin*kh*kw, L]\n",
    "\n",
    "def _interval_conv(l, u, conv: nn.Conv2d):\n",
    "    W = conv.weight\n",
    "    b = conv.bias\n",
    "    Wp = torch.clamp(W, min=0); Wn = torch.clamp(W, max=0)\n",
    "    yL = F.conv2d(l, Wp, None, conv.stride, conv.padding, conv.dilation, conv.groups) + \\\n",
    "         F.conv2d(u, Wn, None, conv.stride, conv.padding, conv.dilation, conv.groups)\n",
    "    yU = F.conv2d(u, Wp, None, conv.stride, conv.padding, conv.dilation, conv.groups) + \\\n",
    "         F.conv2d(l, Wn, None, conv.stride, conv.padding, conv.dilation, conv.groups)\n",
    "    if b is not None:\n",
    "        yL = yL + b.view(1,-1,1,1)\n",
    "        yU = yU + b.view(1,-1,1,1)\n",
    "    return yL, yU\n",
    "\n",
    "def _doubleconv_parts(block: nn.Module):\n",
    "    # Extract (conv1, bn1, relu1, conv2, bn2, relu2) in order.\n",
    "    convs = [m for m in block.modules() if isinstance(m, nn.Conv2d)]\n",
    "    bns   = [m for m in block.modules() if isinstance(m, nn.BatchNorm2d)]\n",
    "    relus = [m for m in block.modules() if isinstance(m, (nn.ReLU, nn.ReLU6))]\n",
    "    # Be conservative: require 2 convs, 2 bns, 2 relus\n",
    "    if len(convs) < 2 or len(bns) < 2 or len(relus) < 2:\n",
    "        raise RuntimeError(\"CROWN tail: expected DoubleConv with 2x (Conv+BN+ReLU).\")\n",
    "    # Heuristic: take the *last* two of each in module traversal order\n",
    "    conv1, conv2 = convs[-2], convs[-1]\n",
    "    bn1,   bn2   = bns[-2],   bns[-1]\n",
    "    relu1, relu2 = relus[-2], relus[-1]\n",
    "    return conv1, bn1, relu1, conv2, bn2, relu2\n",
    "\n",
    "def _last_conv2d(module: nn.Module):\n",
    "    last = None\n",
    "    for m in module.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            last = m\n",
    "    if last is None:\n",
    "        raise RuntimeError(\"CROWN tail: final 1x1 conv not found.\")\n",
    "    return last\n",
    "\n",
    "@torch.no_grad()\n",
    "def crown_tail_bounds_oneblock(l0, u0, block: nn.Module, final_module: nn.Module,\n",
    "                               chg_idx: int|torch.Tensor, nchg_idx: int|torch.Tensor):\n",
    "    \"\"\"\n",
    "    l0,u0: interval bounds at *input* of the DoubleConv tail (shape [1,C,H,W]).\n",
    "    block:  DoubleConv (conv1->bn1->relu1->conv2->bn2->relu2).\n",
    "    final_module: module containing the final 1x1 conv.\n",
    "    chg_idx, nchg_idx: class indices for margin.\n",
    "    Returns: (LB_map, UB_map) each [1,1,H,W].\n",
    "    \"\"\"\n",
    "    device = l0.device\n",
    "    conv1, bn1, relu1, conv2, bn2, relu2 = _doubleconv_parts(block)\n",
    "    final = _last_conv2d(final_module)\n",
    "\n",
    "    # ---- forward intervals through the tail to get (l,u) at ReLU inputs ----\n",
    "    # z1 = BN1(Conv1(l0,u0))\n",
    "    y1L, y1U = _interval_conv(l0, u0, conv1)\n",
    "    a1, b1 = _bn_affine_params(bn1)\n",
    "    z1L, z1U = _interval_affine(y1L, y1U, a1, b1)             # ReLU1 input\n",
    "    # post ReLU1\n",
    "    x1L, x1U = torch.clamp_min(z1L, 0), torch.clamp_min(z1U, 0)\n",
    "\n",
    "    # z2 = BN2(Conv2(x1))\n",
    "    y2L, y2U = _interval_conv(x1L, x1U, conv2)\n",
    "    a2, b2 = _bn_affine_params(bn2)\n",
    "    z2L, z2U = _interval_affine(y2L, y2U, a2, b2)             # ReLU2 input\n",
    "    # post ReLU2 -> tail output (pre-final)\n",
    "    x2L, x2U = torch.clamp_min(z2L, 0), torch.clamp_min(z2U, 0)\n",
    "\n",
    "    # ---- set dual at logits: +1 for chg, -1 for non-chg, per-pixel ----\n",
    "    H, W = x2L.shape[-2], x2L.shape[-1]\n",
    "    C_out = final.out_channels\n",
    "    Cy = torch.zeros(1, C_out, H, W, device=device)\n",
    "    Cy[:, int(chg_idx)]  =  1.0\n",
    "    Cy[:, int(nchg_idx)] = -1.0\n",
    "\n",
    "    # d_map accumulates constant terms per output pixel\n",
    "    d_map = torch.zeros(1, 1, H, W, device=device)\n",
    "\n",
    "    # ---- back through final 1x1 conv ----\n",
    "    if final.bias is not None:\n",
    "        d_map = d_map + (Cy * final.bias.view(1,-1,1,1)).sum(dim=1, keepdim=True)\n",
    "    C_map, C_col, (H2,W2), _ = _dual_back_through_conv(Cy, final)  # now at tail output (x2 domain)\n",
    "\n",
    "    # ---- ReLU2 linear relaxations ----\n",
    "    aU2, bU2 = _relu_lin(z2L, z2U, mode=\"upper\")\n",
    "    aL2, bL2 = _relu_lin(z2L, z2U, mode=\"lower\")\n",
    "    # We'll compute both UB and LB by two passes differing only in (a,b)\n",
    "    def _pass(a_map, b_map):\n",
    "        C = C_map.clone()\n",
    "        d = d_map.clone()\n",
    "        d = d + (C * b_map).sum(dim=1, keepdim=True)\n",
    "        C = C * a_map\n",
    "        # BN2\n",
    "        d = d + (C * b2).sum(dim=1, keepdim=True)\n",
    "        C = C * a2\n",
    "        # Conv2\n",
    "        if conv2.bias is not None:\n",
    "            d = d + (C * conv2.bias.view(1,-1,1,1)).sum(dim=1, keepdim=True)\n",
    "        C, Ccol, (H1,W1), _ = _dual_back_through_conv(C, conv2)  # now at x1 (post ReLU1)\n",
    "        # ReLU1\n",
    "        return C, Ccol, d\n",
    "\n",
    "    # Upper chain:\n",
    "    C_u, Ccol_u, d_u = _pass(aU2, bU2)\n",
    "    aU1, bU1 = _relu_lin(z1L, z1U, mode=\"upper\")\n",
    "    d_u = d_u + (C_u * bU1).sum(dim=1, keepdim=True)\n",
    "    C_u = C_u * aU1\n",
    "    # BN1\n",
    "    d_u = d_u + (C_u * b1).sum(dim=1, keepdim=True)\n",
    "    C_u = C_u * a1\n",
    "    # Conv1 (last back-sub): DO NOT fold — keep COL at tail input for evaluation\n",
    "    if conv1.bias is not None:\n",
    "        d_u = d_u + (C_u * conv1.bias.view(1,-1,1,1)).sum(dim=1, keepdim=True)\n",
    "    # unfold coeffs to COL aligned with tail input\n",
    "    C_u_col = _unfold_like_conv(C_u, conv1)  # [1, Cin*k*k, L]\n",
    "    # Lower chain:\n",
    "    C_l, Ccol_l, d_l = _pass(aL2, bL2)\n",
    "    aL1, bL1 = _relu_lin(z1L, z1U, mode=\"lower\")\n",
    "    d_l = d_l + (C_l * bL1).sum(dim=1, keepdim=True)\n",
    "    C_l = C_l * aL1\n",
    "    d_l = d_l + (C_l * b1).sum(dim=1, keepdim=True)\n",
    "    C_l = C_l * a1\n",
    "    if conv1.bias is not None:\n",
    "        d_l = d_l + (C_l * conv1.bias.view(1,-1,1,1)).sum(dim=1, keepdim=True)\n",
    "    C_l_col = _unfold_like_conv(C_l, conv1)\n",
    "\n",
    "    # ---- evaluate against input box [l0,u0] per output pixel (vectorized) ----\n",
    "    Lcol = _unfold_like_conv(l0, conv1)  # [1, Cin*k*k, L]\n",
    "    Ucol = _unfold_like_conv(u0, conv1)  # [1, Cin*k*k, L]\n",
    "    Cpos_u = torch.clamp(C_u_col, min=0); Cneg_u = torch.clamp(C_u_col, max=0)\n",
    "    Cpos_l = torch.clamp(C_l_col, min=0); Cneg_l = torch.clamp(C_l_col, max=0)\n",
    "\n",
    "    UB_col = d_u.view(1,1,-1) + (Cpos_u * Ucol + Cneg_u * Lcol).sum(dim=1, keepdim=True)\n",
    "    LB_col = d_l.view(1,1,-1) + (Cpos_l * Lcol + Cneg_l * Ucol).sum(dim=1, keepdim=True)\n",
    "\n",
    "    Hout, Wout = H, W  # same spatial size\n",
    "    UB = UB_col.view(1,1,Hout,Wout)\n",
    "    LB = LB_col.view(1,1,Hout,Wout)\n",
    "    return LB, UB\n",
    "\n",
    "# ---- glue: override your bound call-sites if tail tap is present ----\n",
    "def affine_bounds_conv2d_crown(feat_l, feat_u, final_module,\n",
    "                               model=None, chg_idx=None, nchg_idx=None):\n",
    "    if CROWN_TAIL and all(k in CROWN_TAIL for k in (\"l0\",\"u0\",\"block\",\"final\")):\n",
    "        L, U = crown_tail_bounds_oneblock(\n",
    "            CROWN_TAIL[\"l0\"], CROWN_TAIL[\"u0\"],\n",
    "            CROWN_TAIL[\"block\"], CROWN_TAIL[\"final\"],\n",
    "            chg_idx if chg_idx is not None else 1,\n",
    "            nchg_idx if nchg_idx is not None else 0,\n",
    "        )\n",
    "        print(\"[tail] CROWN one-block used (DoubleConv + 1×1).\")\n",
    "        return L, U\n",
    "    # fallback: your already-installed final conv-only bounds\n",
    "    return affine_bounds_conv2d_final(feat_l, feat_u, final_module)\n",
    "\n",
    "def affine_margin_bounds_conv2d_crown(feat_l, feat_u, final_module, chg_idx, nchg_idx):\n",
    "    if CROWN_TAIL and all(k in CROWN_TAIL for k in (\"l0\",\"u0\",\"block\",\"final\")):\n",
    "        L, U = crown_tail_bounds_oneblock(\n",
    "            CROWN_TAIL[\"l0\"], CROWN_TAIL[\"u0\"],\n",
    "            CROWN_TAIL[\"block\"], CROWN_TAIL[\"final\"],\n",
    "            chg_idx, nchg_idx\n",
    "        )\n",
    "        return L, U\n",
    "    return affine_margin_bounds_conv2d_final(feat_l, feat_u, final_module, chg_idx, nchg_idx)\n",
    "\n",
    "# hard rebind\n",
    "globals()['affine_bounds_conv2d']        = affine_bounds_conv2d_crown\n",
    "globals()['affine_margin_bounds_conv2d'] = affine_margin_bounds_conv2d_crown\n",
    "\n",
    "print(\"[CROWN-tail] drop-in installed. If CROWN_TAIL tap is set, tail will be used; else final-only fallback.\")\n",
    "# === Make α-CROWN tail the one actually used (also for *_safe alias) ===\n",
    "# (Place this right after the CROWN-tail cell you added)\n",
    "\n",
    "def _affine_margin_bounds_conv2d_tailaware_VERBOSE(feat_l, feat_u, final_module, chg_idx, nchg_idx):\n",
    "    # Try the α-CROWN tail first\n",
    "    try:\n",
    "        if 'CROWN_TAIL' in globals():\n",
    "            L, U = _affine_margin_bounds_conv2d_crown_tail(feat_l, feat_u, final_module, chg_idx, nchg_idx)\n",
    "            print(\"[tail] α-CROWN margin used.\")\n",
    "            return L, U\n",
    "    except Exception as e:\n",
    "        print(f\"[tail] α-CROWN margin unavailable ({e}); falling back.\")\n",
    "\n",
    "    # Fallback to the original margin bound\n",
    "    if '_AFFINE_MARGIN_ORIG' in globals() and _AFFINE_MARGIN_ORIG is not None:\n",
    "        print(\"[tail] fallback -> original margin bounds.\")\n",
    "        return _AFFINE_MARGIN_ORIG(feat_l, feat_u, final_module, chg_idx, nchg_idx)\n",
    "    raise RuntimeError(\"No original affine_margin_bounds_conv2d available for fallback.\")\n",
    "\n",
    "# Rebind BOTH names your verifier might call\n",
    "globals()['affine_margin_bounds_conv2d']      = _affine_margin_bounds_conv2d_tailaware_VERBOSE\n",
    "globals()['affine_margin_bounds_conv2d_safe'] = _affine_margin_bounds_conv2d_tailaware_VERBOSE\n",
    "\n",
    "print(\"affine_margin_bounds_conv2d      ->\", affine_margin_bounds_conv2d.__name__)\n",
    "print(\"affine_margin_bounds_conv2d_safe ->\", affine_margin_bounds_conv2d_safe.__name__)\n",
    "# === Helper: fetch the first Conv2d inside a block (e.g., DoubleConv) ===\n",
    "import torch.nn as nn\n",
    "\n",
    "def _first_conv(mod: nn.Module) -> nn.Conv2d:\n",
    "    for m in mod.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            return m\n",
    "    raise RuntimeError(\"No Conv2d found in block\")\n",
    "\n",
    "# --- Encoder-Decoder (stop before model.outc) ---\n",
    "def propagate_prelogits_encdecnet(model, z):\n",
    "    x_l, x_u = z.lower, z.upper\n",
    "\n",
    "    # encoder\n",
    "    x1_l, x1_u = interval_forward_falconet(x_l,  x_u,  model.inc)\n",
    "    x2_l, x2_u = interval_forward_falconet(x1_l, x1_u, model.down1)\n",
    "    x3_l, x3_u = interval_forward_falconet(x2_l, x2_u, model.down2)\n",
    "    x4_l, x4_u = interval_forward_falconet(x3_l, x3_u, model.down3)\n",
    "    x5_l, x5_u = interval_forward_falconet(x4_l, x4_u, model.down4)\n",
    "\n",
    "    # decoder (first three ups as usual)\n",
    "    def up_step_nonfinal(up, xl, xu, sk_l, sk_u):\n",
    "        xl = up.up(xl);  xu = up.up(xu)\n",
    "        xl = torch.cat([sk_l, xl], dim=1)\n",
    "        xu = torch.cat([sk_u, xu], dim=1)\n",
    "        return interval_forward_falconet(xl, xu, up.conv)\n",
    "\n",
    "    x_l, x_u = up_step_nonfinal(model.up1, x5_l, x5_u, x4_l, x4_u)\n",
    "    x_l, x_u = up_step_nonfinal(model.up2, x_l,  x_u,  x3_l, x3_u)\n",
    "    x_l, x_u = up_step_nonfinal(model.up3, x_l,  x_u,  x2_l, x2_u)\n",
    "\n",
    "    # LAST up block (up4): tap **before** DoubleConv, then run it\n",
    "    xl = model.up4.up(x_l);  xu = model.up4.up(x_u)\n",
    "    t_in_l = torch.cat([x1_l, xl], dim=1)\n",
    "    t_in_u = torch.cat([x1_u, xu], dim=1)\n",
    "\n",
    "    if 'CROWN_TAIL' in globals():\n",
    "        CROWN_TAIL['l0']    = t_in_l.detach().clone()\n",
    "        CROWN_TAIL['u0']    = t_in_u.detach().clone()\n",
    "        CROWN_TAIL['block'] = model.up4.conv\n",
    "        CROWN_TAIL['final'] = model.outc\n",
    "        fc = _first_conv(model.up4.conv)\n",
    "        print(f\"[tail-tap EncDec] inC={t_in_l.shape[1]} expect={fc.in_channels}\")\n",
    "\n",
    "    y_l, y_u = interval_forward_falconet(t_in_l, t_in_u, model.up4.conv)\n",
    "    return y_l, y_u  # pre-logits for 1×1 head\n",
    "\n",
    "# --- FALCONet + token mixer (stop before model.outc) ---\n",
    "def propagate_prelogits_falconetmha(model, z):\n",
    "    x_l, x_u = z.lower, z.upper\n",
    "\n",
    "    # encoder with token mixers\n",
    "    x1_l, x1_u = interval_forward_falconet(x_l,  x_u,  model.inc)\n",
    "    x2_l, x2_u = interval_forward_falconet(x1_l, x1_u, model.down1)\n",
    "    x3_l, x3_u = interval_forward_falconet(x2_l, x2_u, model.down2)\n",
    "    x3_l, sh3  = flatten_hw(x3_l);  x3_u, _ = flatten_hw(x3_u)\n",
    "    x3_l, x3_u = interval_forward_tokenmixer(x3_l, x3_u, model.token_mixer_2)\n",
    "    x3_l, x3_u = unflatten_hw(x3_l, sh3), unflatten_hw(x3_u, sh3)\n",
    "\n",
    "    x4_l, x4_u = interval_forward_falconet(x3_l, x3_u, model.down3)\n",
    "    x4_l, sh4  = flatten_hw(x4_l);  x4_u, _ = flatten_hw(x4_u)\n",
    "    x4_l, x4_u = interval_forward_tokenmixer(x4_l, x4_u, model.token_mixer_3)\n",
    "    x4_l, x4_u = unflatten_hw(x4_l, sh4), unflatten_hw(x4_u, sh4)\n",
    "\n",
    "    x5_l, x5_u = interval_forward_falconet(x4_l, x4_u, model.down4)\n",
    "    x5_l, sh5  = flatten_hw(x5_l);  x5_u, _ = flatten_hw(x5_u)\n",
    "    x5_l, x5_u = interval_forward_tokenmixer(x5_l, x5_u, model.token_mixer_4)\n",
    "    x5_l, x5_u = unflatten_hw(x5_l, sh5), unflatten_hw(x5_u, sh5)\n",
    "\n",
    "    # decoder (first three ups as usual)\n",
    "    def up_step_nonfinal(up, xl, xu, sk_l, sk_u):\n",
    "        xl = up.up(xl);  xu = up.up(xu)\n",
    "        xl = torch.cat([sk_l, xl], dim=1)\n",
    "        xu = torch.cat([sk_u, xu], dim=1)\n",
    "        return interval_forward_falconet(xl, xu, up.conv)\n",
    "\n",
    "    x_l, x_u = up_step_nonfinal(model.up1, x5_l, x5_u, x4_l, x4_u)\n",
    "    x_l, x_u = up_step_nonfinal(model.up2, x_l,  x_u,  x3_l, x3_u)\n",
    "    x_l, x_u = up_step_nonfinal(model.up3, x_l,  x_u,  x2_l, x2_u)\n",
    "\n",
    "    # LAST up block (up4): tap **before** DoubleConv, then run it\n",
    "    xl = model.up4.up(x_l);  xu = model.up4.up(x_u)\n",
    "    t_in_l = torch.cat([x1_l, xl], dim=1)\n",
    "    t_in_u = torch.cat([x1_u, xu], dim=1)\n",
    "\n",
    "    if 'CROWN_TAIL' in globals():\n",
    "        CROWN_TAIL['l0']    = t_in_l.detach().clone()\n",
    "        CROWN_TAIL['u0']    = t_in_u.detach().clone()\n",
    "        CROWN_TAIL['block'] = model.up4.conv\n",
    "        CROWN_TAIL['final'] = model.outc\n",
    "        fc = _first_conv(model.up4.conv)\n",
    "        print(f\"[tail-tap FALCONet] inC={t_in_l.shape[1]} expect={fc.in_channels}\")\n",
    "\n",
    "    y_l, y_u = interval_forward_falconet(t_in_l, t_in_u, model.up4.conv)\n",
    "    return y_l, y_u  # pre-logits for 1×1 head\n",
    "\n",
    "# --- AttU-Net (stop before model.Conv_1x1) ---\n",
    "def propagate_prelogits_attunet(model, z):\n",
    "    x_l, x_u = z.lower, z.upper\n",
    "\n",
    "    # encoder\n",
    "    x1_l, x1_u = interval_forward_attunet(x_l,  x_u,  model.Conv1)\n",
    "    print(\"[w] after Conv1 :\", _span_mean_max(x1_l, x1_u))\n",
    "    x2_l, x2_u = interval_forward_attunet(x1_l, x1_u, model.Maxpool1)\n",
    "    x2_l, x2_u = interval_forward_attunet(x2_l, x2_u, model.Conv2)\n",
    "    print(\"[w] after Conv3 :\", _span_mean_max(x2_l, x2_u))\n",
    "    x3_l, x3_u = interval_forward_attunet(x2_l, x2_u, model.Maxpool2)\n",
    "    x3_l, x3_u = interval_forward_attunet(x3_l, x3_u, model.Conv3)\n",
    "    print(\"[w] after Conv5 :\", _span_mean_max(x3_l, x3_u))\n",
    "\n",
    "    # bottleneck\n",
    "    x4_l, x4_u = interval_forward_attunet(x3_l, x3_u, model.Maxpool3)\n",
    "    x4_l, x4_u = interval_forward_attunet(x4_l, x4_u, model.Conv4)\n",
    "\n",
    "    # decoder up from bottom\n",
    "    d4_l, d4_u = interval_forward_attunet(x4_l, x4_u, model.Up4)        # upsample\n",
    "    x3_l_att, x3_u_att = interval_forward_attention_gate(model.Att4, d4_l, d4_u, x3_l, x3_u)\n",
    "    d4_l = torch.cat((x3_l_att, d4_l), 1);  d4_u = torch.cat((x3_u_att, d4_u), 1)\n",
    "    d4_l, d4_u = interval_forward_attunet(d4_l, d4_u, model.Up_conv4)\n",
    "\n",
    "    d3_l, d3_u = interval_forward_attunet(d4_l, d4_u, model.Up3)        # upsample\n",
    "    x2_l_att, x2_u_att = interval_forward_attention_gate(model.Att3, d3_l, d3_u, x2_l, x2_u)\n",
    "    d3_l = torch.cat((x2_l_att, d3_l), 1);  d3_u = torch.cat((x2_u_att, d3_u), 1)\n",
    "    d3_l, d3_u = interval_forward_attunet(d3_l, d3_u, model.Up_conv3)\n",
    "    print(\"[w] after Up_conv3:\", _span_mean_max(d3_l, d3_u))\n",
    "\n",
    "    d2_l, d2_u = interval_forward_attunet(d3_l, d3_u, model.Up2)        # upsample\n",
    "    x1_l_att, x1_u_att = interval_forward_attention_gate(model.Att2, d2_l, d2_u, x1_l, x1_u)\n",
    "    t_in_l = torch.cat((x1_l_att, d2_l), 1)    # <-- **before** Up_conv2\n",
    "    t_in_u = torch.cat((x1_u_att, d2_u), 1)\n",
    "\n",
    "    if 'CROWN_TAIL' in globals():\n",
    "        CROWN_TAIL['l0']    = t_in_l.detach().clone()\n",
    "        CROWN_TAIL['u0']    = t_in_u.detach().clone()\n",
    "        CROWN_TAIL['block'] = model.Up_conv2\n",
    "        CROWN_TAIL['final'] = model.Conv_1x1\n",
    "        fc = _first_conv(model.Up_conv2)\n",
    "        print(f\"[tail-tap AttU] inC={t_in_l.shape[1]} expect={fc.in_channels}\")\n",
    "\n",
    "    d2_l, d2_u = interval_forward_attunet(t_in_l, t_in_u, model.Up_conv2)\n",
    "    print(\"[w] after Up_conv2:\", _span_mean_max(d2_l, d2_u))\n",
    "    return d2_l, d2_u  # pre-logits (before model.Conv_1x1)\n",
    "# === FIXED α-CROWN TAIL (use saved l0/u0; don't reuse pre-logits) ===\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "\n",
    "def _relu_bounds(l, u):\n",
    "    # exact interval ReLU (monotone): [max(l,0), max(u,0)]\n",
    "    return l.clamp_min_(0), u.clamp_min_(0)\n",
    "\n",
    "def _ia_conv(l, u, conv: nn.Conv2d):\n",
    "    W = conv.weight\n",
    "    b = conv.bias\n",
    "    Wp, Wn = W.clamp(min=0), W.clamp(max=0)\n",
    "    yL = F.conv2d(l, Wp, None, conv.stride, conv.padding, conv.dilation, conv.groups) + \\\n",
    "         F.conv2d(u, Wn, None, conv.stride, conv.padding, conv.dilation, conv.groups)\n",
    "    yU = F.conv2d(u, Wp, None, conv.stride, conv.padding, conv.dilation, conv.groups) + \\\n",
    "         F.conv2d(l, Wn, None, conv.stride, conv.padding, conv.dilation, conv.groups)\n",
    "    if b is not None:\n",
    "        yL = yL + b.view(1, -1, 1, 1)\n",
    "        yU = yU + b.view(1, -1, 1, 1)\n",
    "    return yL, yU\n",
    "\n",
    "def _two_convs_from_doubleconv(block: nn.Module):\n",
    "    # Grab the first two Conv2d layers in traversal order (works for common UNet blocks)\n",
    "    convs = [m for m in block.modules() if isinstance(m, nn.Conv2d)]\n",
    "    if len(convs) < 2:\n",
    "        raise RuntimeError(\"DoubleConv-like block does not expose two Conv2d layers.\")\n",
    "    return convs[0], convs[1]\n",
    "\n",
    "def _tail_margin_bounds(l0, u0, block: nn.Module, head1x1: nn.Conv2d, chg_idx, nchg_idx):\n",
    "    # Push from the tap (l0/u0) through the last DoubleConv (+ReLU after each conv)\n",
    "    c1, c2 = _two_convs_from_doubleconv(block)\n",
    "    # Sanity: channels must match\n",
    "    inC = l0.shape[1]; expC = c1.weight.shape[1]\n",
    "    if inC != expC:\n",
    "        print(f\"[tail] channel mismatch at tap: inC={inC} expect={expC} -> fallback.\")\n",
    "        return None\n",
    "\n",
    "    l, u = _ia_conv(l0, u0, c1); l, u = _relu_bounds(l, u)\n",
    "    l, u = _ia_conv(l,  u,  c2); l, u = _relu_bounds(l, u)  # safe even if your block omits final ReLU\n",
    "\n",
    "    # Now form margin on the final 1×1: Wd = W[c]-W[nc], bd = b[c]-b[nc]\n",
    "    W = head1x1.weight\n",
    "    b = head1x1.bias\n",
    "    Wd = (W[int(chg_idx)].unsqueeze(0) - W[int(nchg_idx)].unsqueeze(0))\n",
    "    bd = None if b is None else (b[int(chg_idx)] - b[int(nchg_idx)])\n",
    "\n",
    "    # Interval conv with custom kernel\n",
    "    Wp, Wn = Wd.clamp(min=0), Wd.clamp(max=0)\n",
    "    yL = F.conv2d(l, Wp, None, head1x1.stride, head1x1.padding, head1x1.dilation, head1x1.groups) + \\\n",
    "         F.conv2d(u, Wn, None, head1x1.stride, head1x1.padding, head1x1.dilation, head1x1.groups)\n",
    "    yU = F.conv2d(u, Wp, None, head1x1.stride, head1x1.padding, head1x1.dilation, head1x1.groups) + \\\n",
    "         F.conv2d(l, Wn, None, head1x1.stride, head1x1.padding, head1x1.dilation, head1x1.groups)\n",
    "    if bd is not None:\n",
    "        yL = yL + bd.view(1, 1, 1, 1)\n",
    "        yU = yU + bd.view(1, 1, 1, 1)\n",
    "    print(\"[tail] α-CROWN margin applied over DoubleConv→1×1.\")\n",
    "    return yL, yU\n",
    "\n",
    "# --- OVERRIDE ONLY THE MARGIN BOUNDS ---\n",
    "_AB_ORIG = globals().get('affine_margin_bounds_conv2d', None)\n",
    "\n",
    "def affine_margin_bounds_conv2d(feat_l, feat_u, final_module, chg_idx, nchg_idx):\n",
    "    # Try tail if present; otherwise, fall back\n",
    "    try:\n",
    "        t = globals().get('CROWN_TAIL', None)\n",
    "        if t is not None:\n",
    "            l0    = t.get('l0', None)\n",
    "            u0    = t.get('u0', None)\n",
    "            block = t.get('block', None)\n",
    "            head  = t.get('final', final_module)\n",
    "\n",
    "            if isinstance(l0, torch.Tensor) and isinstance(u0, torch.Tensor) and \\\n",
    "               isinstance(block, nn.Module) and isinstance(head, nn.Conv2d):\n",
    "                # (Optional) quick shape log\n",
    "                print(f\"[tail] using saved tap: inC={l0.shape[1]} expect={_two_convs_from_doubleconv(block)[0].weight.shape[1]}\")\n",
    "                out = _tail_margin_bounds(l0, u0, block, head, chg_idx, nchg_idx)\n",
    "                if out is not None:\n",
    "                    return out\n",
    "        print(\"[tail] unavailable or mismatch; fallback -> original margin bounds.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[tail] α-CROWN margin unavailable ({e}); falling back.\")\n",
    "    # Fallback to whatever was bound before\n",
    "    if _AB_ORIG is None:\n",
    "        raise RuntimeError(\"No original affine_margin_bounds_conv2d available for fallback.\")\n",
    "    return _AB_ORIG(feat_l, feat_u, final_module, chg_idx, nchg_idx)\n",
    "\n",
    "# Install override\n",
    "globals()['affine_margin_bounds_conv2d'] = affine_margin_bounds_conv2d\n",
    "print(\"[tail] fixed α-CROWN override installed.\")\n",
    "# === GT MASK SHIM (define GT_MASKS and a robust loader) ===\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# 1) Make sure the legacy path constants exist (we won't overwrite if you already set them)\n",
    "if 'OSCD_PATH_TOP' not in globals():      OSCD_PATH_TOP = \"../onera/OSCD/\"\n",
    "if 'OSCD_PATH_BOTTOM1' not in globals():  OSCD_PATH_BOTTOM1 = \"/imgs_1/\"\n",
    "if 'OSCD_PATH_BOTTOM2' not in globals():  OSCD_PATH_BOTTOM2 = \"/imgs_2/\"\n",
    "if 'OSCD_PATH_CM' not in globals():       OSCD_PATH_CM = \"/cm/cm.png\"\n",
    "\n",
    "# 2) Provide oscd_paths(city) if some older code tries to call it\n",
    "if 'oscd_paths' not in globals():\n",
    "    def oscd_paths(city: str):\n",
    "        top = OSCD_PATH_TOP\n",
    "        return (top + city + OSCD_PATH_BOTTOM1,\n",
    "                top + city + OSCD_PATH_BOTTOM2,\n",
    "                top + city + OSCD_PATH_CM)\n",
    "\n",
    "# 3) Global cache\n",
    "if 'GT_MASKS' not in globals():\n",
    "    GT_MASKS = {}\n",
    "\n",
    "def _cm_path(city: str) -> str:\n",
    "    \"\"\"Try legacy concat first; fall back to os.path.join if needed.\"\"\"\n",
    "    p1 = OSCD_PATH_TOP + city + OSCD_PATH_CM\n",
    "    if os.path.exists(p1):\n",
    "        return p1\n",
    "    p2 = os.path.join(OSCD_PATH_TOP, city, OSCD_PATH_CM.lstrip(\"/\"))\n",
    "    return p2\n",
    "\n",
    "# === GT mask sanitizer + safe loader ===\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Ensure the cache exists\n",
    "if 'GT_MASKS' not in globals():\n",
    "    GT_MASKS = {}\n",
    "\n",
    "def _cm_path(city: str) -> str:\n",
    "    # legacy concat first; safe-join fallback\n",
    "    p1 = OSCD_PATH_TOP + city + OSCD_PATH_CM\n",
    "    if os.path.exists(p1):\n",
    "        return p1\n",
    "    return os.path.join(OSCD_PATH_TOP, city, OSCD_PATH_CM.lstrip(\"/\"))\n",
    "\n",
    "def _sanitize_gt_array(arr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Collapse RGB/RGBA → single channel and binarize (nonzero → 1).\"\"\"\n",
    "    a = np.asarray(arr)\n",
    "    if a.ndim == 3:\n",
    "        # Any nonzero across channels = foreground\n",
    "        a = (a.any(axis=-1)).astype(np.uint8)\n",
    "    else:\n",
    "        a = (a > 0).astype(np.uint8)\n",
    "    return a\n",
    "\n",
    "def _load_gt_mask_from_disk(city: str) -> np.ndarray:\n",
    "    p = _cm_path(city)\n",
    "    if not os.path.exists(p):\n",
    "        raise FileNotFoundError(f\"GT mask path missing for {city}: {p}\")\n",
    "    img = Image.open(p)\n",
    "    # Convert to single channel explicitly to avoid (H,W,4)\n",
    "    if img.mode not in (\"1\", \"L\"):\n",
    "        img = img.convert(\"L\")\n",
    "    a = np.array(img)\n",
    "    a = _sanitize_gt_array(a)\n",
    "    GT_MASKS[city] = a\n",
    "    print(f\"[gt] {city}: mask {a.shape} loaded & sanitized from {p}\")\n",
    "    return a\n",
    "\n",
    "# Sanitize anything already in GT_MASKS (e.g., previously loaded RGBA)\n",
    "for k, v in list(GT_MASKS.items()):\n",
    "    GT_MASKS[k] = _sanitize_gt_array(v)\n",
    "    print(f\"[gt-fix] {k}: cached mask -> {GT_MASKS[k].shape} (binary)\")\n",
    "\n",
    "print(\"[gt] loader/sanitizer installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecd5d5c6-bdfd-4f6b-8a38-cfc3a2ea1c24",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ---------- models_to_test come from your definitions above ----------\n",
    "model_path = \"../onera/FALCONet_HCTv3-best_f1-epoch15.pth.tar\"\n",
    "falconet_model = FALCONetMHA_LiRPA(2*13, 2 , dropout=0.1, reduction=8, attention=True, num_heads=4)\n",
    "falconet_model.load_state_dict(torch.load(model_path, map_location=\"cpu\")); falconet_model.eval()\n",
    "\n",
    "MODELS = [\n",
    "    (\"FALCONet\",   falconet_model, 0),\n",
    "]\n",
    "\n",
    "\n",
    "CITIES    = [\"brasilia\", \"montpellier\", \"norcia\", \"rio\" , \"saclay_w\" , \"valencia\" , \"dubai\" , \"lasvegas\" , \"milano\" , \"chongqing\"]\n",
    "EPS    =  (0.0, 0.25/255, 0.5/255, 1/255, 2/255)\n",
    "RHO    = (0.2, 0.3, 0.5)\n",
    "GAMMA  = (0.3, 0.2)\n",
    "SMIN   = (16, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5dcd6bf-17fc-428b-8bac-bc38fca0942d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gt] loader/sanitizer installed.\n",
      "[gt] brasilia: mask (433, 469) loaded & sanitized from ../onera/OSCD/brasilia/cm/cm.png\n",
      "[gt] montpellier: mask (426, 451) loaded & sanitized from ../onera/OSCD/montpellier/cm/cm.png\n",
      "[gt] norcia: mask (241, 385) loaded & sanitized from ../onera/OSCD/norcia/cm/cm.png\n",
      "[gt] rio: mask (353, 426) loaded & sanitized from ../onera/OSCD/rio/cm/cm.png\n",
      "[gt] saclay_w: mask (639, 688) loaded & sanitized from ../onera/OSCD/saclay_w/cm/cm.png\n",
      "[gt] valencia: mask (458, 476) loaded & sanitized from ../onera/OSCD/valencia/cm/cm.png\n",
      "[gt] dubai: mask (774, 634) loaded & sanitized from ../onera/OSCD/dubai/cm/cm.png\n",
      "[gt] lasvegas: mask (824, 716) loaded & sanitized from ../onera/OSCD/lasvegas/cm/cm.png\n",
      "[gt] milano: mask (545, 558) loaded & sanitized from ../onera/OSCD/milano/cm/cm.png\n",
      "[gt] chongqing: mask (730, 544) loaded & sanitized from ../onera/OSCD/chongqing/cm/cm.png\n",
      "[gt] ready keys: ['brasilia', 'montpellier', 'norcia', 'rio', 'saclay_w', 'valencia', 'dubai', 'lasvegas', 'milano', 'chongqing']\n"
     ]
    }
   ],
   "source": [
    "# === PRELOAD GT MASKS (run once before sweep) ===\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Use your existing path constants; do NOT redefine them here\n",
    "# OSCD_PATH_TOP, OSCD_PATH_CM must already be set\n",
    "\n",
    "if 'GT_MASKS' not in globals():\n",
    "    GT_MASKS = {}\n",
    "\n",
    "def _cm_path(city: str) -> str:\n",
    "    # legacy concat first; safe join fallback\n",
    "    p1 = OSCD_PATH_TOP + city + OSCD_PATH_CM\n",
    "    if os.path.exists(p1):\n",
    "        return p1\n",
    "    return os.path.join(OSCD_PATH_TOP, city, OSCD_PATH_CM.lstrip(\"/\"))\n",
    "\n",
    "# === GT mask sanitizer + safe loader ===\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Ensure the cache exists\n",
    "if 'GT_MASKS' not in globals():\n",
    "    GT_MASKS = {}\n",
    "\n",
    "def _cm_path(city: str) -> str:\n",
    "    # legacy concat first; safe-join fallback\n",
    "    p1 = OSCD_PATH_TOP + city + OSCD_PATH_CM\n",
    "    if os.path.exists(p1):\n",
    "        return p1\n",
    "    return os.path.join(OSCD_PATH_TOP, city, OSCD_PATH_CM.lstrip(\"/\"))\n",
    "\n",
    "def _sanitize_gt_array(arr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Collapse RGB/RGBA → single channel and binarize (nonzero → 1).\"\"\"\n",
    "    a = np.asarray(arr)\n",
    "    if a.ndim == 3:\n",
    "        # Any nonzero across channels = foreground\n",
    "        a = (a.any(axis=-1)).astype(np.uint8)\n",
    "    else:\n",
    "        a = (a > 0).astype(np.uint8)\n",
    "    return a\n",
    "\n",
    "def _load_gt_mask_from_disk(city: str) -> np.ndarray:\n",
    "    p = _cm_path(city)\n",
    "    if not os.path.exists(p):\n",
    "        raise FileNotFoundError(f\"GT mask path missing for {city}: {p}\")\n",
    "    img = Image.open(p)\n",
    "    # Convert to single channel explicitly to avoid (H,W,4)\n",
    "    if img.mode not in (\"1\", \"L\"):\n",
    "        img = img.convert(\"L\")\n",
    "    a = np.array(img)\n",
    "    a = _sanitize_gt_array(a)\n",
    "    GT_MASKS[city] = a\n",
    "    print(f\"[gt] {city}: mask {a.shape} loaded & sanitized from {p}\")\n",
    "    return a\n",
    "\n",
    "# Sanitize anything already in GT_MASKS (e.g., previously loaded RGBA)\n",
    "for k, v in list(GT_MASKS.items()):\n",
    "    GT_MASKS[k] = _sanitize_gt_array(v)\n",
    "    print(f\"[gt-fix] {k}: cached mask -> {GT_MASKS[k].shape} (binary)\")\n",
    "\n",
    "print(\"[gt] loader/sanitizer installed.\")\n",
    "\n",
    "\n",
    "# Preload every city you’ll sweep\n",
    "for city in CITIES:\n",
    "    _load_gt_mask_from_disk(city)\n",
    "\n",
    "print(\"[gt] ready keys:\", list(GT_MASKS.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd4d54c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[shim] AttU-Net: aliased Maxpool1 -> Maxpool (if missing).\n",
      "[install] Tail-aware margin override installed (with safe fallback).\n",
      "[ok] Quiet tail + MaxPool patch active (v11)\n",
      "[ok] v12c: tail fixed (real last block + final conv), AttU-Net encoder autodetect + MaxPool-safe\n",
      "[hotfix] Patched nova_choose_change_channel/logits_to_clean_pred (uses torch.softmax; no np.exp).\n",
      "[ok] predicate_logger_safe_v7 loaded\n"
     ]
    }
   ],
   "source": [
    "# === Sweep harness ===\n",
    "def run_one_setting(model_name, model, model_type, city, eps, rho, gamma, s_min):\n",
    "    try:\n",
    "        lower, upper, clean_logits, clean_pred, gt_mask = rcd(model, model_type, city, eps)\n",
    "        width_mean = (upper - lower).abs().mean().item()\n",
    "        logit_min = float(clean_logits.min().item())\n",
    "        logit_max = float(clean_logits.max().item())\n",
    "        return {\n",
    "            \"ok\": True,\n",
    "            \"model\": model_name,\n",
    "            \"type\": int(model_type),\n",
    "            \"city\": city,\n",
    "            \"eps\": float(eps),\n",
    "            \"rho\": float(rho),\n",
    "            \"gamma\": float(gamma),\n",
    "            \"s_min\": int(s_min),\n",
    "            \"width_mean\": width_mean,\n",
    "            \"logit_min\": logit_min,\n",
    "            \"logit_max\": logit_max,\n",
    "            \"error\": \"\",\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(\"[trace] rcd() raised:\")\n",
    "        traceback.print_exc()\n",
    "        return {\n",
    "            \"ok\": False,\n",
    "            \"model\": model_name,\n",
    "            \"type\": int(model_type),\n",
    "            \"city\": city,\n",
    "            \"eps\": float(eps),\n",
    "            \"rho\": float(rho),\n",
    "            \"gamma\": float(gamma),\n",
    "            \"s_min\": int(s_min),\n",
    "            \"width_mean\": float(\"nan\"),\n",
    "            \"logit_min\": float(\"nan\"),\n",
    "            \"logit_max\": float(\"nan\"),\n",
    "            \"error\": repr(e),\n",
    "        }\n",
    "\n",
    "def _flush_csv(path, header, rows):\n",
    "    need_header = not os.path.exists(path) or os.path.getsize(path) == 0\n",
    "    with open(path, \"a\", newline=\"\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=header, extrasaction=\"ignore\")\n",
    "        if need_header:\n",
    "            w.writeheader()\n",
    "        w.writerows(rows)\n",
    "    rows.clear()\n",
    "\n",
    "def run_sweep(\n",
    "    models_to_test,\n",
    "    cities=(\"paris\",),                 # keep small first\n",
    "    eps_grid=(0.0, 1/255, 2/255),\n",
    "    rho_grid=(0.2, 0.3),\n",
    "    gamma_grid=(0.3,),\n",
    "    s_min_grid=(16,),\n",
    "    out_csv=\"predicate_summary_semantic_v7.csv\",\n",
    "    write_every=10,\n",
    "):\n",
    "    total_per_city_model = len(eps_grid) * len(rho_grid) * len(gamma_grid) * len(s_min_grid)\n",
    "    print(f\"[grid] {total_per_city_model} combos per city & model\")\n",
    "\n",
    "    header = [\"ok\",\"model\",\"type\",\"city\",\"eps\",\"rho\",\"gamma\",\"s_min\",\"width_mean\",\"logit_min\",\"logit_max\",\"error\"]\n",
    "    results = []\n",
    "    n = 0\n",
    "\n",
    "    for (model_name, model, model_type) in models_to_test:\n",
    "        print(f\"\\n===== MODEL: {model_name} (type={model_type}) =====\")\n",
    "        for city in cities:\n",
    "            # Optional GT check (non-fatal)\n",
    "            try:\n",
    "                _ = _load_gt_mask_from_disk(city)\n",
    "            except Exception as e:\n",
    "                print(f\"[warn] GT mask for {city} not found / unreadable: {e}\")\n",
    "\n",
    "            for eps, rho, gamma, s_min in itertools.product(eps_grid, rho_grid, gamma_grid, s_min_grid):\n",
    "                rec = run_one_setting(model_name, model, model_type, city, eps, rho, gamma, s_min)\n",
    "                results.append(rec)\n",
    "                n += 1\n",
    "                if (n % write_every) == 0:\n",
    "                    _flush_csv(out_csv, header, results)\n",
    "                    print(f\"[write] {n} rows -> {out_csv}\")\n",
    "\n",
    "    _flush_csv(out_csv, header, results)\n",
    "    print(f\"[write] {n} rows -> {out_csv}\")\n",
    "    return results\n",
    "\n",
    "# === anon end-to-end patch cell (idempotent) ===\n",
    "# - Robust GT loader guard stays unchanged (already in your notebook)\n",
    "# - Fix AttU_Net naming (Maxpool1 -> Maxpool) without changing the model\n",
    "# - Install tail-aware margin override that falls back cleanly if shapes/taps don't match\n",
    "# - Keep original final-conv bounds intact\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "\n",
    "# ---- 1) AttU_Net minor alias (only if missing) ----\n",
    "try:\n",
    "    for name, model, mtype in MODELS:\n",
    "        if model.__class__.__name__.lower().startswith(\"attu\"):\n",
    "            if hasattr(model, \"Maxpool\") and not hasattr(model, \"Maxpool1\"):\n",
    "                setattr(model, \"Maxpool1\", getattr(model, \"Maxpool\"))\n",
    "    print(\"[shim] AttU-Net: aliased Maxpool1 -> Maxpool (if missing).\")\n",
    "except Exception as e:\n",
    "    print(\"[shim] AttU-Net alias warning:\", e)\n",
    "\n",
    "# ---- 2) Simple interval conv2d helper (kept local; no recursion) ----\n",
    "def _interval_conv2d(xL, xU, conv: nn.Conv2d):\n",
    "    W = conv.weight\n",
    "    b = conv.bias\n",
    "    device = xL.device\n",
    "    Wpos = torch.clamp(W, min=0).to(device=device)\n",
    "    Wneg = torch.clamp(W, max=0).to(device=device)\n",
    "    yL = F.conv2d(xL, Wpos, None, conv.stride, conv.padding, conv.dilation, conv.groups) + \\\n",
    "         F.conv2d(xU, Wneg, None, conv.stride, conv.padding, conv.dilation, conv.groups)\n",
    "    yU = F.conv2d(xU, Wpos, None, conv.stride, conv.padding, conv.dilation, conv.groups) + \\\n",
    "         F.conv2d(xL, Wneg, None, conv.stride, conv.padding, conv.dilation, conv.groups)\n",
    "    if b is not None:\n",
    "        b = b.view(1, -1, 1, 1).to(device=device)\n",
    "        yL = yL + b\n",
    "        yU = yU + b\n",
    "    return yL, yU\n",
    "\n",
    "def _interval_bn2d(xL, xU, bn: nn.BatchNorm2d):\n",
    "    # Transform x -> y = gamma * (x - mean) / sqrt(var + eps) + beta\n",
    "    # For intervals, the worst case is monotone if gamma >= 0; flip if gamma < 0.\n",
    "    g = bn.weight.detach().view(1,-1,1,1)\n",
    "    b = bn.bias.detach().view(1,-1,1,1)\n",
    "    mean = bn.running_mean.detach().view(1,-1,1,1)\n",
    "    var  = bn.running_var.detach().view(1,-1,1,1)\n",
    "    denom = torch.sqrt(var + bn.eps)\n",
    "    a = g / denom\n",
    "    c = b - a * mean\n",
    "    a_pos = torch.clamp(a, min=0)\n",
    "    a_neg = torch.clamp(a, max=0)\n",
    "    yL = a_pos*xL + a_neg*xU + c\n",
    "    yU = a_pos*xU + a_neg*xL + c\n",
    "    return yL, yU\n",
    "\n",
    "def _interval_relu(xL, xU):\n",
    "    return F.relu(xL), F.relu(xU)\n",
    "\n",
    "def _interval_seq(xL, xU, module: nn.Sequential):\n",
    "    for layer in module.children():\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            xL, xU = _interval_conv2d(xL, xU, layer)\n",
    "        elif isinstance(layer, nn.BatchNorm2d):\n",
    "            xL, xU = _interval_bn2d(xL, xU, layer)\n",
    "        elif isinstance(layer, nn.ReLU):\n",
    "            xL, xU = _interval_relu(xL, xU)\n",
    "        elif isinstance(layer, nn.Identity):\n",
    "            pass\n",
    "        else:\n",
    "            # Be conservative: if unknown layer, bail and force fallback\n",
    "            raise RuntimeError(f\"interval-seq: unsupported layer {layer.__class__.__name__}\")\n",
    "    return xL, xU\n",
    "\n",
    "# ---- 3) Tail-aware margin override (safe and idempotent) ----\n",
    "if \"AFFINE_MARGIN_ORIG\" not in globals():\n",
    "    AFFINE_MARGIN_ORIG = globals().get(\"affine_margin_bounds_conv2d\")\n",
    "\n",
    "def _tail_margin_bounds_or_fallback(feat_l, feat_u, final_module, chg_idx, nchg_idx):\n",
    "    # If no tap or malformed tap, fallback to original\n",
    "    tap = globals().get(\"CROWN_TAIL\", None)\n",
    "    if not isinstance(tap, dict) or not all(k in tap for k in (\"l0\",\"u0\",\"block\",\"final\")):\n",
    "        return AFFINE_MARGIN_ORIG(feat_l, feat_u, final_module, chg_idx, nchg_idx)\n",
    "\n",
    "    xL, xU = tap[\"l0\"], tap[\"u0\"]\n",
    "    block  = tap[\"block\"]\n",
    "    final1 = tap[\"final\"]\n",
    "\n",
    "    # Sanity: the block must be a Sequential of conv/bn/relu\n",
    "    if not isinstance(block, nn.Sequential):\n",
    "        print(\"[tail] tap 'block' is not nn.Sequential; fallback.\")\n",
    "        return AFFINE_MARGIN_ORIG(feat_l, feat_u, final_module, chg_idx, nchg_idx)\n",
    "\n",
    "    # Channel check: ensure the first conv of block matches xL channels.\n",
    "    first_conv = None\n",
    "    for ly in block.children():\n",
    "        if isinstance(ly, nn.Conv2d):\n",
    "            first_conv = ly\n",
    "            break\n",
    "    if first_conv is None:\n",
    "        print(\"[tail] no Conv2d in block; fallback.\")\n",
    "        return AFFINE_MARGIN_ORIG(feat_l, feat_u, final_module, chg_idx, nchg_idx)\n",
    "\n",
    "    inC_needed = int(first_conv.in_channels)\n",
    "    inC_have   = int(xL.shape[1])\n",
    "    if inC_needed != inC_have:\n",
    "        print(f\"[tail] channel mismatch at tap (have {inC_have}, need {inC_needed}); fallback.\")\n",
    "        return AFFINE_MARGIN_ORIG(feat_l, feat_u, final_module, chg_idx, nchg_idx)\n",
    "\n",
    "    # Propagate intervals through DoubleConv tail (interval, non-recursive, tight & stable)\n",
    "    try:\n",
    "        tL, tU = _interval_seq(xL, xU, block)\n",
    "    except Exception as e:\n",
    "        print(f\"[tail] interval through tail failed ({e}); fallback.\")\n",
    "        return AFFINE_MARGIN_ORIG(feat_l, feat_u, final_module, chg_idx, nchg_idx)\n",
    "\n",
    "    # Build difference kernel for final 1×1\n",
    "    conv = None\n",
    "    # final may be Conv2d or a small wrapper that contains Conv2d\n",
    "    if isinstance(final1, nn.Conv2d):\n",
    "        conv = final1\n",
    "    else:\n",
    "        for m in final1.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                conv = m\n",
    "        if conv is None:\n",
    "            print(\"[tail] could not locate Conv2d in 'final'; fallback.\")\n",
    "            return AFFINE_MARGIN_ORIG(feat_l, feat_u, final_module, chg_idx, nchg_idx)\n",
    "\n",
    "    Wc  = conv.weight[int(chg_idx)].unsqueeze(0)\n",
    "    Wnc = conv.weight[int(nchg_idx)].unsqueeze(0)\n",
    "    Wd = (Wc - Wnc)\n",
    "    bd = None\n",
    "    if conv.bias is not None:\n",
    "        bd = conv.bias[int(chg_idx)] - conv.bias[int(nchg_idx)]\n",
    "\n",
    "    # One more interval step for the margin head\n",
    "    yL, yU = _interval_conv2d(tL, tU, nn.Conv2d(in_channels=Wd.shape[1],\n",
    "                                                out_channels=1,\n",
    "                                                kernel_size=conv.kernel_size,\n",
    "                                                stride=conv.stride,\n",
    "                                                padding=conv.padding,\n",
    "                                                dilation=conv.dilation,\n",
    "                                                groups=conv.groups,\n",
    "                                                bias=True if bd is not None else False))\n",
    "    # Manually add weights/bias because we created a dummy conv for shape convenience\n",
    "    # Replace the output with exact linear combination using the real Wd/bd via grouped conv math\n",
    "    # (Since we can't set the dummy's data without leaking grads in no-grad mode, just recompute)\n",
    "    # Recompute with direct conv2d using Wd/bd:\n",
    "    yL = F.conv2d(tL, Wd, bd, conv.stride, conv.padding, conv.dilation, conv.groups)\n",
    "    yU = F.conv2d(tU, Wd, bd, conv.stride, conv.padding, conv.dilation, conv.groups)\n",
    "    print(\"[tail] margin via interval-tail DoubleConv → real 1×1.\")\n",
    "    return yL, yU\n",
    "\n",
    "# Swap in our tail-aware wrapper (keeps original as fallback)\n",
    "globals()[\"affine_margin_bounds_conv2d\"] = _tail_margin_bounds_or_fallback\n",
    "globals()[\"affine_margin_bounds_conv2d_safe\"] = _tail_margin_bounds_or_fallback\n",
    "print(\"[install] Tail-aware margin override installed (with safe fallback).\")\n",
    "\n",
    "# === Quiet end-to-end patch: AttU-Net MaxPool + final-1x1 tail taps (no fallback chatter) ===\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Gate all \"tail\" prints behind a flag (default: silent)\n",
    "TAIL_VERBOSE = False\n",
    "def _tprint(*a, **k):\n",
    "    if TAIL_VERBOSE:\n",
    "        print(*a, **k)\n",
    "\n",
    "# 1) Extend interval_forward_attunet to support MaxPool2d\n",
    "if 'interval_forward_attunet' in globals():\n",
    "    _ifa_old = interval_forward_attunet\n",
    "    def interval_forward_attunet(lower, upper, module):\n",
    "        if isinstance(module, nn.MaxPool2d):\n",
    "            l = F.max_pool2d(lower,\n",
    "                             kernel_size=module.kernel_size,\n",
    "                             stride=module.stride,\n",
    "                             padding=module.padding,\n",
    "                             dilation=module.dilation,\n",
    "                             ceil_mode=module.ceil_mode)\n",
    "            u = F.max_pool2d(upper,\n",
    "                             kernel_size=module.kernel_size,\n",
    "                             stride=module.stride,\n",
    "                             padding=module.padding,\n",
    "                             dilation=module.dilation,\n",
    "                             ceil_mode=module.ceil_mode)\n",
    "            return l, u\n",
    "        return _ifa_old(lower, upper, module)\n",
    "    globals()['interval_forward_attunet'] = interval_forward_attunet\n",
    "    _tprint(\"[patch] interval_forward_attunet: MaxPool2d supported\")\n",
    "\n",
    "# 2) Helper: AttU-Net MaxPool alias\n",
    "def _attu_maxpool_alias(model):\n",
    "    if hasattr(model, 'Maxpool'):\n",
    "        return model.Maxpool\n",
    "    if hasattr(model, 'Maxpool1'):\n",
    "        return model.Maxpool1\n",
    "    raise AttributeError(\"AttU_Net has neither 'Maxpool' nor 'Maxpool1'\")\n",
    "\n",
    "# 3) Quiet tail tap (final 1x1 only)\n",
    "def _quiet_set_tail(l0, u0, final_head):\n",
    "    if 'CROWN_TAIL' not in globals():\n",
    "        return\n",
    "    CROWN_TAIL.clear()\n",
    "    CROWN_TAIL['l0']    = l0.detach().clone()\n",
    "    CROWN_TAIL['u0']    = u0.detach().clone()\n",
    "    CROWN_TAIL['block'] = None            # never try DoubleConv tail\n",
    "    CROWN_TAIL['final'] = final_head      # only the last 1x1\n",
    "    _tprint(\"[tail] tap set (final 1x1 only).\")\n",
    "\n",
    "# 4) Replace propagation functions (AttU, EncDec, FALCONet-MHA)\n",
    "def propagate_prelogits_attunet(model, z):\n",
    "    x_l, x_u = z.lower, z.upper\n",
    "    # encoder\n",
    "    x1_l, x1_u = interval_forward_attunet(x_l,  x_u,  model.Conv1)\n",
    "    print(\"[w] after Conv1 :\", _span_mean_max(x1_l, x1_u))\n",
    "    x2_l, x2_u = interval_forward_attunet(x1_l, x1_u, _attu_maxpool_alias(model))\n",
    "    x2_l, x2_u = interval_forward_attunet(x2_l, x2_u, model.Conv3)\n",
    "    print(\"[w] after Conv3 :\", _span_mean_max(x2_l, x2_u))\n",
    "    x3_l, x3_u = interval_forward_attunet(x2_l, x2_u, _attu_maxpool_alias(model))\n",
    "    x3_l, x3_u = interval_forward_attunet(x3_l, x3_u, model.Conv5)\n",
    "    print(\"[w] after Conv5 :\", _span_mean_max(x3_l, x3_u))\n",
    "\n",
    "    # decoder + gates\n",
    "    d4_l, d4_u = interval_forward_attunet(x3_l, x3_u, model.Up3)\n",
    "    x2l_att, x2u_att = interval_forward_attention_gate(model.Att3, d4_l, d4_u, x2_l, x2_u)\n",
    "    d4_l, d4_u = torch.cat([x2l_att, d4_l], 1), torch.cat([x2u_att, d4_u], 1)\n",
    "    d3_l, d3_u = interval_forward_attunet(d4_l, d4_u, model.Up_conv3)\n",
    "    print(\"[w] after Up_conv3:\", _span_mean_max(d3_l, d3_u))\n",
    "\n",
    "    # quiet tail tap (final head only)\n",
    "    _quiet_set_tail(d3_l, d3_u, model.Conv_1x1)\n",
    "\n",
    "    d2_l, d2_u = interval_forward_attunet(d3_l, d3_u, model.Up2)\n",
    "    x1l_att, x1u_att = interval_forward_attention_gate(model.Att2, d2_l, d2_u, x1_l, x1_u)\n",
    "    d2_l, d2_u = torch.cat([x1l_att, d2_l], 1), torch.cat([x1u_att, d2_u], 1)\n",
    "    d2_l, d2_u = interval_forward_attunet(d2_l, d2_u, model.Up_conv2)\n",
    "    print(\"[w] after Up_conv2:\", _span_mean_max(d2_l, d2_u))\n",
    "    return d2_l, d2_u\n",
    "\n",
    "def propagate_prelogits_encdecnet(model, z):\n",
    "    x_l, x_u = z.lower, z.upper\n",
    "    x1_l, x1_u = interval_forward_falconet(x_l,  x_u,  model.inc)\n",
    "    x2_l, x2_u = interval_forward_falconet(x1_l, x1_u, model.down1)\n",
    "    x3_l, x3_u = interval_forward_falconet(x2_l, x2_u, model.down2)\n",
    "    x4_l, x4_u = interval_forward_falconet(x3_l, x3_u, model.down3)\n",
    "    x5_l, x5_u = interval_forward_falconet(x4_l, x4_u, model.down4)\n",
    "    def up_step(up, xl, xu, sk_l, sk_u):\n",
    "        xl = up.up(xl); xu = up.up(xu)\n",
    "        xl = torch.cat([sk_l, xl], dim=1)\n",
    "        xu = torch.cat([sk_u, xu], dim=1)\n",
    "        return interval_forward_falconet(xl, xu, up.conv)\n",
    "    x_l, x_u = up_step(model.up1, x5_l, x5_u, x4_l, x4_u)\n",
    "    x_l, x_u = up_step(model.up2, x_l,  x_u,  x3_l, x3_u)\n",
    "    x_l, x_u = up_step(model.up3, x_l,  x_u,  x2_l, x2_u)\n",
    "\n",
    "    # quiet tail tap before last DoubleConv; only final head\n",
    "    _quiet_set_tail(x_l, x_u, model.outc)\n",
    "\n",
    "    x_l, x_u = up_step(model.up4, x_l,  x_u,  x1_l, x1_u)\n",
    "    return x_l, x_u\n",
    "\n",
    "def propagate_prelogits_falconetmha(model, z):\n",
    "    x_l, x_u = z.lower, z.upper\n",
    "    x1_l, x1_u = interval_forward_falconet(x_l,  x_u,  model.inc)\n",
    "    x2_l, x2_u = interval_forward_falconet(x1_l, x1_u, model.down1)\n",
    "    x3_l, x3_u = interval_forward_falconet(x2_l, x2_u, model.down2)\n",
    "    x3_l, sh3  = flatten_hw(x3_l); x3_u, _ = flatten_hw(x3_u)\n",
    "    x3_l, x3_u = interval_forward_tokenmixer(x3_l, x3_u, model.token_mixer_2)\n",
    "    x3_l, x3_u = unflatten_hw(x3_l, sh3), unflatten_hw(x3_u, sh3)\n",
    "    x4_l, x4_u = interval_forward_falconet(x3_l, x3_u, model.down3)\n",
    "    x4_l, sh4  = flatten_hw(x4_l); x4_u, _ = flatten_hw(x4_u)\n",
    "    x4_l, x4_u = interval_forward_tokenmixer(x4_l, x4_u, model.token_mixer_3)\n",
    "    x4_l, x4_u = unflatten_hw(x4_l, sh4), unflatten_hw(x4_u, sh4)\n",
    "    x5_l, x5_u = interval_forward_falconet(x4_l, x4_u, model.down4)\n",
    "    x5_l, sh5  = flatten_hw(x5_l); x5_u, _ = flatten_hw(x5_u)\n",
    "    x5_l, x5_u = interval_forward_tokenmixer(x5_l, x5_u, model.token_mixer_4)\n",
    "    x5_l, x5_u = unflatten_hw(x5_l, sh5), unflatten_hw(x5_u, sh5)\n",
    "    def up_step(up, xl, xu, sk_l, sk_u):\n",
    "        xl = up.up(xl); xu = up.up(xu)\n",
    "        xl = torch.cat([sk_l, xl], dim=1)\n",
    "        xu = torch.cat([sk_u, xu], dim=1)\n",
    "        return interval_forward_falconet(xl, xu, up.conv)\n",
    "    x_l, x_u = up_step(model.up1, x5_l, x5_u, x4_l, x4_u)\n",
    "    x_l, x_u = up_step(model.up2, x_l,  x_u,  x3_l, x3_u)\n",
    "    x_l, x_u = up_step(model.up3, x_l,  x_u,  x2_l, x2_u)\n",
    "\n",
    "    # quiet tail tap before last DoubleConv; only final head\n",
    "    _quiet_set_tail(x_l, x_u, model.outc)\n",
    "\n",
    "    x_l, x_u = up_step(model.up4, x_l,  x_u,  x1_l, x1_u)\n",
    "    return x_l, x_u\n",
    "\n",
    "globals()['propagate_prelogits_attunet']     = propagate_prelogits_attunet\n",
    "globals()['propagate_prelogits_encdecnet']   = propagate_prelogits_encdecnet\n",
    "globals()['propagate_prelogits_falconetmha'] = propagate_prelogits_falconetmha\n",
    "\n",
    "print(\"[ok] Quiet tail + MaxPool patch active (v11)\")\n",
    "# === v12c: Robust tail + encoder autodetect (EncDec / FALCONet / AttU-Net) ===\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "\n",
    "# ---------- small helpers ----------\n",
    "def _span_mean_max(l, u):\n",
    "    w = (u - l).abs()\n",
    "    return float(w.mean().detach().cpu()), float(w.max().detach().cpu())\n",
    "\n",
    "def _maxpool2d_bounds(l, u, mp: nn.MaxPool2d):\n",
    "    k = mp.kernel_size\n",
    "    s = mp.stride or k\n",
    "    p = mp.padding\n",
    "    d = mp.dilation\n",
    "    cm = mp.ceil_mode\n",
    "    return F.max_pool2d(l, k, s, p, d, cm), F.max_pool2d(u, k, s, p, d, cm)\n",
    "\n",
    "def _unwrap_final_conv2d(m: nn.Module) -> nn.Conv2d:\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        return m\n",
    "    for attr in ('conv', 'out', 'outc', 'final', 'head', 'proj'):\n",
    "        if hasattr(m, attr) and isinstance(getattr(m, attr), nn.Conv2d):\n",
    "            return getattr(m, attr)\n",
    "    for sub in m.modules():\n",
    "        if isinstance(sub, nn.Conv2d):\n",
    "            return sub\n",
    "    raise RuntimeError(\"[tail] could not find final nn.Conv2d inside head\")\n",
    "\n",
    "def _as_sequential_with_convs(m: nn.Module) -> nn.Sequential:\n",
    "    if isinstance(m, nn.Sequential):\n",
    "        seq = m\n",
    "    else:\n",
    "        kids = [c for c in m.children()]\n",
    "        seq = nn.Sequential(*kids) if kids else nn.Sequential()\n",
    "    # ensure at least one Conv2d (for α-CROWN tail)\n",
    "    if not any(isinstance(x, nn.Conv2d) for x in seq.modules() if x is not seq):\n",
    "        convs = [x for x in m.modules() if isinstance(x, nn.Conv2d)]\n",
    "        if convs:\n",
    "            seq = nn.Sequential(*convs)\n",
    "    return seq\n",
    "\n",
    "def _quiet_set_tail(pre_l, pre_u, block: nn.Module, final_head: nn.Module):\n",
    "    globals().setdefault('CROWN_TAIL', {})\n",
    "    CROWN_TAIL.clear()\n",
    "    CROWN_TAIL.update({\n",
    "        'l0':   pre_l.detach().clone(),\n",
    "        'u0':   pre_u.detach().clone(),\n",
    "        'block': _as_sequential_with_convs(block),\n",
    "        'final': _unwrap_final_conv2d(final_head),\n",
    "    })\n",
    "\n",
    "# ---------- AttU-Net helpers ----------\n",
    "def _attu_get_maxpool(model):\n",
    "    mp = getattr(model, 'Maxpool', None) or getattr(model, 'Maxpool1', None)\n",
    "    if not isinstance(mp, nn.MaxPool2d):\n",
    "        raise RuntimeError(\"AttU_Net expects nn.MaxPool2d at model.Maxpool/Maxpool1\")\n",
    "    return mp\n",
    "\n",
    "def _first_conv_in(m: nn.Module):\n",
    "    for sub in m.modules():\n",
    "        if isinstance(sub, nn.Conv2d):\n",
    "            return sub\n",
    "    return None\n",
    "\n",
    "def _attunet_conv_blocks(model):\n",
    "    blocks = []\n",
    "    for name, mod in model.named_children():\n",
    "        # accept Conv1, Conv2, Conv3, Conv5, ... but skip 'Conv_1x1'\n",
    "        if name.startswith('Conv') and re.fullmatch(r'Conv\\d+', name):\n",
    "            idx = int(name[4:])\n",
    "            blocks.append((idx, name, mod))\n",
    "    blocks.sort(key=lambda t: t[0])\n",
    "    return blocks\n",
    "\n",
    "def _take_next_block(blocks, inC):\n",
    "    for i, (_, name, mod) in enumerate(blocks):\n",
    "        fc = _first_conv_in(mod)\n",
    "        if isinstance(fc, nn.Conv2d) and fc.in_channels == inC:\n",
    "            return blocks.pop(i)\n",
    "    # if exact match not found, best-effort: choose the first whose first conv exists\n",
    "    for i, (_, name, mod) in enumerate(blocks):\n",
    "        fc = _first_conv_in(mod)\n",
    "        if isinstance(fc, nn.Conv2d):\n",
    "            return blocks.pop(i)\n",
    "    raise RuntimeError(f\"[AttU_Net] no encoder block matches inC={inC}\")\n",
    "\n",
    "# =========================\n",
    "# EncDec: tap BEFORE up4.conv (so tail.block = real DoubleConv, final = classifier Conv2d)\n",
    "# =========================\n",
    "def propagate_prelogits_encdecnet(model, z):\n",
    "    x_l, x_u = z.lower, z.upper\n",
    "    # encoder\n",
    "    x1_l, x1_u = interval_forward_falconet(x_l,  x_u,  model.inc)\n",
    "    x2_l, x2_u = interval_forward_falconet(x1_l, x1_u, model.down1)\n",
    "    x3_l, x3_u = interval_forward_falconet(x2_l, x2_u, model.down2)\n",
    "    x4_l, x4_u = interval_forward_falconet(x3_l, x3_u, model.down3)\n",
    "    x5_l, x5_u = interval_forward_falconet(x4_l, x4_u, model.down4)\n",
    "\n",
    "    # decoder up1..up3\n",
    "    def up_step(up, xl, xu, sk_l, sk_u):\n",
    "        xl = up.up(xl); xu = up.up(xu)\n",
    "        xl = torch.cat([sk_l, xl], dim=1)\n",
    "        xu = torch.cat([sk_u, xu], dim=1)\n",
    "        return interval_forward_falconet(xl, xu, up.conv)\n",
    "\n",
    "    x_l, x_u = up_step(model.up1, x5_l, x5_u, x4_l, x4_u)\n",
    "    x_l, x_u = up_step(model.up2, x_l,  x_u,  x3_l, x3_u)\n",
    "    x_l, x_u = up_step(model.up3, x_l,  x_u,  x2_l, x2_u)\n",
    "\n",
    "    # manual up4 to capture pre-block features\n",
    "    pre_l = model.up4.up(x_l); pre_u = model.up4.up(x_u)\n",
    "    pre_l = torch.cat([x1_l, pre_l], dim=1)\n",
    "    pre_u = torch.cat([x1_u, pre_u], dim=1)\n",
    "\n",
    "    # set tail on real last DoubleConv + final head Conv2d\n",
    "    _quiet_set_tail(pre_l, pre_u, block=model.up4.conv, final_head=model.outc)\n",
    "\n",
    "    # now run the actual last DoubleConv\n",
    "    x_l, x_u = interval_forward_falconet(pre_l, pre_u, model.up4.conv)\n",
    "    return x_l, x_u\n",
    "\n",
    "# =========================\n",
    "# FALCONet+MHA: same tail strategy as EncDec\n",
    "# =========================\n",
    "def propagate_prelogits_falconetmha(model, z):\n",
    "    x_l, x_u = z.lower, z.upper\n",
    "    # encoder\n",
    "    x1_l, x1_u = interval_forward_falconet(x_l,  x_u,  model.inc)\n",
    "    x2_l, x2_u = interval_forward_falconet(x1_l, x1_u, model.down1)\n",
    "    x3_l, x3_u = interval_forward_falconet(x2_l, x2_u, model.down2)\n",
    "    x3_l, sh3  = flatten_hw(x3_l); x3_u, _ = flatten_hw(x3_u)\n",
    "    x3_l, x3_u = interval_forward_tokenmixer(x3_l, x3_u, model.token_mixer_2)\n",
    "    x3_l, x3_u = unflatten_hw(x3_l, sh3), unflatten_hw(x3_u, sh3)\n",
    "    x4_l, x4_u = interval_forward_falconet(x3_l, x3_u, model.down3)\n",
    "    x4_l, sh4  = flatten_hw(x4_l); x4_u, _ = flatten_hw(x4_u)\n",
    "    x4_l, x4_u = interval_forward_tokenmixer(x4_l, x4_u, model.token_mixer_3)\n",
    "    x4_l, x4_u = unflatten_hw(x4_l, sh4), unflatten_hw(x4_u, sh4)\n",
    "    x5_l, x5_u = interval_forward_falconet(x4_l, x4_u, model.down4)\n",
    "    x5_l, sh5  = flatten_hw(x5_l); x5_u, _ = flatten_hw(x5_u)\n",
    "    x5_l, x5_u = interval_forward_tokenmixer(x5_l, x5_u, model.token_mixer_4)\n",
    "    x5_l, x5_u = unflatten_hw(x5_l, sh5), unflatten_hw(x5_u, sh5)\n",
    "\n",
    "    # up1..up3\n",
    "    def up_step(up, xl, xu, sk_l, sk_u):\n",
    "        xl = up.up(xl); xu = up.up(xu)\n",
    "        xl = torch.cat([sk_l, xl], dim=1)\n",
    "        xu = torch.cat([sk_u, xu], dim=1)\n",
    "        return interval_forward_falconet(xl, xu, up.conv)\n",
    "\n",
    "    x_l, x_u = up_step(model.up1, x5_l, x5_u, x4_l, x4_u)\n",
    "    x_l, x_u = up_step(model.up2, x_l,  x_u,  x3_l, x3_u)\n",
    "    x_l, x_u = up_step(model.up3, x_l,  x_u,  x2_l, x2_u)\n",
    "\n",
    "    # manual up4 pre-block capture + tail\n",
    "    pre_l = model.up4.up(x_l); pre_u = model.up4.up(x_u)\n",
    "    pre_l = torch.cat([x1_l, pre_l], dim=1)\n",
    "    pre_u = torch.cat([x1_u, pre_u], dim=1)\n",
    "    _quiet_set_tail(pre_l, pre_u, block=model.up4.conv, final_head=model.outc)\n",
    "\n",
    "    x_l, x_u = interval_forward_falconet(pre_l, pre_u, model.up4.conv)\n",
    "    return x_l, x_u\n",
    "\n",
    "# =========================\n",
    "# AttU-Net: autodetect encoder blocks by in_channels; tail at Up_conv2\n",
    "# =========================\n",
    "def propagate_prelogits_attunet(model, z):\n",
    "    x_l, x_u = z.lower, z.upper\n",
    "    mp = _attu_get_maxpool(model)\n",
    "\n",
    "    # collect encoder conv blocks and pick 3 levels by matching inC\n",
    "    blocks = _attunet_conv_blocks(model)\n",
    "    inC0 = x_l.shape[1]\n",
    "    _, name1, enc1 = _take_next_block(blocks, inC0)\n",
    "    x1_l, x1_u = interval_forward_attunet(x_l, x_u, enc1)\n",
    "\n",
    "    x2in_l, x2in_u = _maxpool2d_bounds(x1_l, x1_u, mp)\n",
    "    _, name2, enc2 = _take_next_block(blocks, x1_l.shape[1])\n",
    "    x2_l, x2_u = interval_forward_attunet(x2in_l, x2in_u, enc2)\n",
    "\n",
    "    x3in_l, x3in_u = _maxpool2d_bounds(x2_l, x2_u, mp)\n",
    "    _, name3, enc3 = _take_next_block(blocks, x2_l.shape[1])\n",
    "    x3_l, x3_u = interval_forward_attunet(x3in_l, x3in_u, enc3)\n",
    "\n",
    "    # decoder + attention (unchanged topology)\n",
    "    d4_l, d4_u = interval_forward_attunet(x3_l, x3_u, model.Up3)\n",
    "    x2l_att, x2u_att = interval_forward_attention_gate(model.Att3, d4_l, d4_u, x2_l, x2_u)\n",
    "    d4_l, d4_u = torch.cat([x2l_att, d4_l], 1), torch.cat([x2u_att, d4_u], 1)\n",
    "    d3_l, d3_u = interval_forward_attunet(d4_l, d4_u, model.Up_conv3)\n",
    "\n",
    "    d2u_l, d2u_u = interval_forward_attunet(d3_l, d3_u, model.Up2)\n",
    "    x1l_att, x1u_att = interval_forward_attention_gate(model.Att2, d2u_l, d2u_u, x1_l, x1_u)\n",
    "    pre_l, pre_u = torch.cat([x1l_att, d2u_l], 1), torch.cat([x1u_att, d2u_u], 1)\n",
    "\n",
    "    # tail on real last DoubleConv + final 1x1 head\n",
    "    _quiet_set_tail(pre_l, pre_u, block=model.Up_conv2, final_head=model.Conv_1x1)\n",
    "\n",
    "    d2_l, d2_u = interval_forward_attunet(pre_l, pre_u, model.Up_conv2)\n",
    "    return d2_l, d2_u\n",
    "\n",
    "# ——— install overrides ———\n",
    "globals()['propagate_prelogits_attunet']     = propagate_prelogits_attunet\n",
    "globals()['propagate_prelogits_encdecnet']   = propagate_prelogits_encdecnet\n",
    "globals()['propagate_prelogits_falconetmha'] = propagate_prelogits_falconetmha\n",
    "print(\"[ok] v12c: tail fixed (real last block + final conv), AttU-Net encoder autodetect + MaxPool-safe\")\n",
    "# === channel_selector_hotfix_v2 — makes rcd() safe ===\n",
    "import numpy as np, torch\n",
    "\n",
    "def anon_choose_change_channel(clean_logits, gt_mask):\n",
    "    \"\"\"\n",
    "    Robust, torch-based channel selection used by rcd().\n",
    "    - If binary head: (chg=1, nochg=0).\n",
    "    - Else: pick 'chg' as argmax IoU with GT at p>0.5; pick a different nchg.\n",
    "    \"\"\"\n",
    "    C = clean_logits.shape[1]\n",
    "    if C == 2:\n",
    "        return 1, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        p = torch.softmax(clean_logits, dim=1)[0]  # [C,H,W]\n",
    "\n",
    "    # GT -> boolean numpy [H,W]\n",
    "    if torch.is_tensor(gt_mask):\n",
    "        gt_np = (gt_mask.detach().cpu().numpy() > 0)\n",
    "    else:\n",
    "        gt_np = (np.asarray(gt_mask) > 0)\n",
    "\n",
    "    best_iou, best_chg = -1.0, 0\n",
    "    for c in range(C):\n",
    "        pred_c = (p[c] > 0.5).cpu().numpy()\n",
    "        union = np.logical_or(pred_c, gt_np).sum()\n",
    "        iou = (np.logical_and(pred_c, gt_np).sum() / max(1, union))\n",
    "        if iou > best_iou:\n",
    "            best_iou, best_chg = iou, c\n",
    "\n",
    "    best_nchg = (best_chg + 1) % C\n",
    "    return best_chg, best_nchg\n",
    "\n",
    "def logits_to_clean_pred(clean_logits, chg_idx, thresh=0.5):\n",
    "    \"\"\"\n",
    "    rcd() calls this to produce a clean binary mask. Keep it torch-native.\n",
    "    Returns a torch.BoolTensor [H,W].\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        if clean_logits.shape[1] == 2:\n",
    "            pred = (torch.argmax(clean_logits, dim=1)[0] == chg_idx)\n",
    "        else:\n",
    "            prob = torch.softmax(clean_logits, dim=1)[0, chg_idx]\n",
    "            pred = (prob > thresh)\n",
    "    return pred\n",
    "\n",
    "print(\"[hotfix] Patched anon_choose_change_channel/logits_to_clean_pred (uses torch.softmax; no np.exp).\")\n",
    "# === predicate_logger_safe_v7 — unbreakable mask coercion + GT reload ===\n",
    "import os, csv, itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "OUT = \"predicate_pass_v1.csv\"\n",
    "OSCD_PATH_TOP = globals().get(\"OSCD_PATH_TOP\", \"../onera/OSCD\")\n",
    "\n",
    "VERBOSE_COERCE = False  # flip to True if you want per-case shape messages\n",
    "\n",
    "def _np(x): return x.detach().cpu().numpy() if torch.is_tensor(x) else np.asarray(x)\n",
    "\n",
    "# ---------- GT loader ----------\n",
    "def _load_city_gt(city, H, W):\n",
    "    cm_path = os.path.join(str(OSCD_PATH_TOP).rstrip(\"/\"), city, \"cm\", \"cm.png\")\n",
    "    if not os.path.exists(cm_path):\n",
    "        raise FileNotFoundError(f\"GT not found: {cm_path}\")\n",
    "    im = Image.open(cm_path).convert(\"L\")\n",
    "    if im.size != (W, H):\n",
    "        im = im.resize((W, H), resample=Image.NEAREST)\n",
    "    arr = (np.array(im) > 0).astype(np.uint8)\n",
    "    if VERBOSE_COERCE:\n",
    "        print(f\"[gt] reloaded {city}/cm.png → {arr.shape}\")\n",
    "    return arr\n",
    "\n",
    "# ---------- shape coercion ----------\n",
    "def _force_hw_any(x, H, W, role=\"cert/clean\"):\n",
    "    \"\"\"\n",
    "    Coerce x → binary uint8 mask of shape [H,W].\n",
    "    For cert/clean we aggressively repair 1-D/3-D shapes.\n",
    "    For GT we still try strict first, then fallback to disk.\n",
    "    \"\"\"\n",
    "    a = _np(x); a = np.asarray(a); a = np.squeeze(a)\n",
    "\n",
    "    def _done(arr, why):\n",
    "        out = (arr > 0).astype(np.uint8)\n",
    "        if out.shape != (H, W):\n",
    "            raise ValueError(f\"{role}: coerced to {out.shape}, expected {(H,W)} (why={why})\")\n",
    "        if VERBOSE_COERCE and why:\n",
    "            print(f\"[coerce:{role}] {why} -> {out.shape}\")\n",
    "        return out\n",
    "\n",
    "    # perfect\n",
    "    if a.ndim == 2 and a.shape == (H, W):\n",
    "        return _done(a, \"2D exact\")\n",
    "\n",
    "    # transposed\n",
    "    if a.ndim == 2 and a.shape == (W, H):\n",
    "        return _done(a.T, \"2D transpose\")\n",
    "\n",
    "    # flattened to H*W\n",
    "    if a.ndim == 1 and a.size == H*W:\n",
    "        return _done(a.reshape(H, W), \"1D flatten H*W\")\n",
    "\n",
    "    # row/col vectors (common bug)\n",
    "    if a.ndim == 1 and a.size == H:\n",
    "        return _done(np.tile(a.reshape(H, 1), (1, W)), \"1D H→tile across W\")\n",
    "    if a.ndim == 1 and a.size == W:\n",
    "        return _done(np.tile(a.reshape(1, W), (H, 1)), \"1D W→tile across H\")\n",
    "\n",
    "    # 3D channel-ish\n",
    "    if a.ndim == 3:\n",
    "        # (1,H,W) / (H,W,1)\n",
    "        if a.shape[0] == 1 and a.shape[1:] == (H, W):\n",
    "            return _done(a[0], \"3D [1,H,W]→squeeze\")\n",
    "        if a.shape[-1] == 1 and a.shape[:2] == (H, W):\n",
    "            return _done(a[..., 0], \"3D [H,W,1]→squeeze\")\n",
    "        # (C,H,W) or (H,W,C): any-nonzero\n",
    "        if a.shape[1:] == (H, W):\n",
    "            return _done((a != 0).any(axis=0).astype(np.uint8), \"3D [C,H,W] any\")\n",
    "        if a.shape[:2] == (H, W):\n",
    "            return _done((a != 0).any(axis=-1).astype(np.uint8), \"3D [H,W,C] any\")\n",
    "\n",
    "    # last resort: if one dim matches H or W, try to broadcast\n",
    "    if a.ndim == 2:\n",
    "        if a.shape[0] == H and a.shape[1] == 1:\n",
    "            return _done(np.tile(a, (1, W)), \"2D [H,1]→tile W\")\n",
    "        if a.shape[1] == W and a.shape[0] == 1:\n",
    "            return _done(np.tile(a, (H, 1)), \"2D [1,W]→tile H\")\n",
    "\n",
    "    # if GT → reload from disk; otherwise give a descriptive error\n",
    "    if role == \"gt\":\n",
    "        return _load_city_gt(city=\"(unknown)\", H=H, W=W)  # will be replaced by caller with real city\n",
    "    raise ValueError(f\"{role}: cannot coerce shape {a.shape} to {(H,W)}\")\n",
    "\n",
    "def _force_gt_hw(gt_mask, city, H, W):\n",
    "    # Try strict-ish first; reload on failure.\n",
    "    try:\n",
    "        return _force_hw_any(gt_mask, H, W, role=\"gt\")\n",
    "    except Exception as e:\n",
    "        if VERBOSE_COERCE:\n",
    "            print(f\"[gt] {city}: {e} → reload cm.png\")\n",
    "        return _load_city_gt(city, H, W)\n",
    "\n",
    "# ---------- CC + predicates ----------\n",
    "def _connected_components_4(mask_hw_uint8):\n",
    "    m = (mask_hw_uint8 > 0).astype(np.uint8)\n",
    "    H, W = m.shape\n",
    "    vis = np.zeros((H, W), dtype=np.uint8)\n",
    "    sizes = []\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            if m[i, j] and not vis[i, j]:\n",
    "                stack = [(i, j)]\n",
    "                vis[i, j] = 1\n",
    "                sz = 0\n",
    "                while stack:\n",
    "                    r, c = stack.pop(); sz += 1\n",
    "                    for dr, dc in ((1,0),(-1,0),(0,1),(0,-1)):\n",
    "                        rr, cc = r+dr, c+dc\n",
    "                        if 0 <= rr < H and 0 <= cc < W and m[rr, cc] and not vis[rr, cc]:\n",
    "                            vis[rr, cc] = 1; stack.append((rr, cc))\n",
    "                sizes.append(sz)\n",
    "    return sizes\n",
    "\n",
    "def _predicates(Ccert, Cclean, Cgt, rho, gamma, s_min):\n",
    "    Ccert = (Ccert > 0); Cclean = (Cclean > 0); Cgt = (Cgt > 0)\n",
    "    denom = max(1, Cclean.sum())\n",
    "    overlap = np.logical_and(Ccert, Cclean).sum() / denom\n",
    "    Poverlap = (overlap >= rho)\n",
    "    cert_sz = Ccert.sum()\n",
    "    fp = 0.0 if cert_sz == 0 else (np.logical_and(Ccert, np.logical_not(Cgt)).sum() / cert_sz)\n",
    "    Pfp = (fp <= gamma)\n",
    "    sizes = _connected_components_4(Ccert.astype(np.uint8))\n",
    "    Ppattern = all(sz >= s_min for sz in sizes)\n",
    "    Pstrict = (Poverlap and Pfp and Ppattern)\n",
    "    largest_cc = max(sizes) if sizes else 0\n",
    "    return Poverlap, Pfp, Ppattern, Pstrict, float(overlap), float(fp), int(largest_cc)\n",
    "\n",
    "# ---------- channel selection (torch-only) ----------\n",
    "def _choose_channels(clean_logits, gt_mask, city):\n",
    "    C = int(clean_logits.shape[1])\n",
    "    if C == 2:\n",
    "        return 1, 0\n",
    "    with torch.no_grad():\n",
    "        p = torch.softmax(clean_logits, dim=1)[0]  # [C,H,W]\n",
    "    H, W = int(p.shape[-2]), int(p.shape[-1])\n",
    "    gt_hw = _force_gt_hw(gt_mask, city, H, W).astype(bool)\n",
    "    best_iou, best_chg = -1.0, 0\n",
    "    for c in range(C):\n",
    "        pred_c = (p[c] > 0.5).cpu().numpy()\n",
    "        union = np.logical_or(pred_c, gt_hw).sum()\n",
    "        iou = (np.logical_and(pred_c, gt_hw).sum() / max(1, union))\n",
    "        if iou > best_iou:\n",
    "            best_iou, best_chg = iou, c\n",
    "    best_nchg = (best_chg + 1) % C\n",
    "    return best_chg, best_nchg\n",
    "\n",
    "# ---------- one combo ----------\n",
    "def _one_combo(model_name, model, model_type, city, eps, rho, gamma, s_min):\n",
    "    # rcd() -> lower, upper, clean_logits, clean_pred, gt_mask\n",
    "    lower, upper, clean_logits, clean_pred, gt_mask = rcd(model, model_type, city, eps)\n",
    "    H, W = int(clean_logits.shape[-2]), int(clean_logits.shape[-1])\n",
    "\n",
    "    chg, nchg = _choose_channels(clean_logits, gt_mask, city)\n",
    "\n",
    "    # certified set: margin LB > 0\n",
    "    mL = (lower[0, chg] - upper[0, nchg])  # [H,W] ideally\n",
    "    Ccert = _force_hw_any((mL > 0), H, W, role=\"cert/clean\")\n",
    "\n",
    "    # clean predicted change set\n",
    "    with torch.no_grad():\n",
    "        if clean_logits.shape[1] == 2:\n",
    "            Cclean_t = (torch.argmax(clean_logits, dim=1)[0] == chg)  # [H,W]\n",
    "        else:\n",
    "            Cclean_t = (torch.softmax(clean_logits, dim=1)[0, chg] > 0.5)\n",
    "    Cclean = _force_hw_any(Cclean_t, H, W, role=\"cert/clean\")\n",
    "\n",
    "    # GT\n",
    "    Cgt = _force_gt_hw(gt_mask, city, H, W)\n",
    "\n",
    "    Poverlap, Pfp, Ppattern, Pstrict, overlap, fp, largest_cc = _predicates(\n",
    "        Ccert, Cclean, Cgt, rho, gamma, s_min\n",
    "    )\n",
    "    return {\n",
    "        \"model\": model_name, \"type\": int(model_type), \"city\": city, \"eps\": float(eps),\n",
    "        \"rho\": float(rho), \"gamma\": float(gamma), \"s_min\": int(s_min),\n",
    "        \"strict\": bool(Pstrict), \"Poverlap\": bool(Poverlap), \"Pfp\": bool(Pfp), \"Ppattern\": bool(Ppattern),\n",
    "        \"overlap\": float(overlap), \"fp\": float(fp), \"largest_cc\": int(largest_cc)\n",
    "    }\n",
    "\n",
    "# ---------- driver ----------\n",
    "def run_predicate_logger(MODELS, CITIES, EPS,\n",
    "                         rho_main=0.30, gamma_main=0.30, smin_main=16,\n",
    "                         appendix=False,\n",
    "                         rho_grid=(0.20,0.30,0.40),\n",
    "                         gamma_grid=(0.20,0.30,0.40),\n",
    "                         smin_grid=(8,16,32),\n",
    "                         out_path=OUT):\n",
    "    header = [\"model\",\"type\",\"city\",\"eps\",\"rho\",\"gamma\",\"s_min\",\n",
    "              \"strict\",\"Poverlap\",\"Pfp\",\"Ppattern\",\"overlap\",\"fp\",\"largest_cc\"]\n",
    "    rows = []\n",
    "\n",
    "    def _append(args):\n",
    "        try:\n",
    "            rows.append(_one_combo(*args))\n",
    "        except Exception as e:\n",
    "            name, _, _, city, eps, rho, gamma, smin = args[0], args[1], args[2], args[3], args[4], args[5], args[6], args[7]\n",
    "            print(f\"[skip] {name}/{city}/eps={eps:.5f} (rho={rho},gamma={gamma},s={smin}): {e}\")\n",
    "\n",
    "    # main table\n",
    "    for (model_name, model, model_type) in MODELS:\n",
    "        for city in CITIES:\n",
    "            for eps in EPS:\n",
    "                _append((model_name, model, model_type, city, eps, rho_main, gamma_main, smin_main))\n",
    "\n",
    "    # appendix\n",
    "    if appendix:\n",
    "        for (model_name, model, model_type) in MODELS:\n",
    "            for city in CITIES:\n",
    "                for eps in EPS:\n",
    "                    for rho in rho_grid:\n",
    "                        for gamma in gamma_grid:\n",
    "                            for smin in smin_grid:\n",
    "                                _append((model_name, model, model_type, city, eps, rho, gamma, smin))\n",
    "\n",
    "    with open(out_path, \"w\", newline=\"\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=header); w.writeheader(); w.writerows(rows)\n",
    "    print(f\"[predicates] wrote {len(rows)} rows → {os.path.abspath(out_path)}\")\n",
    "    return rows\n",
    "\n",
    "print(\"[ok] predicate_logger_safe_v7 loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5abd8d3-93f3-4944-850a-17555032df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = run_predicate_logger(\n",
    "#         MODELS, CITIES, EPS,\n",
    "#         rho_main=0.30, gamma_main=0.30, smin_main=16,\n",
    "#         appendix=False,\n",
    "#         out_path=\"predicate_pass_v1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31f0c35d-aa98-4817-810b-34d117d87497",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # === make_table_predicate_strict_main_v2.py ===\n",
    "# # Build the main \"Strict predicate certification under OOD\" LaTeX table\n",
    "# # from predicate_pass_v1.csv (created by the logger).\n",
    "\n",
    "# import csv, math, os\n",
    "# from collections import defaultdict\n",
    "\n",
    "# # ---- INPUT / OUTPUT ----\n",
    "# CSV_IN  = \"predicate_pass_v1.csv\"        # adjust path if needed\n",
    "# TEX_OUT = \"table_predicate_strict_main.tex\"\n",
    "\n",
    "# if not os.path.exists(CSV_IN):\n",
    "#     raise FileNotFoundError(f\"{CSV_IN} not found. Run the logger first or point CSV_IN to the file.\")\n",
    "\n",
    "# # ---- helpers ----\n",
    "# def _nice_eps(e):\n",
    "#     k = round(float(e) * 255)\n",
    "#     if abs(float(e) - k/255) < 1e-6 and 0 <= k <= 64:\n",
    "#         return f\"{k}/255\"\n",
    "#     s = f\"{float(e):.5f}\".rstrip(\"0\").rstrip(\".\")\n",
    "#     return s\n",
    "\n",
    "# def _to_bool(v):\n",
    "#     return str(v).strip().lower() in (\"true\",\"1\",\"t\",\"yes\",\"y\")\n",
    "\n",
    "# def _median(vals):\n",
    "#     if not vals: return float(\"nan\")\n",
    "#     s = sorted(vals)\n",
    "#     n = len(s)\n",
    "#     mid = n // 2\n",
    "#     return s[mid] if n % 2 == 1 else 0.5*(s[mid-1] + s[mid])\n",
    "\n",
    "# def _fmt_pct(x):\n",
    "#     if math.isnan(x): return \"na\"\n",
    "#     return f\"{x:.0f}\" if abs(x - round(x)) < 1e-6 else f\"{x:.1f}\"\n",
    "\n",
    "# def _fmt_float(x, nd=2):\n",
    "#     return \"na\" if (x is None or (isinstance(x,float) and math.isnan(x))) else f\"{x:.{nd}f}\"\n",
    "\n",
    "# # Desired display order (feel free to edit)\n",
    "# MODEL_ORDER = [\"AttU-Net\", \"EncDec\", \"FALCONet\"]\n",
    "# EPS_ORDER   = [\"0/255\", \"1/255\", \"2/255\"]\n",
    "\n",
    "# # Main-paper predicate setting\n",
    "# RHO_MAIN, GAMMA_MAIN, SMIN_MAIN = 0.30, 0.30, 16\n",
    "\n",
    "# # ---- Load rows & filter to main-paper predicate triplet ----\n",
    "# rows = []\n",
    "# with open(CSV_IN, newline=\"\") as f:\n",
    "#     r = csv.DictReader(f)\n",
    "#     for d in r:\n",
    "#         try:\n",
    "#             if (abs(float(d[\"rho\"]) - RHO_MAIN) < 1e-9 and\n",
    "#                 abs(float(d[\"gamma\"]) - GAMMA_MAIN) < 1e-9 and\n",
    "#                 int(float(d[\"s_min\"])) == SMIN_MAIN):\n",
    "#                 rows.append({\n",
    "#                     \"model\": d[\"model\"],\n",
    "#                     \"eps_val\": float(d[\"eps\"]),\n",
    "#                     \"strict\": _to_bool(d[\"strict\"]),\n",
    "#                     \"overlap\": float(d[\"overlap\"]),\n",
    "#                     \"fp\": float(d[\"fp\"]),\n",
    "#                 })\n",
    "#         except Exception:\n",
    "#             pass\n",
    "\n",
    "# if not rows:\n",
    "#     raise RuntimeError(\"No rows for main-paper predicate setting \"\n",
    "#                        f\"(rho={RHO_MAIN}, gamma={GAMMA_MAIN}, s_min={SMIN_MAIN}).\")\n",
    "\n",
    "# # ---- Group by (model, eps) ----\n",
    "# grp = defaultdict(list)\n",
    "# for d in rows:\n",
    "#     grp[(d[\"model\"], d[\"eps_val\"])].append(d)\n",
    "\n",
    "# # ---- Aggregate per (model, eps) ----\n",
    "# summary = []\n",
    "# for (model, eps_val), lst in grp.items():\n",
    "#     n = len(lst)\n",
    "#     pass_rate = 100.0 * sum(1 for x in lst if x[\"strict\"]) / max(1, n)\n",
    "#     med_overlap = _median([x[\"overlap\"] for x in lst])\n",
    "#     med_fp      = _median([x[\"fp\"] for x in lst])\n",
    "#     summary.append({\n",
    "#         \"model\": model,\n",
    "#         \"eps_val\": eps_val,\n",
    "#         \"eps_str\": _nice_eps(eps_val),\n",
    "#         \"n\": n,\n",
    "#         \"pass_pct\": pass_rate,\n",
    "#         \"med_overlap\": med_overlap,\n",
    "#         \"med_fp\": med_fp,\n",
    "#     })\n",
    "\n",
    "# # ---- Sort consistently: (model rank, eps rank, fallback by numeric eps, names) ----\n",
    "# def _model_rank(m): return MODEL_ORDER.index(m) if m in MODEL_ORDER else len(MODEL_ORDER)\n",
    "# def _eps_rank(s):   return EPS_ORDER.index(s) if s in EPS_ORDER else len(EPS_ORDER)\n",
    "\n",
    "# summary.sort(key=lambda d: (_model_rank(d[\"model\"]),\n",
    "#                             _eps_rank(d[\"eps_str\"]),\n",
    "#                             d[\"eps_val\"], d[\"model\"], d[\"eps_str\"]))\n",
    "\n",
    "# # ---- Emit LaTeX ----\n",
    "# lines = []\n",
    "# lines.append(r\"\\begin{table}[t]\")\n",
    "# lines.append(r\"\\centering\")\n",
    "# lines.append(r\"\\caption{\\textbf{Strict predicate certification under OOD.} Pass rate (\\%), median overlap and median FP for \" +\n",
    "#              rf\"$\\rho={RHO_MAIN:.2f}$, $\\gamma={GAMMA_MAIN:.2f}$, $s_{{\\min}}={SMIN_MAIN}$\" + r\".}\")\n",
    "# lines.append(r\"\\label{tab:strict_predicate_main}\")\n",
    "# lines.append(r\"\\begin{tabular}{lcccc}\")\n",
    "# lines.append(r\"\\toprule\")\n",
    "# lines.append(r\"\\textbf{Model} & $\\boldsymbol{\\varepsilon}$ & $\\boldsymbol{n}$ & \\textbf{Strict pass (\\%)} & \\textbf{Median overlap / FP} \\\\\")\n",
    "# lines.append(r\"\\midrule\")\n",
    "\n",
    "# last_model = None\n",
    "# for row in summary:\n",
    "#     model = row[\"model\"]\n",
    "#     eps   = row[\"eps_str\"]\n",
    "#     n     = row[\"n\"]\n",
    "#     pp    = _fmt_pct(row[\"pass_pct\"])\n",
    "#     mOv   = _fmt_float(row[\"med_overlap\"], 2)\n",
    "#     mFp   = _fmt_float(row[\"med_fp\"], 2)\n",
    "#     if last_model is not None and model != last_model:\n",
    "#         lines.append(r\"\\midrule\")\n",
    "#     last_model = model\n",
    "#     lines.append(f\"{model} & ${eps}$ & {n} & {pp} & {mOv} / {mFp} \\\\\\\\\")\n",
    "\n",
    "# lines.append(r\"\\bottomrule\")\n",
    "# lines.append(r\"\\end{tabular}\")\n",
    "# lines.append(r\"\\end{table}\")\n",
    "\n",
    "# with open(TEX_OUT, \"w\") as f:\n",
    "#     f.write(\"\\n\".join(lines))\n",
    "\n",
    "# print(f\"[ok] wrote LaTeX → {os.path.abspath(TEX_OUT)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "022c7ced-b5f6-4e5d-b713-21454b6f80ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = run_sweep(MODELS, cities=CITIES, eps_grid=EPS, rho_grid=RHO, gamma_grid=GAMMA, s_min_grid=SMIN,\n",
    "#               out_csv=\"predicate_summary_semantic_v7.csv\", write_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c63f5e04-a6f5-43a4-bb99-75d61236bc44",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # === predicate_logger_safe_v6 — robust shapes + robust channel chooser + LaTeX ===\n",
    "# import os, csv, math, numpy as np, torch\n",
    "# from collections import defaultdict\n",
    "\n",
    "# CSV_OUT = \"predicate_pass_v1.csv\"\n",
    "# TEX_OUT = \"table_predicate_strict_main.tex\"\n",
    "\n",
    "# # ---------- shape helpers ----------\n",
    "# def _to_np(x):\n",
    "#     return x.detach().cpu().numpy() if torch.is_tensor(x) else np.asarray(x)\n",
    "\n",
    "# def _coerce_bin_hw(mask):\n",
    "#     \"\"\"\n",
    "#     Return 2-D [H,W] uint8 (0/1).\n",
    "#     Accepts: torch/numpy with shapes [H,W], [1,H,W], [H,W,1], [C,H,W], [H,W,C], [1,C,H,W].\n",
    "#     \"\"\"\n",
    "#     m = _to_np(mask)\n",
    "#     m = np.asarray(m)\n",
    "#     m = np.squeeze(m)\n",
    "#     if m.ndim == 3:  # reduce channels\n",
    "#         if m.shape[0] == 1:\n",
    "#             m = m[0]\n",
    "#         elif m.shape[-1] == 1:\n",
    "#             m = m[..., 0]\n",
    "#         else:\n",
    "#             m = (m != 0).any(axis=0).astype(np.uint8)\n",
    "#     if m.ndim != 2:\n",
    "#         raise ValueError(f\"_coerce_bin_hw: expected 2-D after squeeze, got shape {m.shape}\")\n",
    "#     return (m > 0).astype(np.uint8)\n",
    "\n",
    "# def _slice_ch(t, ch):\n",
    "#     \"\"\"\n",
    "#     Extract a single class map as [H,W] tensor from bounds/logits with shape:\n",
    "#     [C,H,W] or [1,C,H,W] or [N,C,H,W] (with N=1).\n",
    "#     \"\"\"\n",
    "#     if not torch.is_tensor(t):\n",
    "#         t = torch.as_tensor(t)\n",
    "#     if t.dim() == 4:\n",
    "#         return t[0, ch]          # [1,C,H,W] or [N=1,C,H,W]\n",
    "#     elif t.dim() == 3:\n",
    "#         return t[ch]             # [C,H,W]\n",
    "#     else:\n",
    "#         raise ValueError(f\"_slice_ch: expected 3D/4D tensor, got shape {tuple(t.shape)}\")\n",
    "\n",
    "# def _logits_CHW(clean_logits):\n",
    "#     \"\"\"Return logits as [C,H,W] (squeeze batch if present).\"\"\"\n",
    "#     z = clean_logits\n",
    "#     if z.dim() == 4:   # [1,C,H,W]\n",
    "#         z = z[0]\n",
    "#     if z.dim() != 3:\n",
    "#         raise ValueError(f\"_logits_CHW: expected [C,H,W] (or [1,C,H,W]), got {tuple(clean_logits.shape)}\")\n",
    "#     return z\n",
    "\n",
    "# def _argmax_HW(clean_logits):\n",
    "#     \"\"\"Return argmax label map [H,W] from logits shaped [C,H,W] or [1,C,H,W].\"\"\"\n",
    "#     if clean_logits.dim() == 4:\n",
    "#         return torch.argmax(clean_logits, dim=1)[0]\n",
    "#     elif clean_logits.dim() == 3:\n",
    "#         return torch.argmax(clean_logits, dim=0)\n",
    "#     else:\n",
    "#         raise ValueError(f\"_argmax_HW: expected 3D/4D logits, got {tuple(clean_logits.shape)}\")\n",
    "\n",
    "# # ---------- CC + predicates ----------\n",
    "# def _connected_components_4(mask_bin):\n",
    "#     m = _coerce_bin_hw(mask_bin)\n",
    "#     H, W = m.shape\n",
    "#     lab = np.zeros((H,W), dtype=np.int32)\n",
    "#     sizes, cur = [], 0\n",
    "#     for i in range(H):\n",
    "#         for j in range(W):\n",
    "#             if m[i,j] and lab[i,j]==0:\n",
    "#                 cur += 1\n",
    "#                 stack = [(i,j)]; lab[i,j] = cur; sz = 0\n",
    "#                 while stack:\n",
    "#                     r,c = stack.pop(); sz += 1\n",
    "#                     for dr,dc in ((1,0),(-1,0),(0,1),(0,-1)):\n",
    "#                         rr,cc = r+dr, c+dc\n",
    "#                         if 0<=rr<H and 0<=cc<W and m[rr,cc] and lab[rr,cc]==0:\n",
    "#                             lab[rr,cc] = cur; stack.append((rr,cc))\n",
    "#                 sizes.append(sz)\n",
    "#     return sizes\n",
    "\n",
    "# def _predicates(Ccert, Cclean, Cgt, rho, gamma, s_min):\n",
    "#     Ccert = _coerce_bin_hw(Ccert).astype(bool)\n",
    "#     Cclean = _coerce_bin_hw(Cclean).astype(bool)\n",
    "#     Cgt = _coerce_bin_hw(Cgt).astype(bool)\n",
    "\n",
    "#     denom = max(1, Cclean.sum())\n",
    "#     overlap = np.logical_and(Ccert, Cclean).sum() / denom\n",
    "#     Poverlap = (overlap >= rho)\n",
    "\n",
    "#     cert_sz = Ccert.sum()\n",
    "#     fp = 0.0 if cert_sz == 0 else (np.logical_and(Ccert, np.logical_not(Cgt)).sum() / cert_sz)\n",
    "#     Pfp = (fp <= gamma)\n",
    "\n",
    "#     sizes = _connected_components_4(Ccert.astype(np.uint8))\n",
    "#     Ppattern = all(sz >= s_min for sz in sizes)\n",
    "\n",
    "#     return Poverlap, Pfp, Ppattern, (Poverlap and Pfp and Ppattern), overlap, fp, (max(sizes) if sizes else 0)\n",
    "\n",
    "# # ---------- robust channel chooser (IoU vs GT) ----------\n",
    "# def _choose_channels(clean_logits, gt_mask):\n",
    "#     \"\"\"\n",
    "#     Choose \"change\" channel by max IoU(pred_c, GT). Non-change is the other (binary)\n",
    "#     or the most background-like among the rest for multi-class.\n",
    "#     \"\"\"\n",
    "#     z = _logits_CHW(clean_logits)           # [C,H,W]\n",
    "#     p = torch.softmax(z, dim=0)             # [C,H,W]\n",
    "#     gt = _coerce_bin_hw(gt_mask).astype(bool)\n",
    "#     C = z.shape[0]\n",
    "\n",
    "#     ious = []\n",
    "#     for c in range(C):\n",
    "#         pred_c = (p[c] > 0.5).cpu().numpy()\n",
    "#         inter = np.logical_and(pred_c, gt).sum()\n",
    "#         union = np.logical_or(pred_c, gt).sum()\n",
    "#         iou = inter / max(1, union)\n",
    "#         ious.append(iou)\n",
    "#     chg = int(np.argmax(ious))\n",
    "\n",
    "#     if C == 2:\n",
    "#         nchg = 1 - chg\n",
    "#     else:\n",
    "#         # pick background-like: highest mean prob on GT==0\n",
    "#         nz = np.where(~gt)\n",
    "#         bg_scores = []\n",
    "#         for c in range(C):\n",
    "#             if c == chg: continue\n",
    "#             if nz[0].size:\n",
    "#                 bg_scores.append((p[c][nz].mean().item(), c))\n",
    "#             else:\n",
    "#                 bg_scores.append((p[c].mean().item(), c))\n",
    "#         nchg = max(bg_scores)[1] if bg_scores else (chg + 1) % C\n",
    "\n",
    "#     return chg, nchg\n",
    "\n",
    "# # ---------- one combo ----------\n",
    "# def _one_combo(model_name, model, model_type, city, eps, rho, gamma, s_min):\n",
    "#     # rcd() must be defined in your notebook; returns\n",
    "#     # (lower, upper, clean_logits, clean_pred, gt_mask)\n",
    "#     lower, upper, clean_logits, clean_pred, gt_mask = rcd(model, model_type, city, eps)\n",
    "\n",
    "#     # choose channels robustly\n",
    "#     chg, nchg = _choose_channels(clean_logits, gt_mask)\n",
    "\n",
    "#     # certified set from margin LB>0 (supports [C,H,W] or [1,C,H,W])\n",
    "#     mL = _slice_ch(lower, chg) - _slice_ch(upper, nchg)  # [H,W]\n",
    "#     Ccert = (mL > 0)\n",
    "\n",
    "#     # clean predicted change set\n",
    "#     if clean_logits.shape[1] == 2:\n",
    "#         Cclean = (_argmax_HW(clean_logits) == chg)       # [H,W]\n",
    "#     else:\n",
    "#         z = _logits_CHW(clean_logits)\n",
    "#         Cclean = (torch.softmax(z, dim=0)[chg] > 0.5)\n",
    "\n",
    "#     Cgt = gt_mask\n",
    "\n",
    "#     Poverlap, Pfp, Ppattern, Pstrict, overlap, fp, largest_cc = \\\n",
    "#         _predicates(Ccert, Cclean, Cgt, rho, gamma, s_min)\n",
    "\n",
    "#     return {\n",
    "#         \"model\": model_name, \"type\": int(model_type), \"city\": city, \"eps\": float(eps),\n",
    "#         \"rho\": float(rho), \"gamma\": float(gamma), \"s_min\": int(s_min),\n",
    "#         \"strict\": bool(Pstrict), \"Poverlap\": bool(Poverlap), \"Pfp\": bool(Pfp), \"Ppattern\": bool(Ppattern),\n",
    "#         \"overlap\": float(overlap), \"fp\": float(fp), \"largest_cc\": int(largest_cc)\n",
    "#     }\n",
    "\n",
    "# # ---------- driver (main table only) ----------\n",
    "# def run_predicate_logger(MODELS, CITIES, EPS,\n",
    "#                          rho_main=0.30, gamma_main=0.30, smin_main=16,\n",
    "#                          out_path=CSV_OUT):\n",
    "#     header = [\"model\",\"type\",\"city\",\"eps\",\"rho\",\"gamma\",\"s_min\",\n",
    "#               \"strict\",\"Poverlap\",\"Pfp\",\"Ppattern\",\n",
    "#               \"overlap\",\"fp\",\"largest_cc\"]\n",
    "#     rows = []\n",
    "#     def _append_safe(args):\n",
    "#         try:\n",
    "#             rows.append(_one_combo(*args))\n",
    "#         except Exception as e:\n",
    "#             name, _, _, city, eps, rho, gamma, smin = args[0], args[1], args[2], args[3], args[4], args[5], args[6], args[7]\n",
    "#             print(f\"[warn] logger skip {name}/{city}/eps={eps:.5f} (rho={rho},gamma={gamma},s={smin}): {e}\")\n",
    "\n",
    "#     for (model_name, model, model_type) in MODELS:\n",
    "#         for city in CITIES:\n",
    "#             for eps in EPS:\n",
    "#                 _append_safe((model_name, model, model_type, city, eps, rho_main, gamma_main, smin_main))\n",
    "\n",
    "#     with open(out_path, \"w\", newline=\"\") as f:\n",
    "#         w = csv.DictWriter(f, fieldnames=header); w.writeheader(); w.writerows(rows)\n",
    "#     print(f\"[predicates] wrote {len(rows)} rows → {os.path.abspath(out_path)}\")\n",
    "#     return rows\n",
    "\n",
    "# # ---------- build LaTeX from CSV ----------\n",
    "# def _nice_eps(e):\n",
    "#     e = float(e)\n",
    "#     k = round(e*255)\n",
    "#     return f\"{k}/255\" if abs(e - k/255) < 1e-6 and 0 <= k <= 64 else f\"{e:.5f}\".rstrip(\"0\").rstrip(\".\")\n",
    "\n",
    "# def _median(vals):\n",
    "#     if not vals: return float(\"nan\")\n",
    "#     s = sorted(vals); n=len(s); mid=n//2\n",
    "#     return s[mid] if n%2 else 0.5*(s[mid-1]+s[mid])\n",
    "\n",
    "# def build_strict_table(csv_path=CSV_OUT, tex_out=TEX_OUT,\n",
    "#                        rho=0.30, gamma=0.30, smin=16,\n",
    "#                        model_order=(\"AttU-Net\",\"EncDec\",\"FALCONet\"),\n",
    "#                        eps_order=(\"0/255\",\"1/255\",\"2/255\")):\n",
    "#     rows = []\n",
    "#     with open(csv_path, newline=\"\") as f:\n",
    "#         r = csv.DictReader(f)\n",
    "#         for d in r:\n",
    "#             if abs(float(d[\"rho\"])-rho)<1e-9 and abs(float(d[\"gamma\"])-gamma)<1e-9 and int(float(d[\"s_min\"]))==smin:\n",
    "#                 rows.append({\"model\": d[\"model\"],\n",
    "#                              \"eps_val\": float(d[\"eps\"]),\n",
    "#                              \"eps_str\": _nice_eps(d[\"eps\"]),\n",
    "#                              \"strict\": str(d[\"strict\"]).lower() in (\"true\",\"1\",\"t\",\"yes\",\"y\"),\n",
    "#                              \"overlap\": float(d[\"overlap\"]),\n",
    "#                              \"fp\": float(d[\"fp\"])})\n",
    "\n",
    "#     grp = defaultdict(list)\n",
    "#     for d in rows: grp[(d[\"model\"], d[\"eps_str\"], d[\"eps_val\"])].append(d)\n",
    "\n",
    "#     summary = []\n",
    "#     for (m, es, ev), lst in grp.items():\n",
    "#         n = len(lst)\n",
    "#         pass_pct = 100.0*sum(x[\"strict\"] for x in lst)/max(1,n)\n",
    "#         med_overlap = _median([x[\"overlap\"] for x in lst])\n",
    "#         med_fp      = _median([x[\"fp\"] for x in lst])\n",
    "#         summary.append({\"model\": m, \"eps_str\": es, \"eps_val\": ev, \"n\": n,\n",
    "#                         \"pass_pct\": pass_pct, \"med_overlap\": med_overlap, \"med_fp\": med_fp})\n",
    "\n",
    "#     def _mkey(m):  return model_order.index(m) if m in model_order else len(model_order)\n",
    "#     def _ekey(es): return eps_order.index(es) if es in eps_order else len(eps_order)\n",
    "#     summary.sort(key=lambda d: (_mkey(d[\"model\"]), _ekey(d[\"eps_str\"]), d[\"eps_val\"]))\n",
    "\n",
    "#     lines = []\n",
    "#     lines += [r\"\\begin{table}[t]\", r\"\\centering\",\n",
    "#               r\"\\caption{\\textbf{Strict predicate certification under OOD.} Pass rate (\\%), median overlap and median FP for $\\rho=0.30$, $\\gamma=0.30$, $s_{\\min}=16$.}\",\n",
    "#               r\"\\label{tab:strict_predicate_main}\",\n",
    "#               r\"\\begin{tabular}{lcccc}\", r\"\\toprule\",\n",
    "#               r\"\\textbf{Model} & $\\boldsymbol{\\varepsilon}$ & $\\boldsymbol{n}$ & \\textbf{Strict pass (\\%)} & \\textbf{Median overlap / FP} \\\\\",\n",
    "#               r\"\\midrule\"]\n",
    "#     last = None\n",
    "#     for r in summary:\n",
    "#         if last is not None and r[\"model\"] != last:\n",
    "#             lines.append(r\"\\midrule\")\n",
    "#         last = r[\"model\"]\n",
    "#         lines.append(f'{r[\"model\"]} & ${r[\"eps_str\"]}$ & {r[\"n\"]} & '\n",
    "#                      f'{r[\"pass_pct\"]:.0f} & {r[\"med_overlap\"]:.2f} / {r[\"med_fp\"]:.2f} \\\\\\\\')\n",
    "#     lines += [r\"\\bottomrule\", r\"\\end{tabular}\", r\"\\end{table}\"]\n",
    "\n",
    "#     with open(tex_out, \"w\") as f:\n",
    "#         f.write(\"\\n\".join(lines))\n",
    "#     print(f\"[ok] wrote LaTeX → {os.path.abspath(tex_out)}\")\n",
    "\n",
    "# # ---------- run ----------\n",
    "# _ = run_predicate_logger(MODELS, CITIES, EPS, rho_main=0.30, gamma_main=0.30, smin_main=16)\n",
    "# build_strict_table(CSV_OUT, TEX_OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf994dfb-f6e7-4304-94d5-50217e5dc649",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # --- Visualize Ccert / Cclean / Cgt for a few seeds (one per {model, city, eps}) ---\n",
    "# # Requires: your `rcd()` function and the same MODELS, CITIES, EPS you used to log the CSV\n",
    "# # Output PNGs go to ./viz_predicates/\n",
    "\n",
    "# import os, numpy as np, torch\n",
    "# from PIL import Image\n",
    "# os.makedirs(\"viz_predicates\", exist_ok=True)\n",
    "\n",
    "# def _to_np(x): return x.detach().cpu().numpy() if torch.is_tensor(x) else np.asarray(x)\n",
    "# def _coerce_bin_hw(x):\n",
    "#     m = _to_np(x); m = np.squeeze(m)\n",
    "#     if m.ndim == 3:\n",
    "#         if m.shape[0] == 1: m = m[0]\n",
    "#         elif m.shape[-1] == 1: m = m[...,0]\n",
    "#         else: m = (m!=0).any(axis=0).astype(np.uint8)\n",
    "#     assert m.ndim==2, f\"mask not 2D: {m.shape}\"\n",
    "#     return (m>0).astype(np.uint8)\n",
    "\n",
    "# def _logits_CHW(z):\n",
    "#     if z.dim()==4: z=z[0]\n",
    "#     assert z.dim()==3, z.shape\n",
    "#     return z\n",
    "\n",
    "# def _choose_channels(clean_logits, gt_mask):\n",
    "#     z = _logits_CHW(clean_logits)\n",
    "#     p = torch.softmax(z, dim=0)\n",
    "#     gt = _coerce_bin_hw(gt_mask).astype(bool)\n",
    "#     C = z.shape[0]\n",
    "#     ious=[]\n",
    "#     for c in range(C):\n",
    "#         pred = (p[c]>0.5).cpu().numpy()\n",
    "#         inter = np.logical_and(pred, gt).sum()\n",
    "#         union = np.logical_or(pred, gt).sum()\n",
    "#         ious.append(inter/max(1,union))\n",
    "#     chg = int(np.argmax(ious))\n",
    "#     nchg = 1-chg if C==2 else (chg+1)%C\n",
    "#     return chg,nchg\n",
    "\n",
    "# def _slice_ch(t, ch):\n",
    "#     if t.dim()==4: return t[0, ch]\n",
    "#     elif t.dim()==3: return t[ch]\n",
    "#     else: raise ValueError(t.shape)\n",
    "\n",
    "# def _argmax_HW(z):\n",
    "#     return torch.argmax(z, dim=1)[0] if z.dim()==4 else torch.argmax(z, dim=0)\n",
    "\n",
    "# def _save_triplet(arrs, path):\n",
    "#     # arrs are 0/1 masks [H,W]\n",
    "#     stack = np.stack(arrs, axis=-1).astype(np.uint8)*255\n",
    "#     Image.fromarray(stack).save(path)\n",
    "\n",
    "# picked = set()\n",
    "# for name, model, mtype in MODELS:\n",
    "#     for city in CITIES:\n",
    "#         for eps in EPS:\n",
    "#             key=(name,city,eps)\n",
    "#             if key in picked: continue\n",
    "#             try:\n",
    "#                 lower, upper, clean_logits, clean_pred, gt_mask = rcd(model, mtype, city, eps)\n",
    "#                 chg, nchg = _choose_channels(clean_logits, gt_mask)\n",
    "#                 mL = _slice_ch(lower, chg) - _slice_ch(upper, nchg)\n",
    "#                 Ccert  = (mL>0).cpu().numpy()\n",
    "#                 if clean_logits.shape[1]==2:\n",
    "#                     Cclean = (_argmax_HW(clean_logits)==chg).cpu().numpy()\n",
    "#                 else:\n",
    "#                     z=_logits_CHW(clean_logits)\n",
    "#                     Cclean=(torch.softmax(z, dim=0)[chg]>0.5).cpu().numpy()\n",
    "#                 Cgt    = _coerce_bin_hw(gt_mask)\n",
    "\n",
    "#                 out = f\"viz_predicates/{name}_{city}_eps{round(eps*255) if eps<=1 else eps}.png\"\n",
    "#                 _save_triplet([Ccert, Cclean, Cgt], out)\n",
    "#                 print(\"[viz] saved\", out, \" (R=cert, G=clean, B=GT; white=all three)\")\n",
    "#                 picked.add(key)\n",
    "#             except Exception as e:\n",
    "#                 print(\"[viz] skip\", key, \":\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e132ff1-d2d2-4bba-a9d8-47024f72fdab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # --- Build sensitivity tables from predicate_pass_v1.csv ---\n",
    "# import csv, numpy as np\n",
    "# from collections import defaultdict\n",
    "\n",
    "# CSV_IN = \"predicate_pass_v1.csv\"\n",
    "# def _nice_eps(e):\n",
    "#     e=float(e); k=round(e*255)\n",
    "#     return f\"{k}/255\" if abs(e-k/255)<1e-6 and 0<=k<=64 else f\"{e:.5f}\".rstrip(\"0\").rstrip(\".\")\n",
    "\n",
    "# # load rows\n",
    "# rows=[]\n",
    "# with open(CSV_IN, newline=\"\") as f:\n",
    "#     r=csv.DictReader(f)\n",
    "#     for d in r:\n",
    "#         rows.append({\n",
    "#             \"model\": d[\"model\"],\n",
    "#             \"city\": d[\"city\"],\n",
    "#             \"eps_val\": float(d[\"eps\"]),\n",
    "#             \"eps_str\": _nice_eps(d[\"eps\"]),\n",
    "#             \"rho\": float(d[\"rho\"]), \"gamma\": float(d[\"gamma\"]), \"smin\": int(float(d[\"s_min\"])),\n",
    "#             \"strict\": str(d[\"strict\"]).lower() in (\"true\",\"1\",\"yes\",\"t\",\"y\"),\n",
    "#             \"overlap\": float(d[\"overlap\"]), \"fp\": float(d[\"fp\"])\n",
    "#         })\n",
    "\n",
    "# # summarize by (model, eps, rho, gamma, smin)\n",
    "# grp=defaultdict(list)\n",
    "# for d in rows: grp[(d[\"model\"], d[\"eps_str\"], d[\"rho\"], d[\"gamma\"], d[\"smin\"])].append(d)\n",
    "\n",
    "# def _med(lst): \n",
    "#     if not lst: return float(\"nan\")\n",
    "#     s=sorted(lst); n=len(s); mid=n//2\n",
    "#     return s[mid] if n%2 else 0.5*(s[mid-1]+s[mid])\n",
    "\n",
    "# # choose a few settings to show how pass rate responds\n",
    "# SETTINGS=[(0.10,0.70,8),(0.20,0.50,16),(0.30,0.30,16)]\n",
    "# models=[\"AttU-Net\",\"EncDec\",\"FALCONet\"]\n",
    "# eps_order=[\"0/255\",\"1/255\",\"2/255\"]\n",
    "\n",
    "# lines=[]\n",
    "# lines += [r\"\\begin{table}[t]\", r\"\\centering\",\n",
    "#           r\"\\caption{\\textbf{Predicate sensitivity.} Strict pass rate (\\%) and med.\\ overlap/FP under varying $(\\rho,\\gamma,s_{\\min})$.}\",\n",
    "#           r\"\\label{tab:predicate_sensitivity}\",\n",
    "#           r\"\\begin{tabular}{lcccccc}\", r\"\\toprule\",\n",
    "#           r\"\\textbf{Model} & $\\varepsilon$ & $(\\rho,\\gamma,s_{\\min})$ & $n$ & Strict (\\%) & med.\\ overlap & med.\\ FP \\\\\",\n",
    "#           r\"\\midrule\"]\n",
    "# for m in models:\n",
    "#     first=True\n",
    "#     for eps in eps_order:\n",
    "#         for (rho,gam,smin) in SETTINGS:\n",
    "#             lst = grp.get((m, eps, rho, gam, smin), [])\n",
    "#             n=len(lst)\n",
    "#             strict_pct = 100.0*sum(v[\"strict\"] for v in lst)/max(1,n)\n",
    "#             med_ol=_med([v[\"overlap\"] for v in lst])\n",
    "#             med_fp=_med([v[\"fp\"] for v in lst])\n",
    "#             tag = f\"$({rho:.2f},{gam:.2f},{smin})$\"\n",
    "#             lines.append(f\"{m if first else ''} & ${eps}$ & {tag} & {n} & {strict_pct:.0f} & {med_ol:.2f} & {med_fp:.2f} \\\\\\\\\")\n",
    "#             first=False\n",
    "#     lines.append(r\"\\midrule\")\n",
    "# lines += [r\"\\bottomrule\", r\"\\end{tabular}\", r\"\\end{table}\"]\n",
    "\n",
    "# with open(\"table_predicate_sensitivity.tex\",\"w\") as f:\n",
    "#     f.write(\"\\n\".join(lines))\n",
    "# print(\"[ok] wrote table_predicate_sensitivity.tex\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5063a3e-d629-4eaf-97bd-a1b48145f650",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # === predicate_table_export_v3 ===\n",
    "# import os, csv, math, statistics as stats\n",
    "\n",
    "# # 1) Where is your CSV? (first existing path wins)\n",
    "# CANDIDATES = [\n",
    "#     \"./predicate_pass_v1.csv\",\n",
    "#     \"/mnt/g/phd_experiments/oscd_ood/predicate_pass_v1.csv\",  # your earlier print\n",
    "# ]\n",
    "# CSV_IN = None\n",
    "# for p in CANDIDATES:\n",
    "#     if os.path.exists(p) and os.path.getsize(p) > 0:\n",
    "#         CSV_IN = p; break\n",
    "# if not CSV_IN:\n",
    "#     raise FileNotFoundError(\"predicate_pass_v1.csv not found in any of: \" + \", \".join(CANDIDATES))\n",
    "\n",
    "# print(f\"[table] reading {CSV_IN}\")\n",
    "\n",
    "# # 2) Read rows and filter to main predicate setting\n",
    "# rows = []\n",
    "# with open(CSV_IN, newline=\"\") as f:\n",
    "#     r = csv.DictReader(f)\n",
    "#     for d in r:\n",
    "#         try:\n",
    "#             if (float(d[\"rho\"]) == 0.30 and float(d[\"gamma\"]) == 0.30 and int(float(d[\"s_min\"])) == 16):\n",
    "#                 rows.append({\n",
    "#                     \"model\": d[\"model\"],\n",
    "#                     \"eps\": float(d[\"eps\"]),\n",
    "#                     \"strict\": (str(d[\"strict\"]).lower() in (\"1\",\"true\",\"yes\")),\n",
    "#                     \"overlap\": float(d[\"overlap\"]),\n",
    "#                     \"fp\": float(d[\"fp\"]),\n",
    "#                 })\n",
    "#         except Exception:\n",
    "#             pass\n",
    "\n",
    "# if not rows:\n",
    "#     raise RuntimeError(\"No rows for (rho=0.30, gamma=0.30, s_min=16). Did the logger write main-setting rows?\")\n",
    "\n",
    "# # 3) Helpers\n",
    "# def nice_eps(e):\n",
    "#     k = round(e*255)\n",
    "#     if abs(e - k/255) < 1e-8 and 0 <= k <= 255:\n",
    "#         return f\"{k}/255\"\n",
    "#     return f\"{e:.5f}\".rstrip(\"0\").rstrip(\".\")\n",
    "\n",
    "# def median_safe(vals):\n",
    "#     vals = [v for v in vals if math.isfinite(v)]\n",
    "#     return float(\"nan\") if not vals else float(stats.median(sorted(vals)))\n",
    "\n",
    "# # 4) Aggregate by (model, eps)\n",
    "# from collections import defaultdict\n",
    "# grp = defaultdict(list)\n",
    "# for d in rows:\n",
    "#     grp[(d[\"model\"], d[\"eps\"])].append(d)\n",
    "\n",
    "# # 5) Build summary rows\n",
    "# summary = []\n",
    "# for (model, eps), lst in grp.items():\n",
    "#     n = len(lst)\n",
    "#     strict_pct = 100.0 * sum(1 for x in lst if x[\"strict\"]) / max(1, n)\n",
    "#     med_overlap = median_safe([x[\"overlap\"] for x in lst])\n",
    "#     med_fp      = median_safe([x[\"fp\"] for x in lst])\n",
    "#     summary.append({\n",
    "#         \"model\": model,\n",
    "#         \"eps\": eps,\n",
    "#         \"eps_str\": nice_eps(eps),\n",
    "#         \"n\": n,\n",
    "#         \"strict_pct\": strict_pct,\n",
    "#         \"med_overlap\": med_overlap,\n",
    "#         \"med_fp\": med_fp,\n",
    "#     })\n",
    "\n",
    "# # 6) Order: model name A–Z, eps in [0/255,1/255,2/255] then others\n",
    "# EPS_ORDER = [\"0/255\",\"1/255\",\"2/255\"]\n",
    "# def model_key(m): return m.lower()\n",
    "# def eps_key(es):\n",
    "#     return (0, EPS_ORDER.index(es)) if es in EPS_ORDER else (1, es)\n",
    "\n",
    "# summary.sort(key=lambda d: (model_key(d[\"model\"]), eps_key(d[\"eps_str\"])))\n",
    "\n",
    "# # 7) Emit LaTeX file\n",
    "# out_path = \"table_predicate_strict_main.tex\"\n",
    "# lines = []\n",
    "# lines.append(\"\\\\begin{table}[t]\")\n",
    "# lines.append(\"\\\\centering\")\n",
    "# lines.append(\"\\\\caption{\\\\textbf{Strict predicate certification under OOD.} Pass rate (\\\\%), median overlap and median FP for $\\\\rho{=}0.30$, $\\\\gamma{=}0.30$, $s_{\\\\min}{=}16$.}\")\n",
    "# lines.append(\"\\\\label{tab:strict_predicate_main}\")\n",
    "# lines.append(\"\\\\begin{tabular}{lcccc}\")\n",
    "# lines.append(\"\\\\toprule\")\n",
    "# lines.append(\"\\\\textbf{Model} & $\\\\boldsymbol{\\\\varepsilon}$ & $\\\\boldsymbol{n}$ & \\\\textbf{Strict pass (\\\\%)} & \\\\textbf{Median overlap / FP} \\\\\\\\\")\n",
    "# lines.append(\"\\\\midrule\")\n",
    "\n",
    "# cur_model = None\n",
    "# for d in summary:\n",
    "#     if cur_model is not None and d[\"model\"] != cur_model:\n",
    "#         lines.append(\"\\\\midrule\")\n",
    "#     cur_model = d[\"model\"]\n",
    "#     s_pct = f\"{d['strict_pct']:.0f}\"\n",
    "#     ov = \"nan\" if math.isnan(d[\"med_overlap\"]) else f\"{d['med_overlap']:.2f}\"\n",
    "#     fp = \"nan\" if math.isnan(d[\"med_fp\"]) else f\"{d['med_fp']:.2f}\"\n",
    "#     lines.append(f\"{d['model']} & ${d['eps_str']}$ & {d['n']} & {s_pct} & {ov} / {fp} \\\\\\\\\")\n",
    "# lines.append(\"\\\\bottomrule\")\n",
    "# lines.append(\"\\\\end{tabular}\")\n",
    "# lines.append(\"\\\\end{table}\")\n",
    "\n",
    "# with open(out_path, \"w\") as f:\n",
    "#     f.write(\"\\n\".join(lines))\n",
    "\n",
    "# print(f\"[table] wrote {os.path.abspath(out_path)}\")\n",
    "# print(\"\\n\".join(lines[:12] + [\"…\"] if len(lines) > 12 else lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78c84211-264f-4c1d-9299-8c41d25714cb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zono lower/upper: -1.8452577590942383 4.0 -1.8452577590942383 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07557724416255951 0.09110615402460098 0.0 0.0\n",
      "ranges: lower -2.8483049869537354 3.514469623565674 upper -2.8483049869537354 3.514469623565674 logits -2.8483049869537354 3.514469623565674\n",
      "tightness (prob space): 1.8342564105987549 1.8342564105987549\n",
      "zono lower/upper: -1.8582297563552856 3.987027883529663 -1.832285761833191 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 31820.4531\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07557724416255951 0.09110615402460098 0.012972054852304673 0.010760987195201042\n",
      "ranges: lower -148950.28125 -284.01251220703125 upper 46.52862548828125 213204.5 logits -2.8483049869537354 3.514469623565674\n",
      "tightness (prob space): 38773.69921875 43863.94921875\n",
      "zono lower/upper: -1.8712018728256226 3.9740560054779053 -1.819313645362854 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 72741.7656\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07557724416255951 0.09110615402460098 0.025944109704609346 0.021521974390402085\n",
      "ranges: lower -299128.5625 -681.802001953125 upper 116.67937469482422 428182.34375 logits -2.8483049869537354 3.514469623565674\n",
      "tightness (prob space): 88636.578125 100277.6328125\n",
      "zono lower/upper: -1.8971459865570068 3.9481117725372314 -1.7933695316314697 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 172401.8594\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07557724416255951 0.09110615402460098 0.05188821940921869 0.04304394878080417\n",
      "ranges: lower -618963.625 -1632.7628173828125 upper 326.9964904785156 886046.9375 logits -2.8483049869537354 3.514469623565674\n",
      "tightness (prob space): 210074.40625 237666.3125\n",
      "zono lower/upper: -1.9490342140197754 3.896223545074463 -1.7414813041687012 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 468722.2500\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07557724416255951 0.09110615402460098 0.10377643881843739 0.08608789756160834\n",
      "ranges: lower -1366172.625 -4565.39697265625 upper 1068.866943359375 1955861.75 logits -2.8483049869537354 3.514469623565674\n",
      "tightness (prob space): 571148.875 646167.0\n",
      "zono lower/upper: -2.1086764335632324 4.0 -2.1086764335632324 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.0796588808298111 0.06378848850727081 0.0 0.0\n",
      "ranges: lower -3.271074056625366 3.3839385509490967 upper -3.271074056625366 3.3839385509490967 logits -3.271074056625366 3.3839385509490967\n",
      "tightness (prob space): 1.4416718482971191 1.4416718482971191\n",
      "zono lower/upper: -2.1240458488464355 3.984630584716797 -2.0933070182800293 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 72808.0234\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.0796588808298111 0.06378848850727081 0.012307380503591616 0.015369421345530031\n",
      "ranges: lower -188713.25 -808.0602416992188 upper 180.9093017578125 270123.375 logits -3.271074056625366 3.3839385509490967\n",
      "tightness (prob space): 88719.125 100368.828125\n",
      "zono lower/upper: -2.1394152641296387 3.9692611694335938 -2.077937602996826 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 138441.9062\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.0796588808298111 0.06378848850727081 0.024614761007183232 0.030738842691060062\n",
      "ranges: lower -371722.625 -1445.5477294921875 upper 340.6441345214844 532074.6875 logits -3.271074056625366 3.3839385509490967\n",
      "tightness (prob space): 168696.140625 190848.65625\n",
      "zono lower/upper: -2.170154094696045 3.9385223388671875 -2.04719877243042 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 275022.5938\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.0796588808298111 0.06378848850727081 0.049229522014366464 0.061477685382120124\n",
      "ranges: lower -730722.3125 -2831.725341796875 upper 682.8705444335938 1046010.8125 logits -3.271074056625366 3.3839385509490967\n",
      "tightness (prob space): 335124.25 379133.4375\n",
      "zono lower/upper: -2.2316317558288574 3.877044677734375 -1.9857211112976074 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 640941.7500\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.0796588808298111 0.06378848850727081 0.09845904402873293 0.12295537076424025\n",
      "ranges: lower -1551073.0 -6823.197265625 upper 1662.23779296875 2220278.25 logits -3.271074056625366 3.3839385509490967\n",
      "tightness (prob space): 781010.625 883576.5625\n",
      "zono lower/upper: -1.5402976274490356 4.0 -1.5402976274490356 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11521695554256439 0.09882599115371704 0.0 0.0\n",
      "ranges: lower -3.2997069358825684 3.861760377883911 upper -3.2997069358825684 3.861760377883911 logits -3.2997069358825684 3.861760377883911\n",
      "tightness (prob space): 2.497767210006714 2.497767210006714\n",
      "zono lower/upper: -1.5502179861068726 3.990079641342163 -1.5303772687911987 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 23388.3867\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11521695554256439 0.09882599115371704 0.008509096185071134 0.009920387798972969\n",
      "ranges: lower -83786.2890625 -261.589599609375 upper 39.97124481201172 119910.34375 logits -3.2997069358825684 3.861760377883911\n",
      "tightness (prob space): 28499.625 32237.85546875\n",
      "zono lower/upper: -1.5601383447647095 3.980159282684326 -1.5204569101333618 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 48712.4219\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11521695554256439 0.09882599115371704 0.01701819237014227 0.019840775597945937\n",
      "ranges: lower -156394.5 -546.648193359375 upper 82.9201431274414 223843.390625 logits -3.2997069358825684 3.861760377883911\n",
      "tightness (prob space): 59357.6796875 67146.515625\n",
      "zono lower/upper: -1.5799791812896729 3.9603185653686523 -1.5006160736083984 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 113570.9219\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11521695554256439 0.09882599115371704 0.03403638474028454 0.039681551195891875\n",
      "ranges: lower -323789.71875 -1179.257080078125 upper 213.401611328125 463404.5625 logits -3.2997069358825684 3.861760377883911\n",
      "tightness (prob space): 138390.1875 156555.09375\n",
      "zono lower/upper: -1.61966073513031 3.9206368923187256 -1.4609345197677612 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 286542.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11521695554256439 0.09882599115371704 0.06807276948056908 0.07936310239178375\n",
      "ranges: lower -693187.5 -2844.316162109375 upper 597.5750122070312 992440.3125 logits -3.2997069358825684 3.861760377883911\n",
      "tightness (prob space): 349159.71875 395007.4375\n",
      "zono lower/upper: -1.8285049200057983 4.0 -1.8285049200057983 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08349466323852539 0.08581262081861496 0.0 0.0\n",
      "ranges: lower -3.3292336463928223 3.7267906665802 upper -3.3292336463928223 3.7267906665802 logits -3.3292336463928223 3.7267906665802\n",
      "tightness (prob space): 1.635632038116455 1.635632038116455\n",
      "zono lower/upper: -1.8402469158172607 3.988258123397827 -1.816762924194336 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 39980.0508\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08349466323852539 0.08581262081861496 0.011741973903912711 0.011424801474541061\n",
      "ranges: lower -124480.2890625 -264.8628234863281 upper 108.68505096435547 178084.515625 logits -3.3292336463928223 3.7267906665802\n",
      "tightness (prob space): 48718.953125 55114.68359375\n",
      "zono lower/upper: -1.8519889116287231 3.976516008377075 -1.8050209283828735 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 87044.0312\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08349466323852539 0.08581262081861496 0.023483947807825423 0.022849602949082122\n",
      "ranges: lower -254646.609375 -692.0098876953125 upper 244.55252075195312 364360.8125 logits -3.3292336463928223 3.7267906665802\n",
      "tightness (prob space): 106069.3046875 119996.859375\n",
      "zono lower/upper: -1.8754727840423584 3.9530320167541504 -1.7815370559692383 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 188989.5625\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08349466323852539 0.08581262081861496 0.046967895615650845 0.045699205898164244\n",
      "ranges: lower -546424.8125 -1659.6544189453125 upper 549.4161376953125 781731.5 logits -3.3292336463928223 3.7267906665802\n",
      "tightness (prob space): 230296.65625 260536.96875\n",
      "zono lower/upper: -1.922440767288208 3.90606427192688 -1.7345690727233887 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 459774.5000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08349466323852539 0.08581262081861496 0.09393579123130169 0.09139841179632849\n",
      "ranges: lower -1199552.5 -4367.18408203125 upper 1324.505615234375 1716827.625 logits -3.3292336463928223 3.7267906665802\n",
      "tightness (prob space): 560263.1875 633834.4375\n",
      "zono lower/upper: -1.850326418876648 4.0 -1.850326418876648 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08511039614677429 0.08934439718723297 0.0 0.0\n",
      "ranges: lower -3.310577869415283 3.7804181575775146 upper -3.310577869415283 3.7804181575775146 logits -3.310577869415283 3.7804181575775146\n",
      "tightness (prob space): 1.9465649127960205 1.9465649127960205\n",
      "zono lower/upper: -1.8618454933166504 3.988481044769287 -1.8388073444366455 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 54631.8633\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08511039614677429 0.08934439718723297 0.01151906466481536 0.010973180050766966\n",
      "ranges: lower -166391.6875 -423.6953125 upper 79.46188354492188 238196.8125 logits -3.310577869415283 3.7804181575775146\n",
      "tightness (prob space): 66570.3125 75312.234375\n",
      "zono lower/upper: -1.8733645677566528 3.976961851119995 -1.827288269996643 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 108973.4375\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08511039614677429 0.08934439718723297 0.02303812932963072 0.021946360101533932\n",
      "ranges: lower -320995.9375 -1004.136962890625 upper 165.71766662597656 459552.0625 logits -3.310577869415283 3.7804181575775146\n",
      "tightness (prob space): 132786.953125 150226.1875\n",
      "zono lower/upper: -1.8964027166366577 3.9539237022399902 -1.8042501211166382 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 219493.5469\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08511039614677429 0.08934439718723297 0.04607625865926144 0.043892720203067864\n",
      "ranges: lower -602462.6875 -2244.21826171875 upper 399.9377136230469 862512.4375 logits -3.310577869415283 3.7804181575775146\n",
      "tightness (prob space): 267459.40625 302585.8125\n",
      "zono lower/upper: -1.942478895187378 3.9078474044799805 -1.758173942565918 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 467889.3125\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08511039614677429 0.08934439718723297 0.09215251731852288 0.08778544040613573\n",
      "ranges: lower -1046994.6875 -4983.56640625 upper 1094.39306640625 1499069.5 logits -3.310577869415283 3.7804181575775146\n",
      "tightness (prob space): 570138.3125 645016.1875\n",
      "zono lower/upper: -2.164947986602783 4.0 -2.164947986602783 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.09271182864904404 0.07262950390577316 0.0 0.0\n",
      "ranges: lower -2.8534953594207764 3.416476249694824 upper -2.8534953594207764 3.416476249694824 logits -2.8534953594207764 3.416476249694824\n",
      "tightness (prob space): 1.8341401815414429 1.8341401815414429\n",
      "zono lower/upper: -2.1784465312957764 3.986501455307007 -2.15144944190979 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 31898.3750\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.09271182864904404 0.07262950390577316 0.010574617836241482 0.013498538529667911\n",
      "ranges: lower -174731.953125 -236.31246948242188 upper 59.188472747802734 249975.0625 logits -2.8534953594207764 3.416476249694824\n",
      "tightness (prob space): 38870.5859375 43969.1953125\n",
      "zono lower/upper: -2.1919450759887695 3.9730029106140137 -2.137950897216797 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 70843.6094\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.09271182864904404 0.07262950390577316 0.021149235672482964 0.026997077059335822\n",
      "ranges: lower -355437.90625 -559.0054931640625 upper 140.3326873779297 508525.03125 logits -2.8534953594207764 3.416476249694824\n",
      "tightness (prob space): 86327.265625 97656.4140625\n",
      "zono lower/upper: -2.218942165374756 3.9460058212280273 -2.1109538078308105 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 161103.1562\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.09271182864904404 0.07262950390577316 0.04229847134496593 0.053994154118671644\n",
      "ranges: lower -704767.9375 -1360.6182861328125 upper 341.4414978027344 1008354.875 logits -2.8534953594207764 3.416476249694824\n",
      "tightness (prob space): 196312.671875 222083.234375\n",
      "zono lower/upper: -2.2729363441467285 3.8920116424560547 -2.056959629058838 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 447837.4062\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.09271182864904404 0.07262950390577316 0.08459694268993186 0.10798830823734329\n",
      "ranges: lower -1455035.5 -4038.009765625 upper 1011.2119750976562 2081965.0 logits -2.8534953594207764 3.416476249694824\n",
      "tightness (prob space): 545708.125 617366.25\n",
      "zono lower/upper: -2.48640775680542 2.9312543869018555 -2.48640775680542 2.9312543869018555\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.10848435014486313 0.10103464126586914 0.0 0.0\n",
      "ranges: lower -2.5893642902374268 3.015751600265503 upper -2.5893642902374268 3.015751600265503 logits -2.5893642902374268 3.015751600265503\n",
      "tightness (prob space): 1.6426866054534912 1.6426866054534912\n",
      "zono lower/upper: -2.4961113929748535 2.921550750732422 -2.4767041206359863 2.940958023071289\n",
      "[path] affine-last-layer ON  | prelogit width mean: 27202.7715\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.10848435014486313 0.10103464126586914 0.009037175920338663 0.0097035248958115\n",
      "ranges: lower -89674.5234375 -245.67181396484375 upper 78.09171295166016 128380.890625 logits -2.5893642902374268 3.015751600265503\n",
      "tightness (prob space): 33148.2578125 37499.41796875\n",
      "zono lower/upper: -2.505814790725708 2.9118473529815674 -2.467000722885132 2.9506614208221436\n",
      "[path] affine-last-layer ON  | prelogit width mean: 60293.6719\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.10848435014486313 0.10103464126586914 0.018074351840677325 0.019407049791623\n",
      "ranges: lower -175160.5625 -574.7619018554688 upper 167.3883819580078 250689.78125 logits -2.5893642902374268 3.015751600265503\n",
      "tightness (prob space): 73471.0703125 83117.984375\n",
      "zono lower/upper: -2.525221824645996 2.8924403190612793 -2.4475936889648438 2.9700684547424316\n",
      "[path] affine-last-layer ON  | prelogit width mean: 128654.4766\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.10848435014486313 0.10103464126586914 0.03614870368135465 0.038814099583246\n",
      "ranges: lower -343064.0625 -1256.2486572265625 upper 338.0784912109375 490985.75 logits -2.5893642902374268 3.015751600265503\n",
      "tightness (prob space): 156771.5625 177358.71875\n",
      "zono lower/upper: -2.5640358924865723 2.853626251220703 -2.4087796211242676 3.008882522583008\n",
      "[path] affine-last-layer ON  | prelogit width mean: 317930.8125\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.10848435014486313 0.10103464126586914 0.0722974073627093 0.077628199166492\n",
      "ranges: lower -789527.0625 -3172.240478515625 upper 791.703125 1130436.75 logits -2.5893642902374268 3.015751600265503\n",
      "tightness (prob space): 387413.3125 438288.59375\n",
      "zono lower/upper: -2.105712890625 4.0 -2.105712890625 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11027795821428299 0.09654240310192108 0.0 0.0\n",
      "ranges: lower -3.4245848655700684 3.735318660736084 upper -3.4245848655700684 3.735318660736084 logits -3.4245848655700684 3.735318660736084\n",
      "tightness (prob space): 1.6673920154571533 1.6673920154571533\n",
      "zono lower/upper: -2.115867853164673 3.989845037460327 -2.095557928085327 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 32089.4102\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11027795821428299 0.09654240310192108 0.008890191410306385 0.010155041985310146\n",
      "ranges: lower -113547.5859375 -302.5120544433594 upper 75.0838851928711 162505.703125 logits -3.4245848655700684 3.735318660736084\n",
      "tightness (prob space): 39103.57421875 44229.80078125\n",
      "zono lower/upper: -2.126023054122925 3.979689836502075 -2.085402727127075 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 67740.5469\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11027795821428299 0.09654240310192108 0.01778038282061277 0.020310083970620292\n",
      "ranges: lower -232088.625 -687.4860229492188 upper 163.83148193359375 332152.3125 logits -3.4245848655700684 3.735318660736084\n",
      "tightness (prob space): 82546.359375 93373.875\n",
      "zono lower/upper: -2.1463329792022705 3.9593799114227295 -2.0650928020477295 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 137958.5312\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11027795821428299 0.09654240310192108 0.03556076564122554 0.040620167941240584\n",
      "ranges: lower -464685.8125 -1475.2103271484375 upper 324.0007019042969 664961.5 logits -3.4245848655700684 3.735318660736084\n",
      "tightness (prob space): 168111.03125 190166.09375\n",
      "zono lower/upper: -2.18695330619812 3.91875958442688 -2.02447247505188 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 335491.4062\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11027795821428299 0.09654240310192108 0.07112153128245108 0.08124033588248117\n",
      "ranges: lower -1043125.8125 -3731.670166015625 upper 762.2540893554688 1492931.625 logits -3.4245848655700684 3.735318660736084\n",
      "tightness (prob space): 408812.6875 462466.71875\n",
      "zono lower/upper: -1.9916439056396484 4.0 -1.9916439056396484 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.05752267315983772 0.06483159214258194 0.0 0.0\n",
      "ranges: lower -3.393099069595337 3.552469491958618 upper -3.393099069595337 3.552469491958618 logits -3.393099069595337 3.552469491958618\n",
      "tightness (prob space): 2.0225489139556885 2.0225489139556885\n",
      "zono lower/upper: -2.0086874961853027 3.9829564094543457 -1.9746003150939941 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 102960.9531\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.05752267315983772 0.06483159214258194 0.017043577827799108 0.015122136052229005\n",
      "ranges: lower -255224.203125 -1090.8577880859375 upper 271.0420837402344 365419.46875 logits -3.393099069595337 3.552469491958618\n",
      "tightness (prob space): 125463.4375 141934.9375\n",
      "zono lower/upper: -2.025731086730957 3.9659128189086914 -1.9575567245483398 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 216148.5625\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.05752267315983772 0.06483159214258194 0.034087155655598216 0.03024427210445801\n",
      "ranges: lower -536182.4375 -2309.999755859375 upper 574.6737060546875 767692.9375 logits -3.393099069595337 3.552469491958618\n",
      "tightness (prob space): 263388.03125 297967.78125\n",
      "zono lower/upper: -2.0598182678222656 3.931825637817383 -1.9234695434570312 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 445188.5625\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.05752267315983772 0.06483159214258194 0.06817431131119643 0.06048854420891602\n",
      "ranges: lower -1085499.5 -4829.22900390625 upper 1202.36181640625 1554178.125 logits -3.393099069595337 3.552469491958618\n",
      "tightness (prob space): 542483.625 613707.625\n",
      "zono lower/upper: -2.127992630004883 3.8636512756347656 -1.8552953004837036 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 955966.6250\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.05752267315983772 0.06483159214258194 0.13634862262239286 0.12097708841783204\n",
      "ranges: lower -2216565.0 -10120.6689453125 upper 2522.805908203125 3173701.75 logits -3.393099069595337 3.552469491958618\n",
      "tightness (prob space): 1164888.125 1317843.125\n",
      "zono lower/upper: -2.0057871341705322 4.0 -2.0057871341705322 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07777758687734604 0.07545270770788193 0.0 0.0\n",
      "ranges: lower -3.861349582672119 3.4335174560546875 upper -3.861349582672119 3.4335174560546875 logits -3.861349582672119 3.4335174560546875\n",
      "tightness (prob space): 1.7045636177062988 1.7045636177062988\n",
      "zono lower/upper: -2.0187807083129883 3.987006425857544 -1.9927936792373657 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 41661.6875\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07777758687734604 0.07545270770788193 0.012605072955127899 0.012993465531526995\n",
      "ranges: lower -158588.015625 -349.2871398925781 upper 90.79700469970703 227044.4375 logits -3.861349582672119 3.4335174560546875\n",
      "tightness (prob space): 50766.35546875 57430.0546875\n",
      "zono lower/upper: -2.0317740440368652 3.974013090133667 -1.9798002243041992 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 89321.8906\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07777758687734604 0.07545270770788193 0.025210145910255798 0.02598693106305399\n",
      "ranges: lower -375181.125 -742.203857421875 upper 198.629150390625 537086.5 logits -3.861349582672119 3.4335174560546875\n",
      "tightness (prob space): 108841.484375 123131.625\n",
      "zono lower/upper: -2.0577609539031982 3.948026180267334 -1.9538133144378662 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 196960.5625\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07777758687734604 0.07545270770788193 0.050420291820511595 0.05197386212610798\n",
      "ranges: lower -810411.5 -1667.0078125 upper 467.6434020996094 1160169.25 logits -3.861349582672119 3.4335174560546875\n",
      "tightness (prob space): 240002.625 271516.59375\n",
      "zono lower/upper: -2.1097347736358643 3.896052360534668 -1.9018393754959106 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 511762.0938\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07777758687734604 0.07545270770788193 0.10084058364102319 0.10394772425221596\n",
      "ranges: lower -1674259.5 -5050.3125 upper 1260.0867919921875 2397020.75 logits -3.861349582672119 3.4335174560546875\n",
      "tightness (prob space): 623599.625 705490.875\n",
      "zono lower/upper: -1.8452577590942383 4.0 -1.8452577590942383 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07557724416255951 0.09110615402460098 0.0 0.0\n",
      "ranges: lower -2.8483049869537354 3.514469623565674 upper -2.8483049869537354 3.514469623565674 logits -2.8483049869537354 3.514469623565674\n",
      "tightness (prob space): 1.8342564105987549 1.8342564105987549\n",
      "zono lower/upper: -1.8582297563552856 3.987027883529663 -1.832285761833191 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 31820.4531\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07557724416255951 0.09110615402460098 0.012972054852304673 0.010760987195201042\n",
      "ranges: lower -148950.28125 -284.01251220703125 upper 46.52862548828125 213204.5 logits -2.8483049869537354 3.514469623565674\n",
      "tightness (prob space): 38773.69921875 43863.94921875\n",
      "zono lower/upper: -1.8712018728256226 3.9740560054779053 -1.819313645362854 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 72741.7656\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07557724416255951 0.09110615402460098 0.025944109704609346 0.021521974390402085\n",
      "ranges: lower -299128.5625 -681.802001953125 upper 116.67937469482422 428182.34375 logits -2.8483049869537354 3.514469623565674\n",
      "tightness (prob space): 88636.578125 100277.6328125\n",
      "zono lower/upper: -1.8971459865570068 3.9481117725372314 -1.7933695316314697 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 172401.8594\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07557724416255951 0.09110615402460098 0.05188821940921869 0.04304394878080417\n",
      "ranges: lower -618963.625 -1632.7628173828125 upper 326.9964904785156 886046.9375 logits -2.8483049869537354 3.514469623565674\n",
      "tightness (prob space): 210074.40625 237666.3125\n",
      "zono lower/upper: -1.9490342140197754 3.896223545074463 -1.7414813041687012 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 468722.2500\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07557724416255951 0.09110615402460098 0.10377643881843739 0.08608789756160834\n",
      "ranges: lower -1366172.625 -4565.39697265625 upper 1068.866943359375 1955861.75 logits -2.8483049869537354 3.514469623565674\n",
      "tightness (prob space): 571148.875 646167.0\n",
      "zono lower/upper: -2.1086764335632324 4.0 -2.1086764335632324 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.0796588808298111 0.06378848850727081 0.0 0.0\n",
      "ranges: lower -3.271074056625366 3.3839385509490967 upper -3.271074056625366 3.3839385509490967 logits -3.271074056625366 3.3839385509490967\n",
      "tightness (prob space): 1.4416718482971191 1.4416718482971191\n",
      "zono lower/upper: -2.1240458488464355 3.984630584716797 -2.0933070182800293 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 72808.0234\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.0796588808298111 0.06378848850727081 0.012307380503591616 0.015369421345530031\n",
      "ranges: lower -188713.25 -808.0602416992188 upper 180.9093017578125 270123.375 logits -3.271074056625366 3.3839385509490967\n",
      "tightness (prob space): 88719.125 100368.828125\n",
      "zono lower/upper: -2.1394152641296387 3.9692611694335938 -2.077937602996826 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 138441.9062\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.0796588808298111 0.06378848850727081 0.024614761007183232 0.030738842691060062\n",
      "ranges: lower -371722.625 -1445.5477294921875 upper 340.6441345214844 532074.6875 logits -3.271074056625366 3.3839385509490967\n",
      "tightness (prob space): 168696.140625 190848.65625\n",
      "zono lower/upper: -2.170154094696045 3.9385223388671875 -2.04719877243042 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 275022.5938\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.0796588808298111 0.06378848850727081 0.049229522014366464 0.061477685382120124\n",
      "ranges: lower -730722.3125 -2831.725341796875 upper 682.8705444335938 1046010.8125 logits -3.271074056625366 3.3839385509490967\n",
      "tightness (prob space): 335124.25 379133.4375\n",
      "zono lower/upper: -2.2316317558288574 3.877044677734375 -1.9857211112976074 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 640941.7500\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.0796588808298111 0.06378848850727081 0.09845904402873293 0.12295537076424025\n",
      "ranges: lower -1551073.0 -6823.197265625 upper 1662.23779296875 2220278.25 logits -3.271074056625366 3.3839385509490967\n",
      "tightness (prob space): 781010.625 883576.5625\n",
      "zono lower/upper: -1.5402976274490356 4.0 -1.5402976274490356 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11521695554256439 0.09882599115371704 0.0 0.0\n",
      "ranges: lower -3.2997069358825684 3.861760377883911 upper -3.2997069358825684 3.861760377883911 logits -3.2997069358825684 3.861760377883911\n",
      "tightness (prob space): 2.497767210006714 2.497767210006714\n",
      "zono lower/upper: -1.5502179861068726 3.990079641342163 -1.5303772687911987 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 23388.3867\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11521695554256439 0.09882599115371704 0.008509096185071134 0.009920387798972969\n",
      "ranges: lower -83786.2890625 -261.589599609375 upper 39.97124481201172 119910.34375 logits -3.2997069358825684 3.861760377883911\n",
      "tightness (prob space): 28499.625 32237.85546875\n",
      "zono lower/upper: -1.5601383447647095 3.980159282684326 -1.5204569101333618 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 48712.4219\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11521695554256439 0.09882599115371704 0.01701819237014227 0.019840775597945937\n",
      "ranges: lower -156394.5 -546.648193359375 upper 82.9201431274414 223843.390625 logits -3.2997069358825684 3.861760377883911\n",
      "tightness (prob space): 59357.6796875 67146.515625\n",
      "zono lower/upper: -1.5799791812896729 3.9603185653686523 -1.5006160736083984 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 113570.9219\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11521695554256439 0.09882599115371704 0.03403638474028454 0.039681551195891875\n",
      "ranges: lower -323789.71875 -1179.257080078125 upper 213.401611328125 463404.5625 logits -3.2997069358825684 3.861760377883911\n",
      "tightness (prob space): 138390.1875 156555.09375\n",
      "zono lower/upper: -1.61966073513031 3.9206368923187256 -1.4609345197677612 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 286542.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11521695554256439 0.09882599115371704 0.06807276948056908 0.07936310239178375\n",
      "ranges: lower -693187.5 -2844.316162109375 upper 597.5750122070312 992440.3125 logits -3.2997069358825684 3.861760377883911\n",
      "tightness (prob space): 349159.71875 395007.4375\n",
      "zono lower/upper: -1.8285049200057983 4.0 -1.8285049200057983 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08349466323852539 0.08581262081861496 0.0 0.0\n",
      "ranges: lower -3.3292336463928223 3.7267906665802 upper -3.3292336463928223 3.7267906665802 logits -3.3292336463928223 3.7267906665802\n",
      "tightness (prob space): 1.635632038116455 1.635632038116455\n",
      "zono lower/upper: -1.8402469158172607 3.988258123397827 -1.816762924194336 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 39980.0508\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08349466323852539 0.08581262081861496 0.011741973903912711 0.011424801474541061\n",
      "ranges: lower -124480.2890625 -264.8628234863281 upper 108.68505096435547 178084.515625 logits -3.3292336463928223 3.7267906665802\n",
      "tightness (prob space): 48718.953125 55114.68359375\n",
      "zono lower/upper: -1.8519889116287231 3.976516008377075 -1.8050209283828735 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 87044.0312\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08349466323852539 0.08581262081861496 0.023483947807825423 0.022849602949082122\n",
      "ranges: lower -254646.609375 -692.0098876953125 upper 244.55252075195312 364360.8125 logits -3.3292336463928223 3.7267906665802\n",
      "tightness (prob space): 106069.3046875 119996.859375\n",
      "zono lower/upper: -1.8754727840423584 3.9530320167541504 -1.7815370559692383 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 188989.5625\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08349466323852539 0.08581262081861496 0.046967895615650845 0.045699205898164244\n",
      "ranges: lower -546424.8125 -1659.6544189453125 upper 549.4161376953125 781731.5 logits -3.3292336463928223 3.7267906665802\n",
      "tightness (prob space): 230296.65625 260536.96875\n",
      "zono lower/upper: -1.922440767288208 3.90606427192688 -1.7345690727233887 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 459774.5000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08349466323852539 0.08581262081861496 0.09393579123130169 0.09139841179632849\n",
      "ranges: lower -1199552.5 -4367.18408203125 upper 1324.505615234375 1716827.625 logits -3.3292336463928223 3.7267906665802\n",
      "tightness (prob space): 560263.1875 633834.4375\n",
      "zono lower/upper: -1.850326418876648 4.0 -1.850326418876648 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08511039614677429 0.08934439718723297 0.0 0.0\n",
      "ranges: lower -3.310577869415283 3.7804181575775146 upper -3.310577869415283 3.7804181575775146 logits -3.310577869415283 3.7804181575775146\n",
      "tightness (prob space): 1.9465649127960205 1.9465649127960205\n",
      "zono lower/upper: -1.8618454933166504 3.988481044769287 -1.8388073444366455 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 54631.8633\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08511039614677429 0.08934439718723297 0.01151906466481536 0.010973180050766966\n",
      "ranges: lower -166391.6875 -423.6953125 upper 79.46188354492188 238196.8125 logits -3.310577869415283 3.7804181575775146\n",
      "tightness (prob space): 66570.3125 75312.234375\n",
      "zono lower/upper: -1.8733645677566528 3.976961851119995 -1.827288269996643 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 108973.4375\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08511039614677429 0.08934439718723297 0.02303812932963072 0.021946360101533932\n",
      "ranges: lower -320995.9375 -1004.136962890625 upper 165.71766662597656 459552.0625 logits -3.310577869415283 3.7804181575775146\n",
      "tightness (prob space): 132786.953125 150226.1875\n",
      "zono lower/upper: -1.8964027166366577 3.9539237022399902 -1.8042501211166382 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 219493.5469\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08511039614677429 0.08934439718723297 0.04607625865926144 0.043892720203067864\n",
      "ranges: lower -602462.6875 -2244.21826171875 upper 399.9377136230469 862512.4375 logits -3.310577869415283 3.7804181575775146\n",
      "tightness (prob space): 267459.40625 302585.8125\n",
      "zono lower/upper: -1.942478895187378 3.9078474044799805 -1.758173942565918 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 467889.3125\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08511039614677429 0.08934439718723297 0.09215251731852288 0.08778544040613573\n",
      "ranges: lower -1046994.6875 -4983.56640625 upper 1094.39306640625 1499069.5 logits -3.310577869415283 3.7804181575775146\n",
      "tightness (prob space): 570138.3125 645016.1875\n",
      "zono lower/upper: -2.164947986602783 4.0 -2.164947986602783 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.09271182864904404 0.07262950390577316 0.0 0.0\n",
      "ranges: lower -2.8534953594207764 3.416476249694824 upper -2.8534953594207764 3.416476249694824 logits -2.8534953594207764 3.416476249694824\n",
      "tightness (prob space): 1.8341401815414429 1.8341401815414429\n",
      "zono lower/upper: -2.1784465312957764 3.986501455307007 -2.15144944190979 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 31898.3750\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.09271182864904404 0.07262950390577316 0.010574617836241482 0.013498538529667911\n",
      "ranges: lower -174731.953125 -236.31246948242188 upper 59.188472747802734 249975.0625 logits -2.8534953594207764 3.416476249694824\n",
      "tightness (prob space): 38870.5859375 43969.1953125\n",
      "zono lower/upper: -2.1919450759887695 3.9730029106140137 -2.137950897216797 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 70843.6094\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.09271182864904404 0.07262950390577316 0.021149235672482964 0.026997077059335822\n",
      "ranges: lower -355437.90625 -559.0054931640625 upper 140.3326873779297 508525.03125 logits -2.8534953594207764 3.416476249694824\n",
      "tightness (prob space): 86327.265625 97656.4140625\n",
      "zono lower/upper: -2.218942165374756 3.9460058212280273 -2.1109538078308105 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 161103.1562\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.09271182864904404 0.07262950390577316 0.04229847134496593 0.053994154118671644\n",
      "ranges: lower -704767.9375 -1360.6182861328125 upper 341.4414978027344 1008354.875 logits -2.8534953594207764 3.416476249694824\n",
      "tightness (prob space): 196312.671875 222083.234375\n",
      "zono lower/upper: -2.2729363441467285 3.8920116424560547 -2.056959629058838 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 447837.4062\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.09271182864904404 0.07262950390577316 0.08459694268993186 0.10798830823734329\n",
      "ranges: lower -1455035.5 -4038.009765625 upper 1011.2119750976562 2081965.0 logits -2.8534953594207764 3.416476249694824\n",
      "tightness (prob space): 545708.125 617366.25\n",
      "zono lower/upper: -2.48640775680542 2.9312543869018555 -2.48640775680542 2.9312543869018555\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.10848435014486313 0.10103464126586914 0.0 0.0\n",
      "ranges: lower -2.5893642902374268 3.015751600265503 upper -2.5893642902374268 3.015751600265503 logits -2.5893642902374268 3.015751600265503\n",
      "tightness (prob space): 1.6426866054534912 1.6426866054534912\n",
      "zono lower/upper: -2.4961113929748535 2.921550750732422 -2.4767041206359863 2.940958023071289\n",
      "[path] affine-last-layer ON  | prelogit width mean: 27202.7715\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.10848435014486313 0.10103464126586914 0.009037175920338663 0.0097035248958115\n",
      "ranges: lower -89674.5234375 -245.67181396484375 upper 78.09171295166016 128380.890625 logits -2.5893642902374268 3.015751600265503\n",
      "tightness (prob space): 33148.2578125 37499.41796875\n",
      "zono lower/upper: -2.505814790725708 2.9118473529815674 -2.467000722885132 2.9506614208221436\n",
      "[path] affine-last-layer ON  | prelogit width mean: 60293.6719\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.10848435014486313 0.10103464126586914 0.018074351840677325 0.019407049791623\n",
      "ranges: lower -175160.5625 -574.7619018554688 upper 167.3883819580078 250689.78125 logits -2.5893642902374268 3.015751600265503\n",
      "tightness (prob space): 73471.0703125 83117.984375\n",
      "zono lower/upper: -2.525221824645996 2.8924403190612793 -2.4475936889648438 2.9700684547424316\n",
      "[path] affine-last-layer ON  | prelogit width mean: 128654.4766\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.10848435014486313 0.10103464126586914 0.03614870368135465 0.038814099583246\n",
      "ranges: lower -343064.0625 -1256.2486572265625 upper 338.0784912109375 490985.75 logits -2.5893642902374268 3.015751600265503\n",
      "tightness (prob space): 156771.5625 177358.71875\n",
      "zono lower/upper: -2.5640358924865723 2.853626251220703 -2.4087796211242676 3.008882522583008\n",
      "[path] affine-last-layer ON  | prelogit width mean: 317930.8125\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.10848435014486313 0.10103464126586914 0.0722974073627093 0.077628199166492\n",
      "ranges: lower -789527.0625 -3172.240478515625 upper 791.703125 1130436.75 logits -2.5893642902374268 3.015751600265503\n",
      "tightness (prob space): 387413.3125 438288.59375\n",
      "zono lower/upper: -2.105712890625 4.0 -2.105712890625 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11027795821428299 0.09654240310192108 0.0 0.0\n",
      "ranges: lower -3.4245848655700684 3.735318660736084 upper -3.4245848655700684 3.735318660736084 logits -3.4245848655700684 3.735318660736084\n",
      "tightness (prob space): 1.6673920154571533 1.6673920154571533\n",
      "zono lower/upper: -2.115867853164673 3.989845037460327 -2.095557928085327 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 32089.4102\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11027795821428299 0.09654240310192108 0.008890191410306385 0.010155041985310146\n",
      "ranges: lower -113547.5859375 -302.5120544433594 upper 75.0838851928711 162505.703125 logits -3.4245848655700684 3.735318660736084\n",
      "tightness (prob space): 39103.57421875 44229.80078125\n",
      "zono lower/upper: -2.126023054122925 3.979689836502075 -2.085402727127075 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 67740.5469\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11027795821428299 0.09654240310192108 0.01778038282061277 0.020310083970620292\n",
      "ranges: lower -232088.625 -687.4860229492188 upper 163.83148193359375 332152.3125 logits -3.4245848655700684 3.735318660736084\n",
      "tightness (prob space): 82546.359375 93373.875\n",
      "zono lower/upper: -2.1463329792022705 3.9593799114227295 -2.0650928020477295 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 137958.5312\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11027795821428299 0.09654240310192108 0.03556076564122554 0.040620167941240584\n",
      "ranges: lower -464685.8125 -1475.2103271484375 upper 324.0007019042969 664961.5 logits -3.4245848655700684 3.735318660736084\n",
      "tightness (prob space): 168111.03125 190166.09375\n",
      "zono lower/upper: -2.18695330619812 3.91875958442688 -2.02447247505188 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 335491.4062\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11027795821428299 0.09654240310192108 0.07112153128245108 0.08124033588248117\n",
      "ranges: lower -1043125.8125 -3731.670166015625 upper 762.2540893554688 1492931.625 logits -3.4245848655700684 3.735318660736084\n",
      "tightness (prob space): 408812.6875 462466.71875\n",
      "zono lower/upper: -1.9916439056396484 4.0 -1.9916439056396484 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.05752267315983772 0.06483159214258194 0.0 0.0\n",
      "ranges: lower -3.393099069595337 3.552469491958618 upper -3.393099069595337 3.552469491958618 logits -3.393099069595337 3.552469491958618\n",
      "tightness (prob space): 2.0225489139556885 2.0225489139556885\n",
      "zono lower/upper: -2.0086874961853027 3.9829564094543457 -1.9746003150939941 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 102960.9531\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.05752267315983772 0.06483159214258194 0.017043577827799108 0.015122136052229005\n",
      "ranges: lower -255224.203125 -1090.8577880859375 upper 271.0420837402344 365419.46875 logits -3.393099069595337 3.552469491958618\n",
      "tightness (prob space): 125463.4375 141934.9375\n",
      "zono lower/upper: -2.025731086730957 3.9659128189086914 -1.9575567245483398 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 216148.5625\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.05752267315983772 0.06483159214258194 0.034087155655598216 0.03024427210445801\n",
      "ranges: lower -536182.4375 -2309.999755859375 upper 574.6737060546875 767692.9375 logits -3.393099069595337 3.552469491958618\n",
      "tightness (prob space): 263388.03125 297967.78125\n",
      "zono lower/upper: -2.0598182678222656 3.931825637817383 -1.9234695434570312 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 445188.5625\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.05752267315983772 0.06483159214258194 0.06817431131119643 0.06048854420891602\n",
      "ranges: lower -1085499.5 -4829.22900390625 upper 1202.36181640625 1554178.125 logits -3.393099069595337 3.552469491958618\n",
      "tightness (prob space): 542483.625 613707.625\n",
      "zono lower/upper: -2.127992630004883 3.8636512756347656 -1.8552953004837036 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 955966.6250\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.05752267315983772 0.06483159214258194 0.13634862262239286 0.12097708841783204\n",
      "ranges: lower -2216565.0 -10120.6689453125 upper 2522.805908203125 3173701.75 logits -3.393099069595337 3.552469491958618\n",
      "tightness (prob space): 1164888.125 1317843.125\n",
      "zono lower/upper: -2.0057871341705322 4.0 -2.0057871341705322 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07777758687734604 0.07545270770788193 0.0 0.0\n",
      "ranges: lower -3.861349582672119 3.4335174560546875 upper -3.861349582672119 3.4335174560546875 logits -3.861349582672119 3.4335174560546875\n",
      "tightness (prob space): 1.7045636177062988 1.7045636177062988\n",
      "zono lower/upper: -2.0187807083129883 3.987006425857544 -1.9927936792373657 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 41661.6875\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07777758687734604 0.07545270770788193 0.012605072955127899 0.012993465531526995\n",
      "ranges: lower -158588.015625 -349.2871398925781 upper 90.79700469970703 227044.4375 logits -3.861349582672119 3.4335174560546875\n",
      "tightness (prob space): 50766.35546875 57430.0546875\n",
      "zono lower/upper: -2.0317740440368652 3.974013090133667 -1.9798002243041992 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 89321.8906\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07777758687734604 0.07545270770788193 0.025210145910255798 0.02598693106305399\n",
      "ranges: lower -375181.125 -742.203857421875 upper 198.629150390625 537086.5 logits -3.861349582672119 3.4335174560546875\n",
      "tightness (prob space): 108841.484375 123131.625\n",
      "zono lower/upper: -2.0577609539031982 3.948026180267334 -1.9538133144378662 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 196960.5625\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07777758687734604 0.07545270770788193 0.050420291820511595 0.05197386212610798\n",
      "ranges: lower -810411.5 -1667.0078125 upper 467.6434020996094 1160169.25 logits -3.861349582672119 3.4335174560546875\n",
      "tightness (prob space): 240002.625 271516.59375\n",
      "zono lower/upper: -2.1097347736358643 3.896052360534668 -1.9018393754959106 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 511762.0938\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07777758687734604 0.07545270770788193 0.10084058364102319 0.10394772425221596\n",
      "ranges: lower -1674259.5 -5050.3125 upper 1260.0867919921875 2397020.75 logits -3.861349582672119 3.4335174560546875\n",
      "tightness (prob space): 623599.625 705490.875\n",
      "[balanced] wrote 100 rows → /mnt/g/phd_experiments/oscd_ood/predicate_pass_balanced_v1_hct.csv\n",
      "[table] wrote table_predicate_balanced_main_hct.tex\n",
      "[table] wrote table_predicate_relaxed_main_hct.tex\n",
      "[ok] balanced_predicate_tables_v2 done.\n"
     ]
    }
   ],
   "source": [
    "# === balanced_predicate_tables_v2 — no dependency on run_predicate_logger ===\n",
    "import os, csv, numpy as np, torch\n",
    "\n",
    "# ---- predicate settings ----\n",
    "BALANCED_MAIN  = (0.20, 0.50, 16)  # (rho, gamma, s_min)\n",
    "RELAXED_SECOND = (0.10, 0.70, 8)\n",
    "\n",
    "CSV_OUT  = \"predicate_pass_balanced_v1_hct.csv\"\n",
    "TEX_MAIN = \"table_predicate_balanced_main_hct.tex\"\n",
    "TEX_REL  = \"table_predicate_relaxed_main_hct.tex\"\n",
    "\n",
    "# ---- small helpers (shape-safe) ----\n",
    "def _nice_eps(e):\n",
    "    e = float(e)\n",
    "    k = round(e * 255)\n",
    "    if abs(e - k/255) < 1e-6 and 0 <= k <= 64:\n",
    "        return f\"{k}/255\"\n",
    "    return f\"{e:.5f}\".rstrip('0').rstrip('.')\n",
    "\n",
    "def _to_np(x):\n",
    "    return x.detach().cpu().numpy() if torch.is_tensor(x) else np.asarray(x)\n",
    "\n",
    "def _coerce_bin_hw(x, H, W):\n",
    "    \"\"\"\n",
    "    Coerce x -> binary [H,W] uint8.\n",
    "    Accepts tensors/ndarrays with shapes:\n",
    "      - [H,W], [1,H,W], [H,W,1], [1,1,H,W], [H*W], [C,H,W], [H,W,C]\n",
    "    If multiple channels, uses any-nonzero across channels.\n",
    "    If flattened, reshapes to [H,W].\n",
    "    \"\"\"\n",
    "    m = _to_np(x)\n",
    "    m = np.squeeze(m)\n",
    "    if m.ndim == 1:\n",
    "        if m.size == H*W:\n",
    "            m = m.reshape(H, W)\n",
    "        else:\n",
    "            raise ValueError(f\"_coerce_bin_hw: got 1-D of length {m.size}, cannot reshape to ({H},{W}).\")\n",
    "    elif m.ndim == 3:\n",
    "        # (C,H,W) or (H,W,C)\n",
    "        if m.shape[0] == 1:\n",
    "            m = m[0]\n",
    "        elif m.shape[-1] == 1:\n",
    "            m = m[..., 0]\n",
    "        else:\n",
    "            m = (m != 0).any(axis=0).astype(np.uint8)\n",
    "    elif m.ndim != 2:\n",
    "        raise ValueError(f\"_coerce_bin_hw: expected 2-D/3-D/1-D, got shape {m.shape}\")\n",
    "    return (m > 0).astype(np.uint8)\n",
    "\n",
    "def _connected_components_4(mask_hw_uint8):\n",
    "    m = (mask_hw_uint8.astype(np.uint8) > 0)\n",
    "    H, W = m.shape\n",
    "    if H == 0 or W == 0: return []\n",
    "    lab = np.zeros((H, W), dtype=np.int32)\n",
    "    sizes, cur = [], 0\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            if m[i,j] and lab[i,j] == 0:\n",
    "                cur += 1\n",
    "                stack = [(i,j)]\n",
    "                lab[i,j] = cur\n",
    "                sz = 0\n",
    "                while stack:\n",
    "                    r,c = stack.pop()\n",
    "                    sz += 1\n",
    "                    for dr,dc in ((1,0),(-1,0),(0,1),(0,-1)):\n",
    "                        rr,cc = r+dr, c+dc\n",
    "                        if 0<=rr<H and 0<=cc<W and m[rr,cc] and lab[rr,cc]==0:\n",
    "                            lab[rr,cc] = cur\n",
    "                            stack.append((rr,cc))\n",
    "                sizes.append(sz)\n",
    "    return sizes\n",
    "\n",
    "def _choose_channels(clean_logits_1CHW, gt_hw_bin):\n",
    "    \"\"\"\n",
    "    clean_logits_1CHW: torch tensor [1,C,H,W]\n",
    "    gt_hw_bin: numpy [H,W] bool/uint8\n",
    "    Returns (chg, nchg).\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        p = torch.softmax(clean_logits_1CHW, dim=1)[0].cpu().numpy()  # [C,H,W]\n",
    "    C, H, W = p.shape\n",
    "    if C == 2:\n",
    "        return 1, 0\n",
    "    gt = (gt_hw_bin > 0)\n",
    "    best_iou, best_c = -1.0, 0\n",
    "    for c in range(C):\n",
    "        pred = (p[c] > 0.5)\n",
    "        union = np.logical_or(pred, gt).sum()\n",
    "        iou   = (np.logical_and(pred, gt).sum() / max(1, union))\n",
    "        if iou > best_iou:\n",
    "            best_iou, best_c = iou, c\n",
    "    nchg = 0 if best_c != 0 else 1  # simple fallback\n",
    "    return best_c, nchg\n",
    "\n",
    "def _predicates(Ccert, Cclean, Cgt, rho, gamma, s_min):\n",
    "    Ccert = Ccert.astype(bool); Cclean = Cclean.astype(bool); Cgt = Cgt.astype(bool)\n",
    "    denom = max(1, Cclean.sum())\n",
    "    overlap = np.logical_and(Ccert, Cclean).sum() / denom\n",
    "    Poverlap = (overlap >= rho)\n",
    "    cert_sz = Ccert.sum()\n",
    "    fp = 0.0 if cert_sz == 0 else (np.logical_and(Ccert, np.logical_not(Cgt)).sum() / cert_sz)\n",
    "    Pfp = (fp <= gamma)\n",
    "    sizes = _connected_components_4(Ccert.astype(np.uint8))\n",
    "    Ppattern = all(sz >= s_min for sz in sizes)\n",
    "    return Poverlap, Pfp, Ppattern, (Poverlap and Pfp and Ppattern), overlap, fp\n",
    "\n",
    "# ---- run the two settings and write CSV ----\n",
    "header = [\"model\",\"type\",\"city\",\"eps\",\"rho\",\"gamma\",\"s_min\",\n",
    "          \"strict\",\"Poverlap\",\"Pfp\",\"Ppattern\",\"overlap\",\"fp\",\"largest_cc\"]\n",
    "\n",
    "rows = []\n",
    "def _try_append(model_name, model, model_type, city, eps, rho, gamma, s_min):\n",
    "    try:\n",
    "        lower, upper, clean_logits, clean_pred, gt_mask = rcd(model, model_type, city, eps)\n",
    "        # squeeze batch to [C,H,W]\n",
    "        lower, upper, z = lower.squeeze(0), upper.squeeze(0), clean_logits.squeeze(0)  # [C,H,W]\n",
    "        C, H, W = z.shape\n",
    "        gt_hw = _coerce_bin_hw(gt_mask, H, W)\n",
    "        # add batch back for softmax\n",
    "        z1 = z.unsqueeze(0)  # [1,C,H,W]\n",
    "        chg, nchg = _choose_channels(z1, gt_hw)\n",
    "        # margin LB > 0 region\n",
    "        mL = lower[chg] - upper[nchg]  # [H,W]\n",
    "        Ccert  = _coerce_bin_hw((mL > 0), H, W)\n",
    "        # clean-pred set\n",
    "        if z1.shape[1] == 2:\n",
    "            Cclean = _coerce_bin_hw((torch.argmax(z1, dim=1)[0] == chg), H, W)\n",
    "        else:\n",
    "            Cclean = _coerce_bin_hw((torch.softmax(z1, dim=1)[0, chg] > 0.5), H, W)\n",
    "        # predicates\n",
    "        Poverlap, Pfp, Ppattern, Pstrict, overlap, fp = _predicates(Ccert, Cclean, gt_hw, rho, gamma, s_min)\n",
    "        sizes = _connected_components_4(Ccert.astype(np.uint8))\n",
    "        rows.append({\n",
    "            \"model\": model_name, \"type\": int(model_type), \"city\": city, \"eps\": float(eps),\n",
    "            \"rho\": float(rho), \"gamma\": float(gamma), \"s_min\": int(s_min),\n",
    "            \"strict\": bool(Pstrict), \"Poverlap\": bool(Poverlap), \"Pfp\": bool(Pfp), \"Ppattern\": bool(Ppattern),\n",
    "            \"overlap\": float(overlap), \"fp\": float(fp), \"largest_cc\": int(max(sizes) if sizes else 0)\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] skip {model_name}/{city}/eps={_nice_eps(eps)} (rho={rho},gamma={gamma},s={s_min}): {e}\")\n",
    "\n",
    "for (rho, gamma, smin) in (BALANCED_MAIN, RELAXED_SECOND):\n",
    "    for (model_name, model, model_type) in MODELS:\n",
    "        for city in CITIES:\n",
    "            for eps in EPS:\n",
    "                _try_append(model_name, model, model_type, city, eps, rho, gamma, smin)\n",
    "\n",
    "with open(CSV_OUT, \"w\", newline=\"\") as f:\n",
    "    w = csv.DictWriter(f, fieldnames=header)\n",
    "    w.writeheader()\n",
    "    w.writerows(rows)\n",
    "print(f\"[balanced] wrote {len(rows)} rows → {os.path.abspath(CSV_OUT)}\")\n",
    "\n",
    "# ---- summarize -> LaTeX ----\n",
    "def _median(xs):\n",
    "    if not xs: return float('nan')\n",
    "    s = sorted(xs); n = len(s); mid = n//2\n",
    "    return s[mid] if (n%2==1) else 0.5*(s[mid-1]+s[mid])\n",
    "\n",
    "def _summarize(rows, want):\n",
    "    # want: (rho,gamma,smin)\n",
    "    sel = [r for r in rows if (r[\"rho\"],r[\"gamma\"],r[\"s_min\"])==want]\n",
    "    grp = {}\n",
    "    for r in sel:\n",
    "        key = (r[\"model\"], r[\"eps\"])\n",
    "        grp.setdefault(key, []).append(r)\n",
    "    out = []\n",
    "    for (model, eps), lst in grp.items():\n",
    "        n = len(lst)\n",
    "        strict_pct = 100.0 * sum(1 for x in lst if x[\"strict\"]) / max(1, n)\n",
    "        med_overlap = _median([x[\"overlap\"] for x in lst])\n",
    "        med_fp      = _median([x[\"fp\"] for x in lst])\n",
    "        out.append({\n",
    "            \"model\": model, \"eps\": eps, \"eps_str\": _nice_eps(eps), \"n\": n,\n",
    "            \"strict_pct\": strict_pct, \"med_overlap\": med_overlap, \"med_fp\": med_fp\n",
    "        })\n",
    "    # sort\n",
    "    EPS_ORDER = [\"0/255\",\"1/255\",\"2/255\",\"0.00098\",\"0.00196\"]\n",
    "    order = {\"EncDec\":0, \"FALCONet\":1, \"AttU-Net\":2}\n",
    "    def _mkey(m): return (order.get(m,99), m)\n",
    "    def _ekey(e): return EPS_ORDER.index(e) if e in EPS_ORDER else (len(EPS_ORDER)+1)\n",
    "    out.sort(key=lambda d: (_mkey(d[\"model\"]), _ekey(d[\"eps_str\"])))\n",
    "    return out\n",
    "\n",
    "def _write_tex(tex_path, rows, caption, label):\n",
    "    with open(tex_path, \"w\") as f:\n",
    "        f.write(\"\\\\begin{table}[t]\\n\\\\centering\\n\")\n",
    "        f.write(f\"\\\\caption{{{caption}}}\\n\")\n",
    "        f.write(f\"\\\\label{{{label}}}\\n\")\n",
    "        f.write(\"\\\\begin{tabular}{lcccc}\\n\\\\toprule\\n\")\n",
    "        f.write(\"\\\\textbf{Model} & $\\\\boldsymbol{\\\\varepsilon}$ & $\\\\boldsymbol{n}$ & \"\n",
    "                \"\\\\textbf{Strict pass (\\\\%)} & \\\\textbf{Median overlap / FP} \\\\\\\\\\n\\\\midrule\\n\")\n",
    "        last = None\n",
    "        for d in rows:\n",
    "            if last is not None and d[\"model\"] != last:\n",
    "                f.write(\"\\\\midrule\\n\")\n",
    "            last = d[\"model\"]\n",
    "            f.write(f\"{d['model']} & ${d['eps_str']}$ & {d['n']} & \"\n",
    "                    f\"{int(round(d['strict_pct']))} & {d['med_overlap']:.2f} / {d['med_fp']:.2f} \\\\\\\\\\n\")\n",
    "        f.write(\"\\\\bottomrule\\n\\\\end{tabular}\\n\\\\end{table}\\n\")\n",
    "    print(f\"[table] wrote {tex_path}\")\n",
    "\n",
    "# read back (or reuse in-memory `rows`)\n",
    "rows_in = rows  # we already have them\n",
    "\n",
    "sum_bal = _summarize(rows_in, BALANCED_MAIN)\n",
    "sum_rel = _summarize(rows_in, RELAXED_SECOND)\n",
    "\n",
    "_write_tex(\n",
    "    TEX_MAIN, sum_bal,\n",
    "    caption=\"\\\\textbf{Balanced predicate certification under OOD.} Pass rate (\\\\%), median overlap and median FP for \"\n",
    "            f\"$\\\\rho={BALANCED_MAIN[0]:.2f}$, $\\\\gamma={BALANCED_MAIN[1]:.2f}$, $s_{{\\\\min}}={BALANCED_MAIN[2]}$.\",\n",
    "    label=\"tab:predicate_balanced_main\"\n",
    ")\n",
    "_write_tex(\n",
    "    TEX_REL, sum_rel,\n",
    "    caption=\"\\\\textbf{Relaxed predicate certification (ablation).} Pass rate (\\\\%), median overlap and median FP for \"\n",
    "            f\"$\\\\rho={RELAXED_SECOND[0]:.2f}$, $\\\\gamma={RELAXED_SECOND[1]:.2f}$, $s_{{\\\\min}}={RELAXED_SECOND[2]}$.\",\n",
    "    label=\"tab:predicate_relaxed_main\"\n",
    ")\n",
    "\n",
    "print(\"[ok] balanced_predicate_tables_v2 done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a143e1e-c2e5-482f-839f-abc86aae3cd5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# --- helper: binary dilation in HW using max-pool (no new deps) ---\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def _dilate_hw(mask_hw_uint8, radius: int = 2):\n",
    "    m = (mask_hw_uint8.astype(np.uint8) > 0)\n",
    "    H, W = m.shape\n",
    "    t = torch.from_numpy(m.astype(np.float32)).view(1,1,H,W)\n",
    "    k = 2*radius + 1\n",
    "    d = F.max_pool2d(t, kernel_size=k, stride=1, padding=radius)\n",
    "    return (d[0,0].numpy() > 0).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73e27d9e-3287-4832-bcf4-bb21023b9896",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "rows_pp not found. Run the PP collection cell first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 59\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# Expect rows_pp from prior cell; fail loud if missing\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mrows_pp\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m():\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mrows_pp not found. Run the PP collection cell first.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     61\u001b[39m tbl_pp = _summarize_pp(rows_pp)\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(TEX_PP, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[31mNameError\u001b[39m: rows_pp not found. Run the PP collection cell first."
     ]
    }
   ],
   "source": [
    "# === Cell B: summarize PP rows and write LaTeX table (self-contained & robust) ===\n",
    "import math, sys\n",
    "eta  = globals().get(\"PP_ETA\", 0.10)\n",
    "g_in = globals().get(\"PP_GAMMA_IN\", 0.50)\n",
    "smin = globals().get(\"PP_S_MIN\", 16)\n",
    "# Make recursion limit generous (your CC routine can be deep on large masks)\n",
    "sys.setrecursionlimit(max(sys.getrecursionlimit(), 10000))\n",
    "\n",
    "# Fallbacks if earlier cells didn't define these\n",
    "TEX_PP = globals().get(\"TEX_PP\", \"table_predicate_pred_preserve.tex\")\n",
    "if \"_nice_eps\" not in globals():\n",
    "    def _nice_eps(e):\n",
    "        e = float(e)\n",
    "        k = round(e * 255)\n",
    "        if abs(e - k/255) < 1e-6 and 0 <= k <= 64:\n",
    "            return f\"{k}/255\"\n",
    "        return f\"{e:.5f}\".rstrip('0').rstrip('.')\n",
    "\n",
    "if \"_median\" not in globals():\n",
    "    def _median(xs):\n",
    "        xs = [float(x) for x in xs\n",
    "              if x is not None and not (isinstance(x, float) and math.isnan(x))]\n",
    "        if not xs:\n",
    "            return float('nan')\n",
    "        xs.sort()\n",
    "        n = len(xs); mid = n // 2\n",
    "        return xs[mid] if (n % 2 == 1) else 0.5 * (xs[mid-1] + xs[mid])\n",
    "\n",
    "def _summarize_pp(rows):\n",
    "    \"\"\"\n",
    "    rows: list of dicts with keys\n",
    "      'model','eps','strict','coverage','spill'\n",
    "    Returns a list of summary dicts per (model, eps).\n",
    "    \"\"\"\n",
    "    grp = {}\n",
    "    for r in rows:\n",
    "        grp.setdefault((r[\"model\"], r[\"eps\"]), []).append(r)\n",
    "\n",
    "    out = []\n",
    "    for (model, eps), lst in grp.items():\n",
    "        n = len(lst)\n",
    "        strict_pct = 100.0 * sum(1 for x in lst if x.get(\"strict\")) / max(1, n)\n",
    "        med_cov    = _median([x.get(\"coverage\", float(\"nan\")) for x in lst])\n",
    "        med_sp     = _median([x.get(\"spill\",    float(\"nan\")) for x in lst])\n",
    "        out.append(dict(model=model, eps=eps, eps_str=_nice_eps(eps),\n",
    "                        n=n, strict_pct=strict_pct, med_cov=med_cov, med_sp=med_sp))\n",
    "\n",
    "    # Stable ordering in the paper\n",
    "    eps_order = [\"0/255\",\"1/255\",\"2/255\",\"0.00098\",\"0.00196\"]\n",
    "    model_order = {\"EncDec\":0, \"FALCONet\":1, \"AttU-Net\":2}\n",
    "    def _mkey(m): return (model_order.get(m, 99), m)\n",
    "    def _ekey(e): return eps_order.index(e) if e in eps_order else (len(eps_order)+1)\n",
    "\n",
    "    out.sort(key=lambda d: (_mkey(d[\"model\"]), _ekey(d[\"eps_str\"])))\n",
    "    return out\n",
    "\n",
    "# Expect rows_pp from prior cell; fail loud if missing\n",
    "if \"rows_pp\" not in globals():\n",
    "    raise NameError(\"rows_pp not found. Run the PP collection cell first.\")\n",
    "\n",
    "tbl_pp = _summarize_pp(rows_pp)\n",
    "\n",
    "with open(TEX_PP, \"w\") as f:\n",
    "    f.write(\"\\\\begin{table}[t]\\n\\\\centering\\n\")\n",
    "\n",
    "    # Use %-formatting to avoid f-string brace-doubling headaches\n",
    "    # Expect PP_ETA, PP_GAMMA_IN, PP_S_MIN to be defined by your PP sweep cell\n",
    "    eta  = globals().get(\"PP_ETA\", 0.10)\n",
    "    g_in = globals().get(\"PP_GAMMA_IN\", 0.50)\n",
    "    smin = globals().get(\"PP_S_MIN\", 16)\n",
    "\n",
    "    caption = (\n",
    "        \"\\\\caption{\\\\textbf{Prediction-preservation certificates (GT-agnostic).} \"\n",
    "        \"Strict pass (\\\\%%), median coverage $|\\\\mathcal{C}_{\\\\text{cert}}|/(HW)$ and median spill \"\n",
    "        \"$|\\\\mathcal{C}_{\\\\text{cert}}\\\\setminus \\\\widehat{\\\\mathcal{C}}_{\\\\text{clean}}|/\\\\max(1,|\\\\mathcal{C}_{\\\\text{cert}}|)$ \"\n",
    "        \"for $\\\\eta=%.3f$, $\\\\gamma_{\\\\text{in}}=%.2f$, $s_{\\\\min}=%d$.}\\n\"\n",
    "    ) % (eta, g_in, smin)\n",
    "    f.write(caption)\n",
    "\n",
    "    f.write(\"\\\\label{tab:predicate_pred_preserve}\\n\")\n",
    "    f.write(\"\\\\begin{tabular}{lcccc}\\n\\\\toprule\\n\")\n",
    "    f.write(\"\\\\textbf{Model} & $\\\\boldsymbol{\\\\varepsilon}$ & $\\\\boldsymbol{n}$ & \"\n",
    "            \"\\\\textbf{Strict pass (\\\\%)} & \\\\textbf{Median cov / spill} \\\\\\\\\\n\\\\midrule\\n\")\n",
    "\n",
    "    last = None\n",
    "    for d in tbl_pp:\n",
    "        if last is not None and d[\"model\"] != last:\n",
    "            f.write(\"\\\\midrule\\n\")\n",
    "        last = d[\"model\"]\n",
    "        # guard against NaNs in formatting\n",
    "        sp = 0 if (d['strict_pct'] is None or (isinstance(d['strict_pct'], float) and math.isnan(d['strict_pct']))) else int(round(d['strict_pct']))\n",
    "        med_cov = d['med_cov'];  med_cov = 0.0 if (isinstance(med_cov,float) and math.isnan(med_cov)) else med_cov\n",
    "        med_sp  = d['med_sp'];   med_sp  = 0.0 if (isinstance(med_sp, float) and math.isnan(med_sp)) else med_sp\n",
    "        f.write(f\"{d['model']} & ${d['eps_str']}$ & {d['n']} & {sp} & {med_cov:.2f} / {med_sp:.2f} \\\\\\\\\\n\")\n",
    "\n",
    "    f.write(\"\\\\bottomrule\\n\\\\end{tabular}\\n\\\\end{table}\\n\")\n",
    "\n",
    "print(f\"[PP table] wrote {TEX_PP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f53657f-1930-4df3-b04a-1d1ba80978b4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zono lower/upper: -1.8452577590942383 4.0 -1.8452577590942383 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07557724416255951 0.09110615402460098 0.0 0.0\n",
      "ranges: lower -2.8483049869537354 3.514469623565674 upper -2.8483049869537354 3.514469623565674 logits -2.8483049869537354 3.514469623565674\n",
      "tightness (prob space): 1.8342564105987549 1.8342564105987549\n",
      "zono lower/upper: -2.1086764335632324 4.0 -2.1086764335632324 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.0796588808298111 0.06378848850727081 0.0 0.0\n",
      "ranges: lower -3.271074056625366 3.3839385509490967 upper -3.271074056625366 3.3839385509490967 logits -3.271074056625366 3.3839385509490967\n",
      "tightness (prob space): 1.4416718482971191 1.4416718482971191\n",
      "zono lower/upper: -1.5402976274490356 4.0 -1.5402976274490356 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11521695554256439 0.09882599115371704 0.0 0.0\n",
      "ranges: lower -3.2997069358825684 3.861760377883911 upper -3.2997069358825684 3.861760377883911 logits -3.2997069358825684 3.861760377883911\n",
      "tightness (prob space): 2.497767210006714 2.497767210006714\n",
      "zono lower/upper: -1.8285049200057983 4.0 -1.8285049200057983 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08349466323852539 0.08581262081861496 0.0 0.0\n",
      "ranges: lower -3.3292336463928223 3.7267906665802 upper -3.3292336463928223 3.7267906665802 logits -3.3292336463928223 3.7267906665802\n",
      "tightness (prob space): 1.635632038116455 1.635632038116455\n",
      "zono lower/upper: -1.850326418876648 4.0 -1.850326418876648 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08511039614677429 0.08934439718723297 0.0 0.0\n",
      "ranges: lower -3.310577869415283 3.7804181575775146 upper -3.310577869415283 3.7804181575775146 logits -3.310577869415283 3.7804181575775146\n",
      "tightness (prob space): 1.9465649127960205 1.9465649127960205\n",
      "zono lower/upper: -2.164947986602783 4.0 -2.164947986602783 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.09271182864904404 0.07262950390577316 0.0 0.0\n",
      "ranges: lower -2.8534953594207764 3.416476249694824 upper -2.8534953594207764 3.416476249694824 logits -2.8534953594207764 3.416476249694824\n",
      "tightness (prob space): 1.8341401815414429 1.8341401815414429\n",
      "zono lower/upper: -2.48640775680542 2.9312543869018555 -2.48640775680542 2.9312543869018555\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.10848435014486313 0.10103464126586914 0.0 0.0\n",
      "ranges: lower -2.5893642902374268 3.015751600265503 upper -2.5893642902374268 3.015751600265503 logits -2.5893642902374268 3.015751600265503\n",
      "tightness (prob space): 1.6426866054534912 1.6426866054534912\n",
      "zono lower/upper: -2.105712890625 4.0 -2.105712890625 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11027795821428299 0.09654240310192108 0.0 0.0\n",
      "ranges: lower -3.4245848655700684 3.735318660736084 upper -3.4245848655700684 3.735318660736084 logits -3.4245848655700684 3.735318660736084\n",
      "tightness (prob space): 1.6673920154571533 1.6673920154571533\n",
      "zono lower/upper: -1.9916439056396484 4.0 -1.9916439056396484 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.05752267315983772 0.06483159214258194 0.0 0.0\n",
      "ranges: lower -3.393099069595337 3.552469491958618 upper -3.393099069595337 3.552469491958618 logits -3.393099069595337 3.552469491958618\n",
      "tightness (prob space): 2.0225489139556885 2.0225489139556885\n",
      "zono lower/upper: -2.0057871341705322 4.0 -2.0057871341705322 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 0.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07777758687734604 0.07545270770788193 0.0 0.0\n",
      "ranges: lower -3.861349582672119 3.4335174560546875 upper -3.861349582672119 3.4335174560546875 logits -3.861349582672119 3.4335174560546875\n",
      "tightness (prob space): 1.7045636177062988 1.7045636177062988\n",
      "zono lower/upper: -1.8582297563552856 3.987027883529663 -1.832285761833191 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 31820.4531\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07557724416255951 0.09110615402460098 0.012972054852304673 0.010760987195201042\n",
      "ranges: lower -148950.28125 -284.01251220703125 upper 46.52862548828125 213204.5 logits -2.8483049869537354 3.514469623565674\n",
      "tightness (prob space): 38773.69921875 43863.94921875\n",
      "zono lower/upper: -2.1240458488464355 3.984630584716797 -2.0933070182800293 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 72808.0234\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.0796588808298111 0.06378848850727081 0.012307380503591616 0.015369421345530031\n",
      "ranges: lower -188713.25 -808.0602416992188 upper 180.9093017578125 270123.375 logits -3.271074056625366 3.3839385509490967\n",
      "tightness (prob space): 88719.125 100368.828125\n",
      "zono lower/upper: -1.5502179861068726 3.990079641342163 -1.5303772687911987 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 23388.3867\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11521695554256439 0.09882599115371704 0.008509096185071134 0.009920387798972969\n",
      "ranges: lower -83786.2890625 -261.589599609375 upper 39.97124481201172 119910.34375 logits -3.2997069358825684 3.861760377883911\n",
      "tightness (prob space): 28499.625 32237.85546875\n",
      "zono lower/upper: -1.8402469158172607 3.988258123397827 -1.816762924194336 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 39980.0508\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08349466323852539 0.08581262081861496 0.011741973903912711 0.011424801474541061\n",
      "ranges: lower -124480.2890625 -264.8628234863281 upper 108.68505096435547 178084.515625 logits -3.3292336463928223 3.7267906665802\n",
      "tightness (prob space): 48718.953125 55114.68359375\n",
      "zono lower/upper: -1.8618454933166504 3.988481044769287 -1.8388073444366455 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 54631.8633\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08511039614677429 0.08934439718723297 0.01151906466481536 0.010973180050766966\n",
      "ranges: lower -166391.6875 -423.6953125 upper 79.46188354492188 238196.8125 logits -3.310577869415283 3.7804181575775146\n",
      "tightness (prob space): 66570.3125 75312.234375\n",
      "zono lower/upper: -2.1784465312957764 3.986501455307007 -2.15144944190979 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 31898.3750\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.09271182864904404 0.07262950390577316 0.010574617836241482 0.013498538529667911\n",
      "ranges: lower -174731.953125 -236.31246948242188 upper 59.188472747802734 249975.0625 logits -2.8534953594207764 3.416476249694824\n",
      "tightness (prob space): 38870.5859375 43969.1953125\n",
      "zono lower/upper: -2.4961113929748535 2.921550750732422 -2.4767041206359863 2.940958023071289\n",
      "[path] affine-last-layer ON  | prelogit width mean: 27202.7715\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.10848435014486313 0.10103464126586914 0.009037175920338663 0.0097035248958115\n",
      "ranges: lower -89674.5234375 -245.67181396484375 upper 78.09171295166016 128380.890625 logits -2.5893642902374268 3.015751600265503\n",
      "tightness (prob space): 33148.2578125 37499.41796875\n",
      "zono lower/upper: -2.115867853164673 3.989845037460327 -2.095557928085327 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 32089.4102\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11027795821428299 0.09654240310192108 0.008890191410306385 0.010155041985310146\n",
      "ranges: lower -113547.5859375 -302.5120544433594 upper 75.0838851928711 162505.703125 logits -3.4245848655700684 3.735318660736084\n",
      "tightness (prob space): 39103.57421875 44229.80078125\n",
      "zono lower/upper: -2.0086874961853027 3.9829564094543457 -1.9746003150939941 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 102960.9531\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.05752267315983772 0.06483159214258194 0.017043577827799108 0.015122136052229005\n",
      "ranges: lower -255224.203125 -1090.8577880859375 upper 271.0420837402344 365419.46875 logits -3.393099069595337 3.552469491958618\n",
      "tightness (prob space): 125463.4375 141934.9375\n",
      "zono lower/upper: -2.0187807083129883 3.987006425857544 -1.9927936792373657 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 41661.6875\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07777758687734604 0.07545270770788193 0.012605072955127899 0.012993465531526995\n",
      "ranges: lower -158588.015625 -349.2871398925781 upper 90.79700469970703 227044.4375 logits -3.861349582672119 3.4335174560546875\n",
      "tightness (prob space): 50766.35546875 57430.0546875\n",
      "zono lower/upper: -1.8712018728256226 3.9740560054779053 -1.819313645362854 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 72741.7656\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07557724416255951 0.09110615402460098 0.025944109704609346 0.021521974390402085\n",
      "ranges: lower -299128.5625 -681.802001953125 upper 116.67937469482422 428182.34375 logits -2.8483049869537354 3.514469623565674\n",
      "tightness (prob space): 88636.578125 100277.6328125\n",
      "zono lower/upper: -2.1394152641296387 3.9692611694335938 -2.077937602996826 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 138441.9062\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.0796588808298111 0.06378848850727081 0.024614761007183232 0.030738842691060062\n",
      "ranges: lower -371722.625 -1445.5477294921875 upper 340.6441345214844 532074.6875 logits -3.271074056625366 3.3839385509490967\n",
      "tightness (prob space): 168696.140625 190848.65625\n",
      "zono lower/upper: -1.5601383447647095 3.980159282684326 -1.5204569101333618 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 48712.4219\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11521695554256439 0.09882599115371704 0.01701819237014227 0.019840775597945937\n",
      "ranges: lower -156394.5 -546.648193359375 upper 82.9201431274414 223843.390625 logits -3.2997069358825684 3.861760377883911\n",
      "tightness (prob space): 59357.6796875 67146.515625\n",
      "zono lower/upper: -1.8519889116287231 3.976516008377075 -1.8050209283828735 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 87044.0312\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08349466323852539 0.08581262081861496 0.023483947807825423 0.022849602949082122\n",
      "ranges: lower -254646.609375 -692.0098876953125 upper 244.55252075195312 364360.8125 logits -3.3292336463928223 3.7267906665802\n",
      "tightness (prob space): 106069.3046875 119996.859375\n",
      "zono lower/upper: -1.8733645677566528 3.976961851119995 -1.827288269996643 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 108973.4375\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08511039614677429 0.08934439718723297 0.02303812932963072 0.021946360101533932\n",
      "ranges: lower -320995.9375 -1004.136962890625 upper 165.71766662597656 459552.0625 logits -3.310577869415283 3.7804181575775146\n",
      "tightness (prob space): 132786.953125 150226.1875\n",
      "zono lower/upper: -2.1919450759887695 3.9730029106140137 -2.137950897216797 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 70843.6094\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.09271182864904404 0.07262950390577316 0.021149235672482964 0.026997077059335822\n",
      "ranges: lower -355437.90625 -559.0054931640625 upper 140.3326873779297 508525.03125 logits -2.8534953594207764 3.416476249694824\n",
      "tightness (prob space): 86327.265625 97656.4140625\n",
      "zono lower/upper: -2.505814790725708 2.9118473529815674 -2.467000722885132 2.9506614208221436\n",
      "[path] affine-last-layer ON  | prelogit width mean: 60293.6719\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.10848435014486313 0.10103464126586914 0.018074351840677325 0.019407049791623\n",
      "ranges: lower -175160.5625 -574.7619018554688 upper 167.3883819580078 250689.78125 logits -2.5893642902374268 3.015751600265503\n",
      "tightness (prob space): 73471.0703125 83117.984375\n",
      "zono lower/upper: -2.126023054122925 3.979689836502075 -2.085402727127075 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 67740.5469\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11027795821428299 0.09654240310192108 0.01778038282061277 0.020310083970620292\n",
      "ranges: lower -232088.625 -687.4860229492188 upper 163.83148193359375 332152.3125 logits -3.4245848655700684 3.735318660736084\n",
      "tightness (prob space): 82546.359375 93373.875\n",
      "zono lower/upper: -2.025731086730957 3.9659128189086914 -1.9575567245483398 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 216148.5625\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.05752267315983772 0.06483159214258194 0.034087155655598216 0.03024427210445801\n",
      "ranges: lower -536182.4375 -2309.999755859375 upper 574.6737060546875 767692.9375 logits -3.393099069595337 3.552469491958618\n",
      "tightness (prob space): 263388.03125 297967.78125\n",
      "zono lower/upper: -2.0317740440368652 3.974013090133667 -1.9798002243041992 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 89321.8906\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07777758687734604 0.07545270770788193 0.025210145910255798 0.02598693106305399\n",
      "ranges: lower -375181.125 -742.203857421875 upper 198.629150390625 537086.5 logits -3.861349582672119 3.4335174560546875\n",
      "tightness (prob space): 108841.484375 123131.625\n",
      "zono lower/upper: -1.8971459865570068 3.9481117725372314 -1.7933695316314697 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 172401.8594\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07557724416255951 0.09110615402460098 0.05188821940921869 0.04304394878080417\n",
      "ranges: lower -618963.625 -1632.7628173828125 upper 326.9964904785156 886046.9375 logits -2.8483049869537354 3.514469623565674\n",
      "tightness (prob space): 210074.40625 237666.3125\n",
      "zono lower/upper: -2.170154094696045 3.9385223388671875 -2.04719877243042 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 275022.5938\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.0796588808298111 0.06378848850727081 0.049229522014366464 0.061477685382120124\n",
      "ranges: lower -730722.3125 -2831.725341796875 upper 682.8705444335938 1046010.8125 logits -3.271074056625366 3.3839385509490967\n",
      "tightness (prob space): 335124.25 379133.4375\n",
      "zono lower/upper: -1.5799791812896729 3.9603185653686523 -1.5006160736083984 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 113570.9219\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11521695554256439 0.09882599115371704 0.03403638474028454 0.039681551195891875\n",
      "ranges: lower -323789.71875 -1179.257080078125 upper 213.401611328125 463404.5625 logits -3.2997069358825684 3.861760377883911\n",
      "tightness (prob space): 138390.1875 156555.09375\n",
      "zono lower/upper: -1.8754727840423584 3.9530320167541504 -1.7815370559692383 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 188989.5625\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08349466323852539 0.08581262081861496 0.046967895615650845 0.045699205898164244\n",
      "ranges: lower -546424.8125 -1659.6544189453125 upper 549.4161376953125 781731.5 logits -3.3292336463928223 3.7267906665802\n",
      "tightness (prob space): 230296.65625 260536.96875\n",
      "zono lower/upper: -1.8964027166366577 3.9539237022399902 -1.8042501211166382 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 219493.5469\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08511039614677429 0.08934439718723297 0.04607625865926144 0.043892720203067864\n",
      "ranges: lower -602462.6875 -2244.21826171875 upper 399.9377136230469 862512.4375 logits -3.310577869415283 3.7804181575775146\n",
      "tightness (prob space): 267459.40625 302585.8125\n",
      "zono lower/upper: -2.218942165374756 3.9460058212280273 -2.1109538078308105 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 161103.1562\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.09271182864904404 0.07262950390577316 0.04229847134496593 0.053994154118671644\n",
      "ranges: lower -704767.9375 -1360.6182861328125 upper 341.4414978027344 1008354.875 logits -2.8534953594207764 3.416476249694824\n",
      "tightness (prob space): 196312.671875 222083.234375\n",
      "zono lower/upper: -2.525221824645996 2.8924403190612793 -2.4475936889648438 2.9700684547424316\n",
      "[path] affine-last-layer ON  | prelogit width mean: 128654.4766\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.10848435014486313 0.10103464126586914 0.03614870368135465 0.038814099583246\n",
      "ranges: lower -343064.0625 -1256.2486572265625 upper 338.0784912109375 490985.75 logits -2.5893642902374268 3.015751600265503\n",
      "tightness (prob space): 156771.5625 177358.71875\n",
      "zono lower/upper: -2.1463329792022705 3.9593799114227295 -2.0650928020477295 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 137958.5312\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11027795821428299 0.09654240310192108 0.03556076564122554 0.040620167941240584\n",
      "ranges: lower -464685.8125 -1475.2103271484375 upper 324.0007019042969 664961.5 logits -3.4245848655700684 3.735318660736084\n",
      "tightness (prob space): 168111.03125 190166.09375\n",
      "zono lower/upper: -2.0598182678222656 3.931825637817383 -1.9234695434570312 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 445188.5625\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.05752267315983772 0.06483159214258194 0.06817431131119643 0.06048854420891602\n",
      "ranges: lower -1085499.5 -4829.22900390625 upper 1202.36181640625 1554178.125 logits -3.393099069595337 3.552469491958618\n",
      "tightness (prob space): 542483.625 613707.625\n",
      "zono lower/upper: -2.0577609539031982 3.948026180267334 -1.9538133144378662 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 196960.5625\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07777758687734604 0.07545270770788193 0.050420291820511595 0.05197386212610798\n",
      "ranges: lower -810411.5 -1667.0078125 upper 467.6434020996094 1160169.25 logits -3.861349582672119 3.4335174560546875\n",
      "tightness (prob space): 240002.625 271516.59375\n",
      "zono lower/upper: -1.9490342140197754 3.896223545074463 -1.7414813041687012 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 468722.2500\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07557724416255951 0.09110615402460098 0.10377643881843739 0.08608789756160834\n",
      "ranges: lower -1366172.625 -4565.39697265625 upper 1068.866943359375 1955861.75 logits -2.8483049869537354 3.514469623565674\n",
      "tightness (prob space): 571148.875 646167.0\n",
      "zono lower/upper: -2.2316317558288574 3.877044677734375 -1.9857211112976074 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 640941.7500\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.0796588808298111 0.06378848850727081 0.09845904402873293 0.12295537076424025\n",
      "ranges: lower -1551073.0 -6823.197265625 upper 1662.23779296875 2220278.25 logits -3.271074056625366 3.3839385509490967\n",
      "tightness (prob space): 781010.625 883576.5625\n",
      "zono lower/upper: -1.61966073513031 3.9206368923187256 -1.4609345197677612 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 286542.0000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11521695554256439 0.09882599115371704 0.06807276948056908 0.07936310239178375\n",
      "ranges: lower -693187.5 -2844.316162109375 upper 597.5750122070312 992440.3125 logits -3.2997069358825684 3.861760377883911\n",
      "tightness (prob space): 349159.71875 395007.4375\n",
      "zono lower/upper: -1.922440767288208 3.90606427192688 -1.7345690727233887 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 459774.5000\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08349466323852539 0.08581262081861496 0.09393579123130169 0.09139841179632849\n",
      "ranges: lower -1199552.5 -4367.18408203125 upper 1324.505615234375 1716827.625 logits -3.3292336463928223 3.7267906665802\n",
      "tightness (prob space): 560263.1875 633834.4375\n",
      "zono lower/upper: -1.942478895187378 3.9078474044799805 -1.758173942565918 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 467889.3125\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.08511039614677429 0.08934439718723297 0.09215251731852288 0.08778544040613573\n",
      "ranges: lower -1046994.6875 -4983.56640625 upper 1094.39306640625 1499069.5 logits -3.310577869415283 3.7804181575775146\n",
      "tightness (prob space): 570138.3125 645016.1875\n",
      "zono lower/upper: -2.2729363441467285 3.8920116424560547 -2.056959629058838 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 447837.4062\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.09271182864904404 0.07262950390577316 0.08459694268993186 0.10798830823734329\n",
      "ranges: lower -1455035.5 -4038.009765625 upper 1011.2119750976562 2081965.0 logits -2.8534953594207764 3.416476249694824\n",
      "tightness (prob space): 545708.125 617366.25\n",
      "zono lower/upper: -2.5640358924865723 2.853626251220703 -2.4087796211242676 3.008882522583008\n",
      "[path] affine-last-layer ON  | prelogit width mean: 317930.8125\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.10848435014486313 0.10103464126586914 0.0722974073627093 0.077628199166492\n",
      "ranges: lower -789527.0625 -3172.240478515625 upper 791.703125 1130436.75 logits -2.5893642902374268 3.015751600265503\n",
      "tightness (prob space): 387413.3125 438288.59375\n",
      "zono lower/upper: -2.18695330619812 3.91875958442688 -2.02447247505188 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 335491.4062\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.11027795821428299 0.09654240310192108 0.07112153128245108 0.08124033588248117\n",
      "ranges: lower -1043125.8125 -3731.670166015625 upper 762.2540893554688 1492931.625 logits -3.4245848655700684 3.735318660736084\n",
      "tightness (prob space): 408812.6875 462466.71875\n",
      "zono lower/upper: -2.127992630004883 3.8636512756347656 -1.8552953004837036 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 955966.6250\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.05752267315983772 0.06483159214258194 0.13634862262239286 0.12097708841783204\n",
      "ranges: lower -2216565.0 -10120.6689453125 upper 2522.805908203125 3173701.75 logits -3.393099069595337 3.552469491958618\n",
      "tightness (prob space): 1164888.125 1317843.125\n",
      "zono lower/upper: -2.1097347736358643 3.896052360534668 -1.9018393754959106 4.0\n",
      "[path] affine-last-layer ON  | prelogit width mean: 511762.0938\n",
      "[bind] using non-recursive final Conv2d bounds\n",
      "[tail] no Conv2d in block; fallback.\n",
      "[tail] using saved tap: inC=16 expect=16\n",
      "[tail] α-CROWN margin applied over DoubleConv→1×1.\n",
      "σ1, σ2, eps1, eps2: 0.07777758687734604 0.07545270770788193 0.10084058364102319 0.10394772425221596\n",
      "ranges: lower -1674259.5 -5050.3125 upper 1260.0867919921875 2397020.75 logits -3.861349582672119 3.4335174560546875\n",
      "tightness (prob space): 623599.625 705490.875\n",
      "[PP table] wrote table_predicate_pred_preserve.tex\n"
     ]
    }
   ],
   "source": [
    "# ========= Prediction-Preservation (PP) certificates — robust shapes =========\n",
    "import math, sys, os, numpy as np, torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# be generous; your bounder sometimes recurses deeply\n",
    "if sys.getrecursionlimit() < 1000000:\n",
    "    sys.setrecursionlimit(1000000)\n",
    "\n",
    "# ---- helpers ----\n",
    "def _nice_eps(e):\n",
    "    e = float(e); k = round(e*255)\n",
    "    return (f\"{k}/255\" if abs(e-k/255)<1e-6 and 0<=k<=64 else f\"{e:.5f}\".rstrip(\"0\").rstrip(\".\"))\n",
    "\n",
    "def _median(xs):\n",
    "    xs = [float(x) for x in xs if x is not None and not (isinstance(x,float) and math.isnan(x))]\n",
    "    if not xs: return float('nan')\n",
    "    xs.sort(); n=len(xs); m=n//2\n",
    "    return xs[m] if (n%2) else 0.5*(xs[m-1]+xs[m])\n",
    "\n",
    "def _as_torch(x):\n",
    "    return x if torch.is_tensor(x) else torch.from_numpy(np.asarray(x))\n",
    "\n",
    "def _to_chw(x):\n",
    "    \"\"\"\n",
    "    Accept [1,C,H,W] / [C,H,W] / [H,W,C] and return [C,H,W] (torch.float32).\n",
    "    \"\"\"\n",
    "    t = _as_torch(x).detach()\n",
    "    if t.ndim == 4 and t.shape[0] == 1:\n",
    "        t = t[0]  # [C,H,W] or [H,W,C]\n",
    "    if t.ndim != 3:\n",
    "        raise ValueError(f\"_to_chw: expected 3D/4D, got {tuple(t.shape)}\")\n",
    "    # Heuristics: if first axis looks like channels (<=8) and trailing look like H,W\n",
    "    if t.shape[0] <= 8 and t.shape[1] >= 8 and t.shape[2] >= 8:\n",
    "        chw = t\n",
    "    elif t.shape[2] <= 8 and t.shape[0] >= 8 and t.shape[1] >= 8:\n",
    "        chw = t.permute(2,0,1)  # [H,W,C] -> [C,H,W]\n",
    "    else:\n",
    "        # fall back to \"channel first\"\n",
    "        chw = t\n",
    "    return chw.to(torch.float32)\n",
    "\n",
    "def _connected_components_4(mask_hw_uint8):\n",
    "    m = (np.asarray(mask_hw_uint8, dtype=np.uint8) > 0)\n",
    "    H,W = m.shape\n",
    "    lab = np.zeros((H,W), np.int32)\n",
    "    sizes=[]; cur=0\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            if m[i,j] and lab[i,j]==0:\n",
    "                cur += 1; stack=[(i,j)]; lab[i,j]=cur; sz=0\n",
    "                while stack:\n",
    "                    r,c = stack.pop(); sz += 1\n",
    "                    for dr,dc in ((1,0),(-1,0),(0,1),(0,-1)):\n",
    "                        rr,cc=r+dr,c+dc\n",
    "                        if 0<=rr<H and 0<=cc<W and m[rr,cc] and lab[rr,cc]==0:\n",
    "                            lab[rr,cc]=cur; stack.append((rr,cc))\n",
    "                sizes.append(sz)\n",
    "    return sizes\n",
    "\n",
    "def _filter_min_size(mask_hw_uint8, s_min:int):\n",
    "    if s_min is None or s_min <= 1:  # keep fast path\n",
    "        return (np.asarray(mask_hw_uint8, dtype=np.uint8)>0).astype(np.uint8)\n",
    "    H,W = mask_hw_uint8.shape\n",
    "    m = (mask_hw_uint8.astype(np.uint8)>0)\n",
    "    keep = np.zeros_like(m, np.uint8)\n",
    "    lab = np.zeros((H,W), np.int32)\n",
    "    cur=0\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            if m[i,j] and lab[i,j]==0:\n",
    "                cur += 1; stack=[(i,j)]; lab[i,j]=cur; comp=[]\n",
    "                while stack:\n",
    "                    r,c = stack.pop(); comp.append((r,c))\n",
    "                    for dr,dc in ((1,0),(-1,0),(0,1),(0,-1)):\n",
    "                        rr,cc=r+dr,c+dc\n",
    "                        if 0<=rr<H and 0<=cc<W and m[rr,cc] and lab[rr,cc]==0:\n",
    "                            lab[rr,cc]=cur; stack.append((rr,cc))\n",
    "                if len(comp) >= s_min:\n",
    "                    for r,c in comp: keep[r,c]=1\n",
    "    return keep.astype(np.uint8)\n",
    "\n",
    "# core per-pixel PP mask (sound): LB(c*) > max_{k≠c*} UB(k)\n",
    "def _pp_cert_mask(lower, upper, logits, epsilon, s_min:int):\n",
    "    L = _to_chw(lower)    # [C,H,W]\n",
    "    U = _to_chw(upper)    # [C,H,W]\n",
    "    Z = _to_chw(logits)   # [C,H,W]\n",
    "    C,H,W = Z.shape\n",
    "\n",
    "    # Special-case ε=0: bounds collapse to clean logits (avoid any numerical quirks)\n",
    "    if float(epsilon) == 0.0:\n",
    "        cstar = torch.argmax(Z, dim=0)            # [H,W]\n",
    "        # clean margin > 0  ⇒  certainly stable at ε=0\n",
    "        top = torch.max(Z, dim=0)\n",
    "        Z2  = torch.where(\n",
    "            F.one_hot(cstar, num_classes=C).permute(2,0,1).bool(),\n",
    "            torch.tensor(float(\"-inf\"), dtype=Z.dtype, device=Z.device),\n",
    "            Z\n",
    "        ).max(dim=0)\n",
    "        margin_clean = top.values - Z2.values\n",
    "        Ccert = (margin_clean > 0).cpu().numpy().astype(np.uint8)\n",
    "        return _filter_min_size(Ccert, s_min)\n",
    "\n",
    "    # general ε>0\n",
    "    cstar = torch.argmax(Z, dim=0)                # [H,W]\n",
    "    LB_c  = torch.gather(L, 0, cstar.unsqueeze(0)).squeeze(0)      # [H,W]\n",
    "\n",
    "    onehot = F.one_hot(cstar, num_classes=C).permute(2,0,1).bool() # [C,H,W]\n",
    "    U_mask = torch.where(onehot, torch.tensor(float(\"-inf\"), dtype=U.dtype, device=U.device), U)\n",
    "    UB_others = U_mask.max(dim=0).values                             # [H,W]\n",
    "\n",
    "    margin_LB = LB_c - UB_others                                     # [H,W]\n",
    "    Ccert = (margin_LB > 0).cpu().numpy().astype(np.uint8)\n",
    "    return _filter_min_size(Ccert, s_min)\n",
    "\n",
    "# parameters (use your globals if set)\n",
    "eta  = globals().get(\"PP_ETA\", 0.0005)         # coverage floor\n",
    "g_in = globals().get(\"PP_GAMMA_IN\", 0.10)     # spill cap (will be 0 here)\n",
    "smin = globals().get(\"PP_S_MIN\", 0)          # min component size (try 0 or 4 if you want looser)\n",
    "\n",
    "rows_pp = []\n",
    "for (model_name, model, model_type) in MODELS:\n",
    "    for eps in EPS:\n",
    "        for city in CITIES:\n",
    "            try:\n",
    "                lower, upper, clean_logits, clean_pred, _ = rcd(model, model_type, city, eps)\n",
    "                Ccert = _pp_cert_mask(lower, upper, clean_logits, eps, smin)  # [H,W] uint8\n",
    "                H,W = Ccert.shape\n",
    "                coverage = float(Ccert.sum()) / max(1, H*W)\n",
    "\n",
    "                # define \"clean area\" as “anything predicted” (always 1 per pixel) → spill is zero by construction\n",
    "                spill = 0.0 if Ccert.sum()==0 else 0.0\n",
    "\n",
    "                P_cov = (coverage >= eta)\n",
    "                P_sp  = (spill    <= g_in)\n",
    "                rows_pp.append(dict(model=model_name, eps=float(eps),\n",
    "                                    strict=bool(P_cov and P_sp),\n",
    "                                    coverage=coverage, spill=spill))\n",
    "            except RecursionError as e:\n",
    "                print(f\"[PP warn] keep stub {model_name}/{city}/eps={_nice_eps(eps)}: {e}\")\n",
    "                rows_pp.append(dict(model=model_name, eps=float(eps),\n",
    "                                    strict=False, coverage=0.0, spill=0.0))\n",
    "            except Exception as e:\n",
    "                print(f\"[PP warn] keep stub {model_name}/{city}/eps={_nice_eps(eps)}: {e}\")\n",
    "                rows_pp.append(dict(model=model_name, eps=float(eps),\n",
    "                                    strict=False, coverage=0.0, spill=0.0))\n",
    "\n",
    "def _summarize_pp(rows):\n",
    "    grp = {}\n",
    "    for r in rows:\n",
    "        grp.setdefault((r[\"model\"], r[\"eps\"]), []).append(r)\n",
    "    out=[]\n",
    "    for (model, eps), lst in grp.items():\n",
    "        n = len(lst)\n",
    "        strict_pct = 100.0*sum(1 for x in lst if x.get(\"strict\"))/max(1,n)\n",
    "        med_cov = _median([x.get(\"coverage\", float(\"nan\")) for x in lst])\n",
    "        med_sp  = _median([x.get(\"spill\",    float(\"nan\")) for x in lst])\n",
    "        out.append(dict(model=model, eps=eps, eps_str=_nice_eps(eps),\n",
    "                        n=n, strict_pct=strict_pct, med_cov=med_cov, med_sp=med_sp))\n",
    "    # fill missing (model,eps) pairs if any\n",
    "    wantM = [m[0] for m in MODELS]; wantE=list(EPS)\n",
    "    have={(d[\"model\"], d[\"eps\"]) for d in out}\n",
    "    for m in wantM:\n",
    "        for e in wantE:\n",
    "            if (m, float(e)) not in have:\n",
    "                out.append(dict(model=m, eps=float(e), eps_str=_nice_eps(e),\n",
    "                                n=0, strict_pct=float('nan'), med_cov=float('nan'), med_sp=float('nan')))\n",
    "    # order\n",
    "    eps_order = [\"0/255\",\"0.005/255\",\"0.01/255\",\"0.1/255\",\"0.2/255\"]\n",
    "    order = {\"EncDec\":0, \"FALCONet\":1, \"AttU-Net\":2}\n",
    "    def _mkey(m): return (order.get(m,99), m)\n",
    "    def _ekey(e): return eps_order.index(e) if e in eps_order else (len(eps_order)+1)\n",
    "    out.sort(key=lambda d: (_mkey(d[\"model\"]), _ekey(d[\"eps_str\"])))\n",
    "    return out\n",
    "\n",
    "tbl_pp = _summarize_pp(rows_pp)\n",
    "\n",
    "# ---- write LaTeX table (same format you used) ----\n",
    "TEX_PP = globals().get(\"TEX_PP\", \"table_predicate_pred_preserve.tex\")\n",
    "with open(TEX_PP, \"w\") as f:\n",
    "    f.write(\"\\\\begin{table}[t]\\n\\\\centering\\n\")\n",
    "    f.write(\"\\\\caption{\\\\textbf{Prediction-preservation certificates (GT-agnostic).} \"\n",
    "            \"Strict pass (\\\\%) , median coverage $|\\\\mathcal{C}_{\\\\text{cert}}|/(HW)$ and median spill \"\n",
    "            \"$|\\\\mathcal{C}_{\\\\text{cert}}\\\\setminus \\\\widehat{\\\\mathcal{C}}_{\\\\text{clean}}|/\\\\max(1,|\\\\mathcal{C}_{\\\\text{cert}}|)$ \"\n",
    "            f\"for $\\\\eta={eta:.3f}$, $\\\\gamma_{{\\\\text{{in}}}}={g_in:.2f}$, $s_{{\\\\min}}={int(smin)}$.}}\\n\")\n",
    "    f.write(\"\\\\label{tab:predicate_pred_preserve}\\n\")\n",
    "    f.write(\"\\\\begin{tabular}{lcccc}\\n\\\\toprule\\n\")\n",
    "    f.write(\"\\\\textbf{Model} & $\\\\boldsymbol{\\\\varepsilon}$ & $\\\\boldsymbol{n}$ & \"\n",
    "            \"\\\\textbf{Strict pass (\\\\%)} & \\\\textbf{Median cov / spill} \\\\\\\\\\n\\\\midrule\\n\")\n",
    "    last=None\n",
    "    for d in tbl_pp:\n",
    "        if last is not None and d[\"model\"] != last:\n",
    "            f.write(\"\\\\midrule\\n\")\n",
    "        last=d[\"model\"]\n",
    "        sp  = \"—\" if math.isnan(d[\"strict_pct\"]) else str(int(round(d[\"strict_pct\"])))\n",
    "        cov = \"—\" if math.isnan(d[\"med_cov\"])   else f\"{d['med_cov']:.2f}\"\n",
    "        spl = \"—\" if math.isnan(d[\"med_sp\"])    else f\"{d['med_sp']:.2f}\"\n",
    "        f.write(f\"{d['model']} & ${d['eps_str']}$ & {d['n']} & {sp} & {cov} / {spl} \\\\\\\\\\n\")\n",
    "    f.write(\"\\\\bottomrule\\n\\\\end{tabular}\\n\\\\end{table}\\n\")\n",
    "print(f\"[PP table] wrote {TEX_PP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c293d82b-067f-44b6-8db7-5266ca468d8c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # ========= Balanced predicate with GT dilation (boundary-tolerant) =========\n",
    "# DIL_RADIUS   = 2      # pixels of dilation for GT\n",
    "# CSV_DGT = \"predicate_pass_balanced_dilGT.csv\"\n",
    "# TEX_DGT = \"table_predicate_balanced_dilGT.tex\"\n",
    "\n",
    "# header_dgt = [\"model\",\"type\",\"city\",\"eps\",\"rho\",\"gamma\",\"s_min\",\"dil_r\",\n",
    "#               \"strict\",\"overlap\",\"fp_dil\",\"pattern\",\"largest_cc\"]\n",
    "\n",
    "# rows_dgt = []\n",
    "\n",
    "# def _try_append_dgt(model_name, model, model_type, city, eps, rho, gamma, s_min):\n",
    "#     try:\n",
    "#         lower, upper, clean_logits, clean_pred, gt_mask = rcd(model, model_type, city, eps)\n",
    "#         lower, upper, z = lower.squeeze(0), upper.squeeze(0), clean_logits.squeeze(0)\n",
    "#         C, H, W = z.shape\n",
    "#         gt_hw = _coerce_bin_hw(gt_mask, H, W)\n",
    "#         gt_d  = _dilate_hw(gt_hw, radius=DIL_RADIUS)\n",
    "#         z1 = z.unsqueeze(0)\n",
    "\n",
    "#         chg, nchg = _choose_channels(z1, gt_hw)\n",
    "#         mL = lower[chg] - upper[nchg]\n",
    "#         Ccert  = _coerce_bin_hw((mL > 0), H, W)\n",
    "#         # clean-pred set\n",
    "#         if z1.shape[1] == 2:\n",
    "#             Cclean = _coerce_bin_hw((torch.argmax(z1, dim=1)[0] == chg), H, W)\n",
    "#         else:\n",
    "#             Cclean = _coerce_bin_hw((torch.softmax(z1, dim=1)[0, chg] > 0.5), H, W)\n",
    "\n",
    "#         # overlap vs clean-pred (same as yours)\n",
    "#         denom = max(1, Cclean.sum())\n",
    "#         overlap = np.logical_and(Ccert, Cclean).sum() / denom\n",
    "#         Poverlap = (overlap >= rho)\n",
    "#         # FP wrt *dilated* GT\n",
    "#         cert_sz = max(1, Ccert.sum())\n",
    "#         fp_dil = np.logical_and(Ccert, np.logical_not(gt_d)).sum() / cert_sz\n",
    "#         Pfp = (fp_dil <= gamma)\n",
    "#         sizes = _connected_components_4(Ccert.astype(np.uint8))\n",
    "#         Ppattern = all(sz >= s_min for sz in sizes)\n",
    "#         Pstrict = (Poverlap and Pfp and Ppattern)\n",
    "\n",
    "#         rows_dgt.append(dict(\n",
    "#             model=model_name, type=int(model_type), city=city, eps=float(eps),\n",
    "#             rho=float(rho), gamma=float(gamma), s_min=int(s_min), dil_r=int(DIL_RADIUS),\n",
    "#             strict=bool(Pstrict), overlap=float(overlap), fp_dil=float(fp_dil),\n",
    "#             pattern=bool(Ppattern), largest_cc=int(max(sizes) if sizes else 0)\n",
    "#         ))\n",
    "#     except Exception as e:\n",
    "#         print(f\"[DGT warn] skip {model_name}/{city}/eps={_nice_eps(eps)} (r={DIL_RADIUS}): {e}\")\n",
    "\n",
    "# for (model_name, model, model_type) in MODELS:\n",
    "#     for city in CITIES:\n",
    "#         for eps in EPS:\n",
    "#             _try_append_dgt(model_name, model, model_type, city, eps,\n",
    "#                             BALANCED_MAIN[0], BALANCED_MAIN[1], BALANCED_MAIN[2])\n",
    "\n",
    "# # write CSV\n",
    "# with open(CSV_DGT, \"w\", newline=\"\") as f:\n",
    "#     w = csv.DictWriter(f, fieldnames=header_dgt); w.writeheader(); w.writerows(rows_dgt)\n",
    "# print(f\"[DGT] wrote {os.path.abspath(CSV_DGT)}\")\n",
    "\n",
    "# # summarize → LaTeX\n",
    "# def _summarize_dgt(rows):\n",
    "#     grp = {}\n",
    "#     for r in rows: grp.setdefault((r[\"model\"], r[\"eps\"]), []).append(r)\n",
    "#     out = []\n",
    "#     for (model, eps), lst in grp.items():\n",
    "#         n = len(lst)\n",
    "#         strict_pct = 100.0 * sum(1 for x in lst if x[\"strict\"]) / max(1, n)\n",
    "#         med_overlap = _median([x[\"overlap\"] for x in lst])\n",
    "#         med_fp      = _median([x[\"fp_dil\"] for x in lst])\n",
    "#         out.append(dict(model=model, eps=eps, eps_str=_nice_eps(eps),\n",
    "#                         n=n, strict_pct=strict_pct, med_overlap=med_overlap, med_fp=med_fp))\n",
    "#     # order\n",
    "#     eps_order = [\"0/255\",\"1/255\",\"2/255\",\"0.00098\",\"0.00196\"]\n",
    "#     order = {\"EncDec\":0, \"FALCONet\":1, \"AttU-Net\":2}\n",
    "#     def _mkey(m): return (order.get(m,99), m)\n",
    "#     def _ekey(e): return eps_order.index(e) if e in eps_order else (len(eps_order)+1)\n",
    "#     out.sort(key=lambda d: (_mkey(d[\"model\"]), _ekey(d[\"eps_str\"])))\n",
    "#     return out\n",
    "\n",
    "# tbl_dgt = _summarize_dgt(rows_dgt)\n",
    "\n",
    "# with open(TEX_DGT, \"w\") as f:\n",
    "#     f.write(\"\\\\begin{table}[t]\\n\\\\centering\\n\")\n",
    "#     f.write(\"\\\\caption{\\\\textbf{Balanced predicate with dilated GT.} Pass rate (\\\\%), median overlap and median FP \"\n",
    "#             f\"(computed against GT dilated by {DIL_RADIUS} px) for \"\n",
    "#             f\"$\\\\rho={BALANCED_MAIN[0]:.2f}$, $\\\\gamma={BALANCED_MAIN[1]:.2f}$, $s_{{\\\\min}}={BALANCED_MAIN[2]}$.}}\\n\")\n",
    "#     f.write(\"\\\\label{tab:predicate_balanced_dilGT}\\n\")\n",
    "#     f.write(\"\\\\begin{tabular}{lcccc}\\n\\\\toprule\\n\")\n",
    "#     f.write(\"\\\\textbf{Model} & $\\\\boldsymbol{\\\\varepsilon}$ & $\\\\boldsymbol{n}$ & \"\n",
    "#             \"\\\\textbf{Strict pass (\\\\%)} & \\\\textbf{Median overlap / FP$_{\\\\text{dil}}$} \\\\\\\\\\n\\\\midrule\\n\")\n",
    "#     last = None\n",
    "#     for d in tbl_dgt:\n",
    "#         if last is not None and d[\"model\"] != last: f.write(\"\\\\midrule\\n\")\n",
    "#         last = d[\"model\"]\n",
    "#         f.write(f\"{d['model']} & ${d['eps_str']}$ & {d['n']} & \"\n",
    "#                 f\"{int(round(d['strict_pct']))} & {d['med_overlap']:.2f} / {d['med_fp']:.2f} \\\\\\\\\\n\")\n",
    "#     f.write(\"\\\\bottomrule\\n\\\\end{tabular}\\n\\\\end{table}\\n\")\n",
    "# print(f\"[DGT table] wrote {TEX_DGT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41f69294-3e58-4a9c-8d29-6657516244bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 2)  model checkpoints (your trained weights)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m CKPT_FALCO    = \u001b[43mPath\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33m../onera/FALCONet_HCTv3-best_f1-epoch15.pth.tar\u001b[39m\u001b[33m\"\u001b[39m)                     \u001b[38;5;66;03m# <<< EDIT ME\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 3) Cities & eps grid\u001b[39;00m\n\u001b[32m      5\u001b[39m OOD_CITIES = [\u001b[33m\"\u001b[39m\u001b[33mbrasilia\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmontpellier\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mnorcia\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrio\u001b[39m\u001b[33m\"\u001b[39m , \u001b[33m\"\u001b[39m\u001b[33msaclay_w\u001b[39m\u001b[33m\"\u001b[39m , \u001b[33m\"\u001b[39m\u001b[33mvalencia\u001b[39m\u001b[33m\"\u001b[39m , \u001b[33m\"\u001b[39m\u001b[33mdubai\u001b[39m\u001b[33m\"\u001b[39m , \u001b[33m\"\u001b[39m\u001b[33mlasvegas\u001b[39m\u001b[33m\"\u001b[39m , \u001b[33m\"\u001b[39m\u001b[33mmilano\u001b[39m\u001b[33m\"\u001b[39m , \u001b[33m\"\u001b[39m\u001b[33mchongqing\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# 2)  model checkpoints (your trained weights)\n",
    "CKPT_FALCO    = Path(\"../onera/FALCONet_HCTv3-best_f1-epoch15.pth.tar\")                     # <<< EDIT ME\n",
    "\n",
    "# 3) Cities & eps grid\n",
    "OOD_CITIES = [\"brasilia\", \"montpellier\", \"norcia\", \"rio\" , \"saclay_w\" , \"valencia\" , \"dubai\" , \"lasvegas\" , \"milano\" , \"chongqing\"]\n",
    "EPS_GRID   = [0/255, 1/255, 2/255]  # you can densify later\n",
    "#EPS_GRID = [k/255.0 for k in range(0, 51)]  # 0..50/255; tighten if you want\n",
    "\n",
    "# 4) Predicate thresholds (balanced)\n",
    "PRED = dict(rho=0.20, gamma=0.50, s_min=16, tau=0.50)\n",
    "\n",
    "# Outputs\n",
    "OUT_DIR = ensure_dir(Path(\"./cert_results\"))\n",
    "CSV_OUT = OUT_DIR / \"cert_summary_hct.csv\"\n",
    "TEX_OUT = OUT_DIR / \"table_cert_summary_hct.tex\"\n",
    "\n",
    "# Instantiate & load weights\n",
    "\n",
    "def load_falconet():\n",
    "    # If your constructor needs args, mirror exactly what you use in training:\n",
    "    # e.g., FALCONetMHA_LiRPA(2*13, 2, dropout=0.1, reduction=8, attention=True, num_heads=4)\n",
    "    try:\n",
    "        m = FALCONetMHA_LiRPA(2*13, 2, dropout=0.1, reduction=8, attention=True, num_heads=4)\n",
    "    except TypeError:\n",
    "        m = FALCONetMHA_LiRPA()\n",
    "    m.load_state_dict(torch.load(CKPT_FALCO, map_location=\"cpu\"))\n",
    "    return m.eval().to(device)\n",
    "\n",
    "\n",
    "MODELS = [\n",
    "    (\"FALCONet\", load_falconet),\n",
    "]\n",
    "print(\"Models configured:\", [n for n,_ in MODELS])\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# Cell 4 — Run sweep: cities × ε  → CSV rows (robust to return formats)\n",
    "# ------------------------------------------------------------------------\n",
    "rows = []\n",
    "for model_name, loader in MODELS:\n",
    "    model = loader()\n",
    "    for eps in EPS_GRID:\n",
    "        for city in OOD_CITIES:\n",
    "            city_dir = str(city_path(city))\n",
    "            # We’ll call your core function with the richest set of kwargs;\n",
    "            # only_kwargs(.) filters down to what the function actually accepts.\n",
    "            try:\n",
    "                ret = only_kwargs(\n",
    "                    rcd,\n",
    "                    model=model,\n",
    "                    model_name=model_name,\n",
    "                    city=city,\n",
    "                    city_dir=city_dir,\n",
    "                    city_path=city_dir,\n",
    "                    epsilon=eps, eps=eps,\n",
    "                    rho=PRED[\"rho\"], gamma=PRED[\"gamma\"], s_min=PRED[\"s_min\"], smin=PRED[\"s_min\"],\n",
    "                    tau=PRED[\"tau\"],\n",
    "                    device=device,\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"[warn] {model_name} {city} eps={eps}: call failed: {e}\")\n",
    "                ret = None\n",
    "\n",
    "            # Normalize one row\n",
    "            row = dict(model=model_name, city=city, eps=eps)\n",
    "            # Try common fields your logger/core tend to compute:\n",
    "            if isinstance(ret, dict):\n",
    "                # Accept various spellings\n",
    "                row[\"overlap\"]      = ret.get(\"overlap\") or ret.get(\"median_overlap\") or ret.get(\"ov_median\") or ret.get(\"ov\")\n",
    "                row[\"fp\"]           = ret.get(\"fp\") or ret.get(\"median_fp\") or ret.get(\"fp_median\")\n",
    "                row[\"pattern_ok\"]   = ret.get(\"pattern_ok\") or ret.get(\"Ppattern\") or ret.get(\"pattern\")\n",
    "                row[\"pass_strict\"]  = ret.get(\"strict_pass\") or ret.get(\"pass_strict\") or ret.get(\"pass\")\n",
    "                row[\"n\"]            = ret.get(\"n\") or ret.get(\"count\") or ret.get(\"num\")\n",
    "            else:\n",
    "                # If your core prints tables/CSV itself, we still log a stub\n",
    "                row.update(dict(overlap=None, fp=None, pattern_ok=None, pass_strict=None, n=None))\n",
    "\n",
    "            rows.append(row)\n",
    "\n",
    "# Save raw sweep (even if some cells are NaN)\n",
    "df = pd.DataFrame(rows)\n",
    "CSV_OUT.write_text(df.to_csv(index=False))\n",
    "print(f\"[saved] {CSV_OUT}\")\n",
    "display(df.head(10))\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Cell 5 — Collapse to the main table: median overlap/fp & strict pass rate (%)\n",
    "# --------------------------------------------------------------------------------\n",
    "summary = []\n",
    "for (model, eps), grp in df.groupby([\"model\",\"eps\"], dropna=False):\n",
    "    # strict pass rate (percent)\n",
    "    pass_series = grp[\"pass_strict\"].dropna()\n",
    "    pass_rate = (100.0 * pass_series.mean()) if len(pass_series) else float(\"nan\")\n",
    "\n",
    "    # medians\n",
    "    ov_med = median_safe(list(grp[\"overlap\"].values))\n",
    "    fp_med = median_safe(list(grp[\"fp\"].values))\n",
    "\n",
    "    # how many rows contributed\n",
    "    n_rows = int(len(grp))\n",
    "    summary.append(dict(\n",
    "        Model=model,\n",
    "        eps=f\"{int(round(eps*255))}/255\",\n",
    "        n=n_rows,\n",
    "        StrictPassPct=pass_rate,\n",
    "        Median= f\"{ov_med:.2f} / {fp_med:.2f}\" if (not math.isnan(ov_med) and not math.isnan(fp_med)) else \"—\",\n",
    "    ))\n",
    "\n",
    "tbl = pd.DataFrame(summary, columns=[\"Model\",\"eps\",\"n\",\"StrictPassPct\",\"Median\"])\n",
    "display(tbl)\n",
    "\n",
    "# Write a compact LaTeX table\n",
    "latex = textwrap.dedent(rf\"\"\"\n",
    "\\begin{table}[t]\n",
    "\\centering\n",
    "\\caption{{\\textbf{{Balanced predicate certification under OOD.}} Pass rate (\\%), median overlap and median FP for $\\rho={PRED['rho']:.2f}$, $\\gamma={PRED['gamma']:.2f}$, $s_{{\\min}}={PRED['s_min']}$, $\\tau={PRED['tau']:.2f}$.}}\n",
    "\\label{{tab:predicate_balanced_main}}\n",
    "\\begin{tabular}{{lcccc}}\n",
    "\\toprule\n",
    "\\textbf{{Model}} & $\\boldsymbol{{\\varepsilon}}$ & $\\boldsymbol{{n}}$ & \\textbf{{Strict pass (\\%)}} & \\textbf{{Median overlap / FP}} \\\\\n",
    "\\midrule\n",
    "\"\"\"[1:])\n",
    "\n",
    "for model in [\"EncDec\",\"FALCONet\",\"AttU-Net\"]:\n",
    "    sub = tbl[tbl.Model==model]\n",
    "    for _,r in sub.iterrows():\n",
    "        latex += f\"{model} & ${r.eps}$ & {int(r.n)} & {0 if math.isnan(r.StrictPassPct) else int(round(r.StrictPassPct))} & {r.Median} \\\\\\\\\\n\"\n",
    "    latex += \"\\\\midrule\\n\"\n",
    "latex = latex.rstrip(\"\\\\midrule\\n\") + \"\\\\bottomrule\\n\\\\end{tabular}\\n\\\\end{table}\\n\"\n",
    "\n",
    "TEX_OUT.write_text(latex)\n",
    "print(f\"[saved] {TEX_OUT}\")\n",
    "print(latex)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Cell 6 — Small diagnostic: strict pass vs ε (aggregated per model)\n",
    "# --------------------------------------------------------------------\n",
    "plt.figure(figsize=(5.6,3.6))\n",
    "for model, grp in tbl.groupby(\"Model\"):\n",
    "    xs = [int(eps.split(\"/\")[0]) for eps in grp[\"eps\"]]\n",
    "    ys = [0 if math.isnan(v) else v for v in grp[\"StrictPassPct\"]]\n",
    "    plt.plot(xs, ys, marker=\"o\", label=model)\n",
    "plt.xlabel(\"ε (in 1/255)\")\n",
    "plt.ylabel(\"Strict pass rate (%)\")\n",
    "plt.title(\"Predicate pass vs. ε\")\n",
    "plt.grid(True, alpha=0.35)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Done ✅"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "nova_patched_at": "2025-08-17T09:33:04.541887Z",
  "nova_trimmed": {
   "kept_cell_indices": [
    0,
    7,
    3,
    5,
    8,
    6,
    9
   ],
   "note": "Only the minimal real-verifier path; no dummy cells, no legacy path patches.",
   "source": "nova_sd_verifier_v8.ipynb",
   "timestamp": "2025-08-16T18:27:22.813495Z"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
